{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "binding-conservation",
   "metadata": {},
   "source": [
    "# Consumer Behavior Analytics - Data Modelling  of `customers_exposed`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-occupation",
   "metadata": {},
   "source": [
    "**Libraries and imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modified-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic DS libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# DataViz libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistics Libraries\n",
    "from scipy import stats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "# Data Utils\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, \\\n",
    "                                                                     recall_score, \\\n",
    "                                                                     precision_score, \\\n",
    "                                                                     accuracy_score, \\\n",
    "                                                                     roc_auc_score, \\\n",
    "                                                                     auc, \\\n",
    "                                                                     plot_confusion_matrix, \\\n",
    "                                                                     plot_roc_curve\n",
    "                                                                         \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Notebook setup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mediterranean-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading customers exposed\n",
    "customers_exposed = pd.read_csv('../data/customers_exposed_ohe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "supposed-september",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Response</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Income_PerCap</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Prop_Spending_Income_pc</th>\n",
       "      <th>Total_Puchases</th>\n",
       "      <th>Avg_Ticket</th>\n",
       "      <th>Age</th>\n",
       "      <th>Dt_Customer_InDays</th>\n",
       "      <th>Education_2n Cycle</th>\n",
       "      <th>Education_Basic</th>\n",
       "      <th>Education_Graduation</th>\n",
       "      <th>Education_Master</th>\n",
       "      <th>Education_PhD</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Together</th>\n",
       "      <th>Marital_Status_Widow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1957</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>88</td>\n",
       "      <td>546</td>\n",
       "      <td>172</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>1617</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>25</td>\n",
       "      <td>64.68</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1974</td>\n",
       "      <td>30351.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10117.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>6</td>\n",
       "      <td>7.67</td>\n",
       "      <td>40</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950</td>\n",
       "      <td>5648.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>49</td>\n",
       "      <td>0.034703</td>\n",
       "      <td>2</td>\n",
       "      <td>24.50</td>\n",
       "      <td>64</td>\n",
       "      <td>592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1946</td>\n",
       "      <td>82800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1006</td>\n",
       "      <td>22</td>\n",
       "      <td>115</td>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82800.0</td>\n",
       "      <td>1315</td>\n",
       "      <td>0.015882</td>\n",
       "      <td>26</td>\n",
       "      <td>50.58</td>\n",
       "      <td>68</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949</td>\n",
       "      <td>76995.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>1012</td>\n",
       "      <td>80</td>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>176</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25665.0</td>\n",
       "      <td>1782</td>\n",
       "      <td>0.069433</td>\n",
       "      <td>26</td>\n",
       "      <td>68.54</td>\n",
       "      <td>65</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_Birth   Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  \\\n",
       "0        1957  58138.0        0         0       58       635         88   \n",
       "1        1974  30351.0        1         0       19        14          0   \n",
       "2        1950   5648.0        1         1       68        28          0   \n",
       "3        1946  82800.0        0         0       23      1006         22   \n",
       "4        1949  76995.0        0         1       91      1012         80   \n",
       "\n",
       "   MntMeatProducts  MntFishProducts  MntSweetProducts  MntGoldProds  \\\n",
       "0              546              172                88            88   \n",
       "1               24                3                 3             2   \n",
       "2                6                1                 1            13   \n",
       "3              115               59                68            45   \n",
       "4              498                0                16           176   \n",
       "\n",
       "   NumDealsPurchases  NumWebPurchases  NumCatalogPurchases  NumStorePurchases  \\\n",
       "0                  3                8                   10                  4   \n",
       "1                  1                3                    0                  2   \n",
       "2                  1                1                    0                  0   \n",
       "3                  1                7                    6                 12   \n",
       "4                  2               11                    4                  9   \n",
       "\n",
       "   NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  \\\n",
       "0                  7             0             0             0             0   \n",
       "1                  9             0             0             0             0   \n",
       "2                 20             1             0             0             0   \n",
       "3                  3             0             0             1             1   \n",
       "4                  5             0             0             0             1   \n",
       "\n",
       "   AcceptedCmp2  Complain  Response  Family_Size  Income_PerCap  Total_Spent  \\\n",
       "0             0         0         1            1        58138.0         1617   \n",
       "1             0         0         1            3        10117.0           46   \n",
       "2             0         0         0            4         1412.0           49   \n",
       "3             0         0         1            1        82800.0         1315   \n",
       "4             0         0         0            3        25665.0         1782   \n",
       "\n",
       "   Prop_Spending_Income_pc  Total_Puchases  Avg_Ticket  Age  \\\n",
       "0                 0.027813              25       64.68   57   \n",
       "1                 0.004547               6        7.67   40   \n",
       "2                 0.034703               2       24.50   64   \n",
       "3                 0.015882              26       50.58   68   \n",
       "4                 0.069433              26       68.54   65   \n",
       "\n",
       "   Dt_Customer_InDays  Education_2n Cycle  Education_Basic  \\\n",
       "0                  37                   0                0   \n",
       "1                 312                   0                0   \n",
       "2                 592                   0                0   \n",
       "3                 118                   0                0   \n",
       "4                 242                   0                0   \n",
       "\n",
       "   Education_Graduation  Education_Master  Education_PhD  \\\n",
       "0                     1                 0              0   \n",
       "1                     0                 0              1   \n",
       "2                     0                 0              1   \n",
       "3                     0                 0              1   \n",
       "4                     0                 1              0   \n",
       "\n",
       "   Marital_Status_Divorced  Marital_Status_Married  Marital_Status_Single  \\\n",
       "0                        0                       0                      1   \n",
       "1                        0                       0                      0   \n",
       "2                        0                       0                      0   \n",
       "3                        0                       0                      1   \n",
       "4                        0                       1                      0   \n",
       "\n",
       "   Marital_Status_Together  Marital_Status_Widow  \n",
       "0                        0                     0  \n",
       "1                        1                     0  \n",
       "2                        1                     0  \n",
       "3                        0                     0  \n",
       "4                        0                     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_exposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "satisfied-retirement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5486\n",
       "0    0.4514\n",
       "Name: Response, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking class balance (or imballance)\n",
    "customers_exposed['Response'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-writing",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-objective",
   "metadata": {},
   "source": [
    "We are going to start preparing the data for modelling regarding both datasets: `customers_whole` and `customers_exposed`, but only until One Hot Encoding.\n",
    "\n",
    "After that, we will save both one hot encoded dataframes into new csv files and split both analysis in different notebooks. The analysis in this notebook will be for `customers_whole` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adjacent-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining Sample first_date\n",
    "# first_date = customers_whole['Dt_Customer'].min()\n",
    "\n",
    "# # Transforming datetime feature to numeric feature\n",
    "# for df in [customers_exposed, customers_whole]:\n",
    "#     df['Dt_Customer_InDays'] = df['Dt_Customer'] - first_date\n",
    "    \n",
    "#     df['Dt_Customer_InDays'] = (df['Dt_Customer_InDays'] / np.timedelta64(1, 'D')).astype(int) + 1\n",
    "    \n",
    "#     # Dropping unuseful columns for modelling\n",
    "#     df.drop(['ID', 'Dt_Customer'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beginning-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One Hot Encoding categorical features with pd.get_dummies\n",
    "# customers_exposed_ohe = pd.get_dummies(customers_exposed)\n",
    "# customers_whole_ohe = pd.get_dummies(customers_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aggregate-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving One Hot Enconded files into a new csv file\n",
    "# customers_whole_ohe.to_csv('../data/customers_whole_ohe.csv', header = True, index = False)\n",
    "# # pd.read_csv('../data/customers_whole_ohe.csv')\n",
    "\n",
    "# customers_exposed_ohe.to_csv('../data/customers_exposed_ohe.csv', header = True, index = False)\n",
    "# # pd.read_csv('../data/customers_exposed_ohe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-principle",
   "metadata": {},
   "source": [
    "Both files have been saved! We will not need to load the `customers_whole_ohe.csv` into this notebook, but it is aways good to keep a standartd log of actions.\n",
    "\n",
    "**We will move forward with modelling for the `customers_whole` dataset hereafter.**\n",
    "\n",
    "Let's start:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-photography",
   "metadata": {},
   "source": [
    "### Splitting Data into _Train_, _Validation_ and _Test_ sets\n",
    "\n",
    "We will split the data according to the following schedule:\n",
    "\n",
    "- Create a `df_train` and a `df_test`.\n",
    "- From the previous `df_train` we will once again split it into two: `df_train` and `df_val`.\n",
    "\n",
    "We also know that _specially_ in this dataset (`_whole`) we have unballanced data. So we will perform a oversampling technique called SMOTE. According to the paper published in _The Journal of Artificial Intelligence Research_ in 2002:\n",
    "\n",
    "> [With SMOTE] The minority class is over-sampled by taking each minority class sample and introducing synthetic examples along the line segments joining any/all of the $k$ minority class nearest neighbors. Depending upon the amount of over-sampling required, neighbors from the k nearest neighbors are randomly chosen.[$^{SMOTE: \\: Synthetic\\:Minority\\:Over-sampling\\:Technique}$](https://arxiv.org/pdf/1106.1813.pdf)\n",
    "\n",
    "- Finally, we will separate all dfs into `X`'s and `y`, naming respectively accordint to the df they belong to.\n",
    "\n",
    "Let's start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "limited-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting df_train and df_test for training and testing\n",
    "df_train, df_test = train_test_split(customers_exposed, test_size = .2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "civil-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savint test set to a new csv file\n",
    "df_test.to_csv('../data/tests_sets/df_test_pure-customers_exposed.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rough-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting df_train into df_train and df_val\n",
    "df_train, df_val = train_test_split(df_train, test_size = .2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "primary-remains",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    212\n",
       "0    176\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking target variable balance (or imballance)\n",
    "df_train['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "every-doubt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    212\n",
       "1    212\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balancing target variable with SMOTE technique\n",
    "\n",
    "# Instantiating SMOTER over_sampler\n",
    "smote = SMOTE(random_state = 7)\n",
    "\n",
    "# Fitting and resampling data with SMOTE\n",
    "X_train, y_train = smote.fit_resample(df_train.drop('Response', axis = 1), df_train['Response'])\n",
    "\n",
    "# Checking target class balance\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "statutory-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_val.drop('Response', axis = 1)\n",
    "y_val = df_val['Response']\n",
    "\n",
    "X_test = df_test.drop('Response', axis = 1)\n",
    "y_test = df_test['Response']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-pharmacology",
   "metadata": {},
   "source": [
    "Let's check if the generated `X`'s and `y`'s are correctly built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "closed-shelter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, y_train   shapes:  (424, 40) (424,)\n",
      "X_val  , y_val     shapes:  (97, 40) (97,)\n",
      "X_test , y_test    shapes:  (122, 40) (122,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train, y_train   shapes: ', X_train.shape, y_train.shape)\n",
    "print('X_val  , y_val     shapes: ', X_val.shape, y_val.shape)\n",
    "print('X_test , y_test    shapes: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-publicity",
   "metadata": {},
   "source": [
    "**All shapes match**. We are good to go on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "enormous-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model2 = RandomForestClassifier()\n",
    "# param_grid = {\n",
    "#             'n_estimators': [50, 60, 70, 80, 90, 100],\n",
    "#             'max_depth': np.arange(0, 10),\n",
    "#             'min_samples_split': np.arange(0, 10),\n",
    "#             'min_samples_leaf': stats.loguniform(.01, 1),\n",
    "#         }\n",
    "# rf_model_rsearch = RandomizedSearchCV(rf_model2, param_distributions = param_grid, cv = 10, \n",
    "#                                       n_jobs = -1, scoring = 'f1', random_state = 7, n_iter = 50, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "documentary-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model_rsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "elect-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_val, rf_model_rsearch.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-reminder",
   "metadata": {},
   "source": [
    "### Analyzing multicolinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-maldives",
   "metadata": {},
   "source": [
    "In the previous notebooks, we have created new variables from pre-existing variables. Therefore we made room for possible multicolinearity.\n",
    "\n",
    "Some techniques for analyzing multicolinearity are:\n",
    "\n",
    "- Checking correlation values between variables;\n",
    "- Checking the Variance Inflation Factor (VIF) and dropping variables with factor $> 10$;\n",
    "- Performing Principal Component Analysis, to the cost of lesser interpretability;\n",
    "- Perform regularization such as (Lasso or Ridge) for linear models, such as Logistic Regression;\n",
    "\n",
    "For the sake of simplicity, let's go foward with `VIF` and drop variables with factor $ >10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "occupied-guitar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines',\n",
       "       'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
       "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
       "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
       "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
       "       'AcceptedCmp2', 'Complain', 'Family_Size', 'Income_PerCap',\n",
       "       'Total_Spent', 'Prop_Spending_Income_pc', 'Total_Puchases',\n",
       "       'Avg_Ticket', 'Age', 'Dt_Customer_InDays', 'Education_2n Cycle',\n",
       "       'Education_Basic', 'Education_Graduation', 'Education_Master',\n",
       "       'Education_PhD', 'Marital_Status_Divorced', 'Marital_Status_Married',\n",
       "       'Marital_Status_Single', 'Marital_Status_Together',\n",
       "       'Marital_Status_Widow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "floating-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating numeric features in a list, except booleans\n",
    "numeric_features = [\n",
    "    'Year_Birth', \n",
    "#     'Education',\n",
    "    'Income', \n",
    "    'Kidhome',                \n",
    "    'Teenhome', \n",
    "    'Recency', \n",
    "    'MntWines', \n",
    "    'MntFruits',\n",
    "    'MntMeatProducts', \n",
    "    'MntFishProducts', \n",
    "    'MntSweetProducts',\n",
    "    'MntGoldProds', \n",
    "    'NumDealsPurchases', \n",
    "    'NumWebPurchases',\n",
    "    'NumCatalogPurchases', \n",
    "    'NumStorePurchases', \n",
    "    'NumWebVisitsMonth',\n",
    "    'Total_Spent',\n",
    "    'Total_Puchases',\n",
    "    'Family_Size',\n",
    "    'Income_PerCap',\n",
    "    'Prop_Spending_Income_pc', \n",
    "    'Avg_Ticket', \n",
    "    'Age', \n",
    "    'Dt_Customer_InDays'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "committed-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of varibles for VIF analysis\n",
    "\n",
    "################################################################################################\n",
    "#   This cell has been iterated \"mannually\" after checking vif values in the dataframe below   #\n",
    "################################################################################################\n",
    "\n",
    "numeric_features_vif_ok = [\n",
    "#     'Year_Birth', \n",
    "#     'Education',\n",
    "#     'Income', \n",
    "    'Kidhome',                \n",
    "    'Teenhome', \n",
    "    'Recency', \n",
    "#     'MntWines', \n",
    "#     'MntFruits',\n",
    "#     'MntMeatProducts', \n",
    "#     'MntFishProducts', \n",
    "#     'MntSweetProducts',\n",
    "    'MntGoldProds', \n",
    "#     'NumDealsPurchases', \n",
    "#     'NumWebPurchases',\n",
    "#     'NumCatalogPurchases', \n",
    "#     'NumStorePurchases', \n",
    "#     'NumWebVisitsMonth',\n",
    "#     'Total_Spent',\n",
    "#     'Total_Puchases',\n",
    "#     'Family_Size',\n",
    "    'Income_PerCap',\n",
    "    'Prop_Spending_Income_pc', \n",
    "    'Avg_Ticket', \n",
    "#     'Age', \n",
    "    'Dt_Customer_InDays'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wanted-shield",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vif_index</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.475610</td>\n",
       "      <td>Kidhome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.043968</td>\n",
       "      <td>Teenhome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.314574</td>\n",
       "      <td>Recency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.413804</td>\n",
       "      <td>MntGoldProds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.562519</td>\n",
       "      <td>Income_PerCap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.257530</td>\n",
       "      <td>Prop_Spending_Income_pc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.602235</td>\n",
       "      <td>Avg_Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.111658</td>\n",
       "      <td>Dt_Customer_InDays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vif_index                  feature\n",
       "0   1.475610                  Kidhome\n",
       "1   2.043968                 Teenhome\n",
       "2   3.314574                  Recency\n",
       "3   2.413804             MntGoldProds\n",
       "4   3.562519            Income_PerCap\n",
       "5   4.257530  Prop_Spending_Income_pc\n",
       "6   1.602235               Avg_Ticket\n",
       "7   3.111658       Dt_Customer_InDays"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe for storing vif and its respective variable\n",
    "vif_df = pd.DataFrame()\n",
    "\n",
    "# Calculating vif values and saving it into vif_index columns\n",
    "vif_df[\"vif_index\"] = [vif(X_train[numeric_features_vif_ok].values, i) \\\n",
    "                               for i in range(X_train[numeric_features_vif_ok].shape[1])]\n",
    "\n",
    "# Saving variable name into feature column\n",
    "vif_df[\"feature\"] = X_train[numeric_features_vif_ok].columns\n",
    "\n",
    "# Checking results\n",
    "vif_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-weekly",
   "metadata": {},
   "source": [
    "All `VIF` factor are now $\\le 10$, we can start dealing with the different orders of magnitude in our numeric features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "incorrect-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_from_vif = [feature for feature in numeric_features if feature not in numeric_features_vif_ok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "single-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_drop_from_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-advocacy",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "In order to have the numeric data in the same order of magnite, we will:\n",
    "\n",
    "- Use RobustScaler for variables with outliers;\n",
    "- Use StandardScaler for variables with no outliers;\n",
    "\n",
    "\n",
    "Let's start by listing features with outliers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-award",
   "metadata": {},
   "source": [
    "**Getting features with ouliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "quantitative-bruce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MntFruits',\n",
       " 'MntMeatProducts',\n",
       " 'MntFishProducts',\n",
       " 'MntSweetProducts',\n",
       " 'MntGoldProds',\n",
       " 'NumDealsPurchases',\n",
       " 'NumWebVisitsMonth',\n",
       " 'Family_Size',\n",
       " 'Income_PerCap',\n",
       " 'Prop_Spending_Income_pc',\n",
       " 'Avg_Ticket']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing features names if feature has outlier\n",
    "to_robust_scale = []\n",
    "for feature in numeric_features:\n",
    "    \n",
    "    Q1 = np.percentile(X_train[feature].sort_values(), 25, interpolation = 'midpoint')  \n",
    "    Q3 = np.percentile(X_train[feature].sort_values(), 75, interpolation = 'midpoint')  \n",
    "\n",
    "    IQR = Q3 - Q1  \n",
    "    \n",
    "    low_lim = Q1 - 1.5 * IQR \n",
    "    up_lim = Q3 + 1.5 * IQR \n",
    "\n",
    "    if (X_train[feature] > up_lim).any() or (X_train[feature] < low_lim).any(): \n",
    "         to_robust_scale.append(feature)\n",
    "\n",
    "to_robust_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-college",
   "metadata": {},
   "source": [
    "And then, from the previous list, we can list the variables that will be standardized:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-thunder",
   "metadata": {},
   "source": [
    "**Listing features _without_ outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "organizational-russia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year_Birth',\n",
       " 'Income',\n",
       " 'Kidhome',\n",
       " 'Teenhome',\n",
       " 'Recency',\n",
       " 'MntWines',\n",
       " 'NumWebPurchases',\n",
       " 'NumCatalogPurchases',\n",
       " 'NumStorePurchases',\n",
       " 'Total_Spent',\n",
       " 'Total_Puchases',\n",
       " 'Age',\n",
       " 'Dt_Customer_InDays']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_standardize = [feature for feature in numeric_features if feature not in to_robust_scale]\n",
    "to_standardize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-guyana",
   "metadata": {},
   "source": [
    "**Applying RobustScaler to variables listed in `to_robust_scale` list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "divine-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler()\n",
    "robust_scaler.fit(X_train[to_robust_scale])\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled[to_robust_scale] = robust_scaler.transform(X_train[to_robust_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-secret",
   "metadata": {},
   "source": [
    "**Applying StandardScaler to variables listed in `to_standardize` list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "inappropriate-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_scaler = StandardScaler()\n",
    "\n",
    "stand_scaler.fit(X_train[to_standardize])\n",
    "X_train_scaled[to_standardize] = stand_scaler.transform(X_train[to_standardize])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-geometry",
   "metadata": {},
   "source": [
    "Let's check the `X_train` dataset to see if everything went well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "extensive-belief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Income_PerCap</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Prop_Spending_Income_pc</th>\n",
       "      <th>Total_Puchases</th>\n",
       "      <th>Avg_Ticket</th>\n",
       "      <th>Age</th>\n",
       "      <th>Dt_Customer_InDays</th>\n",
       "      <th>Education_2n Cycle</th>\n",
       "      <th>Education_Basic</th>\n",
       "      <th>Education_Graduation</th>\n",
       "      <th>Education_Master</th>\n",
       "      <th>Education_PhD</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Together</th>\n",
       "      <th>Marital_Status_Widow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.0</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.25</td>\n",
       "      <td>-2.58</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-2.40</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.34</td>\n",
       "      <td>2.09</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.39</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.61</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.99</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.29</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.37</td>\n",
       "      <td>32.99</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year_Birth  Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  \\\n",
       "count      424.00  424.00   424.00    424.00   424.00    424.00     424.00   \n",
       "mean         0.00    0.00     0.00      0.00     0.00      0.00       0.38   \n",
       "std          1.00    1.00     1.00      1.00     1.00      1.00       0.99   \n",
       "min         -2.25   -2.58    -0.66     -0.74    -1.57     -1.27      -0.39   \n",
       "25%         -0.83   -0.85    -0.66     -0.74    -0.84     -0.93      -0.32   \n",
       "50%          0.09    0.12    -0.66     -0.74    -0.10     -0.08       0.00   \n",
       "75%          0.67    0.80     1.40      1.09     0.82      0.78       0.68   \n",
       "max          2.34    2.09     3.45      2.93     1.86      2.39       4.00   \n",
       "\n",
       "       MntMeatProducts  MntFishProducts  MntSweetProducts  MntGoldProds  \\\n",
       "count           424.00           424.00            424.00        424.00   \n",
       "mean              0.34             0.41              0.43          0.38   \n",
       "std               0.69             0.91              0.98          0.98   \n",
       "min              -0.30            -0.29             -0.32         -0.61   \n",
       "25%              -0.22            -0.25             -0.28         -0.28   \n",
       "50%               0.00             0.00              0.00          0.00   \n",
       "75%               0.78             0.75              0.72          0.72   \n",
       "max               3.63             3.41              3.87          3.61   \n",
       "\n",
       "       NumDealsPurchases  NumWebPurchases  NumCatalogPurchases  \\\n",
       "count             424.00           424.00               424.00   \n",
       "mean                0.59             0.00                -0.00   \n",
       "std                 0.95             1.00                 1.00   \n",
       "min                -0.50            -1.92                -1.36   \n",
       "25%                 0.00            -0.75                -1.02   \n",
       "50%                 0.00             0.02                 0.02   \n",
       "75%                 1.00             0.79                 0.71   \n",
       "max                 5.00             2.34                 2.43   \n",
       "\n",
       "       NumStorePurchases  NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  \\\n",
       "count             424.00             424.00        424.00        424.00   \n",
       "mean                0.00              -0.21          0.28          0.27   \n",
       "std                 1.00               0.66          0.45          0.44   \n",
       "min                -1.95              -1.50          0.00          0.00   \n",
       "25%                -0.74              -0.75          0.00          0.00   \n",
       "50%                -0.13               0.00          0.00          0.00   \n",
       "75%                 0.78               0.25          1.00          1.00   \n",
       "max                 1.99               3.50          1.00          1.00   \n",
       "\n",
       "       AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  Family_Size  \\\n",
       "count        424.00        424.00        424.00    424.00       424.00   \n",
       "mean           0.25          0.22          0.04      0.00         0.35   \n",
       "std            0.43          0.41          0.20      0.05         0.94   \n",
       "min            0.00          0.00          0.00      0.00        -1.00   \n",
       "25%            0.00          0.00          0.00      0.00         0.00   \n",
       "50%            0.00          0.00          0.00      0.00         0.00   \n",
       "75%            1.00          0.00          0.00      0.00         1.00   \n",
       "max            1.00          1.00          1.00      1.00         3.00   \n",
       "\n",
       "       Income_PerCap  Total_Spent  Prop_Spending_Income_pc  Total_Puchases  \\\n",
       "count         424.00       424.00                   424.00          424.00   \n",
       "mean            0.23        -0.00                     0.10            0.00   \n",
       "std             0.86         1.00                     0.69            1.00   \n",
       "min            -0.94        -1.37                    -0.93           -2.40   \n",
       "25%            -0.46        -0.99                    -0.43           -0.67   \n",
       "50%             0.00         0.00                     0.00            0.20   \n",
       "75%             0.54         0.82                     0.57            0.64   \n",
       "max             2.76         2.29                     2.83            2.37   \n",
       "\n",
       "       Avg_Ticket     Age  Dt_Customer_InDays  Education_2n Cycle  \\\n",
       "count      424.00  424.00              424.00              424.00   \n",
       "mean         0.23   -0.00               -0.00                0.07   \n",
       "std          1.78    1.00                1.00                0.25   \n",
       "min         -0.78   -2.33               -1.59                0.00   \n",
       "25%         -0.46   -0.69               -0.88                0.00   \n",
       "50%         -0.00   -0.08               -0.10                0.00   \n",
       "75%          0.54    0.84                0.84                0.00   \n",
       "max         32.99    2.26                1.79                1.00   \n",
       "\n",
       "       Education_Basic  Education_Graduation  Education_Master  Education_PhD  \\\n",
       "count           424.00                424.00            424.00         424.00   \n",
       "mean              0.01                  0.48              0.15           0.24   \n",
       "std               0.10                  0.50              0.35           0.43   \n",
       "min               0.00                  0.00              0.00           0.00   \n",
       "25%               0.00                  0.00              0.00           0.00   \n",
       "50%               0.00                  0.00              0.00           0.00   \n",
       "75%               0.00                  1.00              0.00           0.00   \n",
       "max               1.00                  1.00              1.00           1.00   \n",
       "\n",
       "       Marital_Status_Divorced  Marital_Status_Married  Marital_Status_Single  \\\n",
       "count                    424.0                  424.00                 424.00   \n",
       "mean                       0.1                    0.33                   0.23   \n",
       "std                        0.3                    0.47                   0.42   \n",
       "min                        0.0                    0.00                   0.00   \n",
       "25%                        0.0                    0.00                   0.00   \n",
       "50%                        0.0                    0.00                   0.00   \n",
       "75%                        0.0                    1.00                   0.00   \n",
       "max                        1.0                    1.00                   1.00   \n",
       "\n",
       "       Marital_Status_Together  Marital_Status_Widow  \n",
       "count                   424.00                424.00  \n",
       "mean                      0.24                  0.04  \n",
       "std                       0.43                  0.20  \n",
       "min                       0.00                  0.00  \n",
       "25%                       0.00                  0.00  \n",
       "50%                       0.00                  0.00  \n",
       "75%                       0.00                  0.00  \n",
       "max                       1.00                  1.00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking statistics from scaled DFs\n",
    "round(X_train_scaled.describe(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-treatment",
   "metadata": {},
   "source": [
    "The dataset seems alright.\n",
    "\n",
    "Aiming to avoid **data leakage**, we've performed the `.fit` method using only the `X_train` dataset. We need now to `.transform` the values from `X_val` and `X_test` datasets so we can use them later to make predictions and evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "primary-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming x_val and x_test with scalers from X_train\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_val_scaled[to_robust_scale] = robust_scaler.transform(X_val[to_robust_scale])\n",
    "X_test_scaled[to_robust_scale] = robust_scaler.transform(X_test[to_robust_scale])\n",
    "\n",
    "X_val_scaled[to_standardize] = stand_scaler.transform(X_val[to_standardize])\n",
    "X_test_scaled[to_standardize] = stand_scaler.transform(X_test[to_standardize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "taken-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking transformed datasets\n",
    "# X_val.head() # Uncomment to view dataframes\n",
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "hawaiian-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../data/tests_sets/X_train-customers_exposed.csv', header = True, index = False)\n",
    "y_train.to_csv('../data/tests_sets/y_train-customers_exposed.csv', header = True, index = False)\n",
    "\n",
    "X_val.to_csv('../data/tests_sets/X_val-customers_exposed.csv', header = True, index = False)\n",
    "y_val.to_csv('../data/tests_sets/y_val-customers_exposed.csv', header = True, index = False)\n",
    "\n",
    "X_test.to_csv('../data/tests_sets/X_test-customers_exposed.csv', header = True, index = False)\n",
    "y_test.to_csv('../data/tests_sets/y_test-customers_exposed.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-ability",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-carroll",
   "metadata": {},
   "source": [
    "Let's start with a baseline model.\n",
    "\n",
    "A baseline model is a good pratice to determine if all sweat put into modelling with different algorithms and hyperparameter tuning is worth the effort.\n",
    "\n",
    "We can use a simple **Linear Regression**, not tunned, model as our baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-retailer",
   "metadata": {},
   "source": [
    "### Simple LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "known-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating the model\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "# Fitting the model\n",
    "log_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "computational-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting using X_val\n",
    "y_val_pred = log_model.predict(X_val_scaled)\n",
    "# y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "alert-syracuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.71        39\n",
      "           1       0.81      0.76      0.79        58\n",
      "\n",
      "    accuracy                           0.75        97\n",
      "   macro avg       0.74      0.75      0.75        97\n",
      "weighted avg       0.76      0.75      0.75        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating metrics with Skelearn Classification Report\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "modified-utilization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (10, 4))\n",
    "plot_roc_curve(log_model, X_val_scaled, y_val, ax = ax[0])\n",
    "plot_confusion_matrix(log_model, X_val_scaled, y_val, cmap=plt.cm.Reds, ax = ax[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-glass",
   "metadata": {},
   "source": [
    "### Keeping metrics logs in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "seeing-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "EXPERIMENT_NAME = '[v3.9] [customers_exposed] [Consumer Behavior Analytics] [Renan Moises]'\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment_id = client.create_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "timely-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "metrics = [accuracy_score, precision_score, recall_score, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "suspected-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.create_run(experiment_id)\n",
    "\n",
    "client.log_param(run.info.run_id, 'model', 'LogistRegression-Baseline')\n",
    "\n",
    "for metric in zip(metrics_names, metrics):\n",
    "    client.log_metric(run.info.run_id, metric[0], metric[1](y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-desktop",
   "metadata": {},
   "source": [
    "## Modelling for Real\n",
    "\n",
    "- LogisticRegression (tunned)\n",
    "- KNNClassifier\n",
    "- SVC\n",
    "- RFClassifier\n",
    "- AdaBoost\n",
    "- GradientBoostClassifier\n",
    "- XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "unauthorized-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression-Tunned': LogisticRegression(),\n",
    "    'KNNClassifier': KNeighborsClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'XGboostClassifier': XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-mouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression-Tunned ####################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "for model_key, model_value in models.items():\n",
    "#     X_train_modelling = X_train.copy().drop(to_drop_from_vif, axis = 1)\n",
    "#     X_val_modelling = X_val.copy().drop(to_drop_from_vif, axis = 1)\n",
    "    \n",
    "    X_train_modelling = X_train.copy()\n",
    "    X_val_modelling = X_val.copy()\n",
    "\n",
    "    \n",
    "    if model_key == 'LogisticRegression-Tunned':\n",
    "        # Dropping Multicolinear Features for Logistic Regression\n",
    "        X_train_modelling = X_train_scaled.drop(to_drop_from_vif, axis = 1)\n",
    "        X_val_modelling = X_val_scaled.drop(to_drop_from_vif, axis = 1)\n",
    "        \n",
    "        param_grid = {\n",
    "            'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "            'tol': stats.loguniform(0.1, 1),\n",
    "            'C': stats.loguniform(3, 10)\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'KNNClassifier':\n",
    "        # Dropping Multicolinear Features for KNNClassifier\n",
    "        X_train_modelling = X_train_scaled.drop(to_drop_from_vif, axis = 1)\n",
    "        X_val_modelling = X_val_scaled.drop(to_drop_from_vif, axis = 1)\n",
    "        \n",
    "        param_grid = {'n_neighbors':[3, 4, 5, 6, 7]}\n",
    "    \n",
    "    elif model_key == 'SVC':\n",
    "        # Dropping Multicolinear Features for SVC\n",
    "        X_train_modelling = X_train_scaled.drop(to_drop_from_vif, axis = 1)\n",
    "        X_val_modelling = X_val_scaled.drop(to_drop_from_vif, axis = 1)\n",
    "        \n",
    "        param_grid = {\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'C': stats.loguniform(3, 20)\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'RandomForestClassifier':\n",
    "        param_grid = {\n",
    "            'n_estimators': np.array([50, 60, 70, 80, 90, 100, 120, 150, 200, 400], dtype = int),\n",
    "            'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "            'max_features': ['auto', 'sqrt'],\n",
    "            'min_samples_split': np.arange(0, 10),\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'bootstrap': [True, False],\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'AdaBoostClassifier':\n",
    "        param_grid = {\n",
    "            'n_estimators': np.array([50, 60, 70, 80, 90, 100, 120, 150, 200, 400], dtype = int),\n",
    "            'learning_rate': stats.lognorm(.001, 1)\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'GradientBoostingClassifier':\n",
    "        param_grid = {\n",
    "            'n_estimators': np.array([50, 60, 70, 80, 90, 100, 120, 150, 200, 400], dtype = int),\n",
    "            'learning_rate': stats.loguniform(.001, 1),\n",
    "            'min_samples_split': np.arange(0, 10),\n",
    "            'min_samples_leaf': stats.loguniform(.01, 1),\n",
    "            'max_depth': np.arange(0, 10)\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        param_grid = {\n",
    "            'n_estimators': np.array([50, 60, 70, 80, 90, 100, 120, 150, 200, 400], dtype = int),\n",
    "            'learning_rate': stats.loguniform(.001, 1),            \n",
    "            'max_depth': np.arange(0, 10),\n",
    "            'gamma': stats.loguniform(.001, 1),\n",
    "        }   \n",
    "    \n",
    "    \n",
    "    # Running RandomizedSearchCV\n",
    "    print(model_key, '#'.replace('#', '#'*(61 - len(model_key))))\n",
    "    model_rsearch = RandomizedSearchCV(model_value, \n",
    "                                       param_distributions = param_grid, \n",
    "                                       n_iter = 50, \n",
    "                                       scoring = 'f1', # Used to update weights\n",
    "                                       cv = 10, \n",
    "                                       n_jobs = -1, \n",
    "                                       verbose = 1,\n",
    "                                       random_state = 7)\n",
    "    \n",
    "    # Fitting the model to the train data\n",
    "    model_rsearch.fit(X_train_modelling, y_train)\n",
    "    \n",
    "    # Saving model as a joblib file\n",
    "#     joblib.dump(model_rsearch, f'../models/cexposed_{model_key}.pkl')\n",
    "    with open(f\"../models/pkl_cexposed_{model_key}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model_rsearch, file)\n",
    "\n",
    "    \n",
    "    # Predictions using X_val\n",
    "    y_val_pred = model_rsearch.predict(X_val_modelling)\n",
    "    \n",
    "    # Setting up metrics\n",
    "    metrics_names = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    metrics = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "    \n",
    "    # MLFlow Logs\n",
    "    run = client.create_run(experiment_id)\n",
    "    for metric_name, metric in zip(metrics_names, metrics):\n",
    "        client.log_metric(run.info.run_id, metric_name, metric(y_val, y_val_pred))\n",
    "    client.log_param(run.info.run_id, \"model\", model_key)\n",
    "    client.log_param(run.info.run_id, \"params\", model_value.get_params())\n",
    "    client.log_param(run.info.run_id, \"features\", X_train_modelling.columns.tolist())\n",
    "\n",
    "    \n",
    "    print(classification_report(y_val, y_val_pred), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad_boost_param_grid = {\n",
    "#             'n_estimators': np.array([50, 60, 70, 80, 90, 100, 120, 150, 200, 400], dtype = int),\n",
    "#             'learning_rate': stats.lognorm(.001, 1),\n",
    "#             'min_samples_split': np.arange(0, 10),\n",
    "#             'min_samples_leaf': stats.loguniform(.01, 1),\n",
    "#             'max_depth': np.arange(0, 10)\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradboost_model = GradientBoostingClassifier()\n",
    "\n",
    "# gradboost_model_rsearch = RandomizedSearchCV(gradboost_model, param_distributions = grad_boost_param_grid,\n",
    "#                                              n_iter = 50, \n",
    "#                                              scoring = 'f1', # Used to update weights\n",
    "#                                              cv = 10, \n",
    "#                                              n_jobs = -1, \n",
    "#                                              verbose = 1,\n",
    "#                                              random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradboost_model_rsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_val, gradboost_model_rsearch.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, gradboost_model_rsearch.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 2, figsize = (10, 4))\n",
    "# plot_roc_curve(gradboost_model_rsearch, X_val, y_val, ax = ax[0])\n",
    "# plot_confusion_matrix(gradboost_model_rsearch, X_val, y_val, cmap=plt.cm.Reds, ax = ax[1])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 2, figsize = (10, 4))\n",
    "# plot_roc_curve(log_model, X_test_scaled, y_test, ax = ax[0])\n",
    "# plot_confusion_matrix(log_model, X_test_scaled, y_test, cmap=plt.cm.Reds, ax = ax[1])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-batman",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# DRAFTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled.rename(columns={'Education_2n Cycle': 'Education_2n_Cycle'}, inplace = True)\n",
    "# X_val_scaled.rename(columns={'Education_2n Cycle': 'Education_2n_Cycle'}, inplace = True)\n",
    "# X_test_scaled.rename(columns={'Education_2n Cycle': 'Education_2n_Cycle'}, inplace = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
