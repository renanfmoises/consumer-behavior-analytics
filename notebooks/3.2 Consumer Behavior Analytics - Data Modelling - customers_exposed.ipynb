{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "binding-conservation",
   "metadata": {},
   "source": [
    "# Consumer Behavior Analytics - Data Modelling  of `customers_exposed`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-occupation",
   "metadata": {},
   "source": [
    "**Libraries and imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modified-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic DS libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# DataViz libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistics Libraries\n",
    "from scipy import stats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "# Data Utils\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, \\\n",
    "                                                                     recall_score, \\\n",
    "                                                                     precision_score, \\\n",
    "                                                                     accuracy_score, \\\n",
    "                                                                     roc_auc_score, \\\n",
    "                                                                     auc, \\\n",
    "                                                                     plot_confusion_matrix, \\\n",
    "                                                                     plot_roc_curve\n",
    "                                                                         \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier,\\\n",
    "                             AdaBoostClassifier,\\\n",
    "                             GradientBoostingClassifier,\\\n",
    "                             VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Notebook setup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mediterranean-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading customers exposed\n",
    "customers_exposed = pd.read_csv('../data/customers_exposed_ohe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "supposed-september",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Response</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Income_PerCap</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Prop_Spending_Income_pc</th>\n",
       "      <th>Total_Puchases</th>\n",
       "      <th>Avg_Ticket</th>\n",
       "      <th>Age</th>\n",
       "      <th>Dt_Customer_InDays</th>\n",
       "      <th>Lives_Alone</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Together</th>\n",
       "      <th>Marital_Status_Widow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>88</td>\n",
       "      <td>546</td>\n",
       "      <td>172</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>1617</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>25</td>\n",
       "      <td>64.68</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>30351.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10117.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>6</td>\n",
       "      <td>7.67</td>\n",
       "      <td>40</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5648.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>49</td>\n",
       "      <td>0.034703</td>\n",
       "      <td>2</td>\n",
       "      <td>24.50</td>\n",
       "      <td>64</td>\n",
       "      <td>592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>82800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1006</td>\n",
       "      <td>22</td>\n",
       "      <td>115</td>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82800.0</td>\n",
       "      <td>1315</td>\n",
       "      <td>0.015882</td>\n",
       "      <td>26</td>\n",
       "      <td>50.58</td>\n",
       "      <td>68</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>76995.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>1012</td>\n",
       "      <td>80</td>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>176</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25665.0</td>\n",
       "      <td>1782</td>\n",
       "      <td>0.069433</td>\n",
       "      <td>26</td>\n",
       "      <td>68.54</td>\n",
       "      <td>65</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education   Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  \\\n",
       "0          3  58138.0        0         0       58       635         88   \n",
       "1          5  30351.0        1         0       19        14          0   \n",
       "2          5   5648.0        1         1       68        28          0   \n",
       "3          5  82800.0        0         0       23      1006         22   \n",
       "4          4  76995.0        0         1       91      1012         80   \n",
       "\n",
       "   MntMeatProducts  MntFishProducts  MntSweetProducts  MntGoldProds  \\\n",
       "0              546              172                88            88   \n",
       "1               24                3                 3             2   \n",
       "2                6                1                 1            13   \n",
       "3              115               59                68            45   \n",
       "4              498                0                16           176   \n",
       "\n",
       "   NumDealsPurchases  NumWebPurchases  NumCatalogPurchases  NumStorePurchases  \\\n",
       "0                  3                8                   10                  4   \n",
       "1                  1                3                    0                  2   \n",
       "2                  1                1                    0                  0   \n",
       "3                  1                7                    6                 12   \n",
       "4                  2               11                    4                  9   \n",
       "\n",
       "   NumWebVisitsMonth  Complain  Response  Family_Size  Income_PerCap  \\\n",
       "0                  7         0         1            1        58138.0   \n",
       "1                  9         0         1            3        10117.0   \n",
       "2                 20         0         0            4         1412.0   \n",
       "3                  3         0         1            1        82800.0   \n",
       "4                  5         0         0            3        25665.0   \n",
       "\n",
       "   Total_Spent  Prop_Spending_Income_pc  Total_Puchases  Avg_Ticket  Age  \\\n",
       "0         1617                 0.027813              25       64.68   57   \n",
       "1           46                 0.004547               6        7.67   40   \n",
       "2           49                 0.034703               2       24.50   64   \n",
       "3         1315                 0.015882              26       50.58   68   \n",
       "4         1782                 0.069433              26       68.54   65   \n",
       "\n",
       "   Dt_Customer_InDays  Lives_Alone  Marital_Status_Divorced  \\\n",
       "0                  37            1                        0   \n",
       "1                 312            0                        0   \n",
       "2                 592            0                        0   \n",
       "3                 118            1                        0   \n",
       "4                 242            0                        0   \n",
       "\n",
       "   Marital_Status_Married  Marital_Status_Single  Marital_Status_Together  \\\n",
       "0                       0                      1                        0   \n",
       "1                       0                      0                        1   \n",
       "2                       0                      0                        1   \n",
       "3                       0                      1                        0   \n",
       "4                       1                      0                        0   \n",
       "\n",
       "   Marital_Status_Widow  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_exposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "satisfied-retirement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5486\n",
       "0    0.4514\n",
       "Name: Response, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking class balance (or imballance)\n",
    "customers_exposed['Response'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-writing",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-objective",
   "metadata": {},
   "source": [
    "We are going to start preparing the data for modelling regarding both datasets: `customers_whole` and `customers_exposed`, but only until One Hot Encoding.\n",
    "\n",
    "After that, we will save both one hot encoded dataframes into new csv files and split both analysis in different notebooks. The analysis in this notebook will be for `customers_whole` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adjacent-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining Sample first_date\n",
    "# first_date = customers_whole['Dt_Customer'].min()\n",
    "\n",
    "# # Transforming datetime feature to numeric feature\n",
    "# for df in [customers_exposed, customers_whole]:\n",
    "#     df['Dt_Customer_InDays'] = df['Dt_Customer'] - first_date\n",
    "    \n",
    "#     df['Dt_Customer_InDays'] = (df['Dt_Customer_InDays'] / np.timedelta64(1, 'D')).astype(int) + 1\n",
    "    \n",
    "#     # Dropping unuseful columns for modelling\n",
    "#     df.drop(['ID', 'Dt_Customer'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beginning-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One Hot Encoding categorical features with pd.get_dummies\n",
    "# customers_exposed_ohe = pd.get_dummies(customers_exposed)\n",
    "# customers_whole_ohe = pd.get_dummies(customers_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aggregate-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving One Hot Enconded files into a new csv file\n",
    "# customers_whole_ohe.to_csv('../data/customers_whole_ohe.csv', header = True, index = False)\n",
    "# # pd.read_csv('../data/customers_whole_ohe.csv')\n",
    "\n",
    "# customers_exposed_ohe.to_csv('../data/customers_exposed_ohe.csv', header = True, index = False)\n",
    "# # pd.read_csv('../data/customers_exposed_ohe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-principle",
   "metadata": {},
   "source": [
    "Both files have been saved! We will not need to load the `customers_whole_ohe.csv` into this notebook, but it is aways good to keep a standartd log of actions.\n",
    "\n",
    "**We will move forward with modelling for the `customers_whole` dataset hereafter.**\n",
    "\n",
    "Let's start:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-photography",
   "metadata": {},
   "source": [
    "### Splitting Data into _Train_, _Validation_ and _Test_ sets\n",
    "\n",
    "We will split the data according to the following schedule:\n",
    "\n",
    "- Create a `df_train` and a `df_test`.\n",
    "- From the previous `df_train` we will once again split it into two: `df_train` and `df_val`.\n",
    "\n",
    "We also know that _specially_ in this dataset (`_whole`) we have unballanced data. So we will perform a oversampling technique called SMOTE. According to the paper published in _The Journal of Artificial Intelligence Research_ in 2002:\n",
    "\n",
    "> [With SMOTE] The minority class is over-sampled by taking each minority class sample and introducing synthetic examples along the line segments joining any/all of the $k$ minority class nearest neighbors. Depending upon the amount of over-sampling required, neighbors from the k nearest neighbors are randomly chosen.[$^{SMOTE: \\: Synthetic\\:Minority\\:Over-sampling\\:Technique}$](https://arxiv.org/pdf/1106.1813.pdf)\n",
    "\n",
    "- Finally, we will separate all dfs into `X`'s and `y`, naming respectively accordint to the df they belong to.\n",
    "\n",
    "Let's start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "limited-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting df_train and df_test for training and testing\n",
    "df_train, df_test = train_test_split(customers_exposed, test_size = .2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "civil-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savint test set to a new csv file\n",
    "df_test.to_csv('../data/tests_sets/df_test_pure-customers_exposed.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rough-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting df_train into df_train and df_val\n",
    "df_train, df_val = train_test_split(df_train, test_size = .2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "primary-remains",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    212\n",
       "0    176\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking target variable balance (or imballance)\n",
    "df_train['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "every-doubt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    212\n",
       "1    212\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balancing target variable with SMOTE technique\n",
    "\n",
    "# Instantiating SMOTER over_sampler\n",
    "smote = SMOTE(random_state = 7)\n",
    "\n",
    "# Fitting and resampling data with SMOTE\n",
    "X_train, y_train = smote.fit_resample(df_train.drop('Response', axis = 1), df_train['Response'])\n",
    "\n",
    "# Checking target class balance\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "statutory-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_val.drop('Response', axis = 1)\n",
    "y_val = df_val['Response']\n",
    "\n",
    "X_test = df_test.drop('Response', axis = 1)\n",
    "y_test = df_test['Response']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-pharmacology",
   "metadata": {},
   "source": [
    "Let's check if the generated `X`'s and `y`'s are correctly built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "closed-shelter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, y_train   shapes:  (424, 31) (424,)\n",
      "X_val  , y_val     shapes:  (97, 31) (97,)\n",
      "X_test , y_test    shapes:  (122, 31) (122,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train, y_train   shapes: ', X_train.shape, y_train.shape)\n",
    "print('X_val  , y_val     shapes: ', X_val.shape, y_val.shape)\n",
    "print('X_test , y_test    shapes: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-publicity",
   "metadata": {},
   "source": [
    "**All shapes match**. We are good to go on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-reminder",
   "metadata": {},
   "source": [
    "### Analyzing multicolinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-maldives",
   "metadata": {},
   "source": [
    "In the previous notebooks, we have created new variables from pre-existing variables. Therefore we made room for possible multicolinearity.\n",
    "\n",
    "Some techniques for analyzing multicolinearity are:\n",
    "\n",
    "- Checking correlation values between variables;\n",
    "- Checking the Variance Inflation Factor (VIF) and dropping variables with factor $> 10$;\n",
    "- Performing Principal Component Analysis, to the cost of lesser interpretability;\n",
    "- Perform regularization such as (Lasso or Ridge) for linear models, such as Logistic Regression;\n",
    "\n",
    "For the sake of simplicity, let's go foward with `VIF` and drop variables with factor $ >10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "amino-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recovering X_train columns\n",
    "# X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "floating-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating numeric features in a list, except booleans\n",
    "numeric_features = [\n",
    "    'Education',\n",
    "    'Income',\n",
    "    'Kidhome',\n",
    "    'Teenhome',\n",
    "    'Recency',\n",
    "    'MntWines',\n",
    "    'MntFruits',\n",
    "    'MntMeatProducts',\n",
    "    'MntFishProducts',\n",
    "    'MntSweetProducts',\n",
    "    'MntGoldProds',\n",
    "    'NumDealsPurchases',\n",
    "    'NumWebPurchases',\n",
    "    'NumCatalogPurchases',\n",
    "    'NumStorePurchases',\n",
    "    'NumWebVisitsMonth',\n",
    "    'Complain',\n",
    "    'Family_Size',\n",
    "    'Income_PerCap',\n",
    "    'Total_Spent',\n",
    "    'Prop_Spending_Income_pc',\n",
    "    'Total_Puchases',\n",
    "    'Avg_Ticket',\n",
    "    'Age',\n",
    "    'Dt_Customer_InDays',\n",
    "    'Lives_Alone',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "committed-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of varibles for VIF analysis\n",
    "\n",
    "################################################################################################\n",
    "#   This cell has been iterated \"mannually\" after checking vif values in the dataframe below   #\n",
    "################################################################################################\n",
    "\n",
    "numeric_features_vif_ok = [\n",
    "#     'Education',\n",
    "#     'Income',\n",
    "#     'Kidhome',\n",
    "#     'Teenhome',\n",
    "    'Recency',\n",
    "#     'MntWines',\n",
    "#     'MntFruits',\n",
    "#     'MntMeatProducts',\n",
    "#     'MntFishProducts',\n",
    "#     'MntSweetProducts',\n",
    "#     'MntGoldProds',\n",
    "#     'NumDealsPurchases',\n",
    "#     'NumWebPurchases',\n",
    "#     'NumCatalogPurchases',\n",
    "#     'NumStorePurchases',\n",
    "#     'NumWebVisitsMonth',\n",
    "    'Complain',\n",
    "    'Family_Size',\n",
    "    'Income_PerCap',\n",
    "#     'Total_Spent',\n",
    "#     'Prop_Spending_Income_pc',\n",
    "#     'Total_Puchases',\n",
    "    'Avg_Ticket',\n",
    "#     'Age',\n",
    "    'Dt_Customer_InDays',\n",
    "    'Lives_Alone',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "wanted-shield",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vif_index</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.552680</td>\n",
       "      <td>Recency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.019633</td>\n",
       "      <td>Complain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.042938</td>\n",
       "      <td>Family_Size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.177922</td>\n",
       "      <td>Income_PerCap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.516791</td>\n",
       "      <td>Avg_Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.590459</td>\n",
       "      <td>Dt_Customer_InDays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.140468</td>\n",
       "      <td>Lives_Alone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vif_index             feature\n",
       "0   3.552680             Recency\n",
       "1   1.019633            Complain\n",
       "2   4.042938         Family_Size\n",
       "3   4.177922       Income_PerCap\n",
       "4   1.516791          Avg_Ticket\n",
       "5   3.590459  Dt_Customer_InDays\n",
       "6   2.140468         Lives_Alone"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe for storing vif and its respective variable\n",
    "vif_df = pd.DataFrame()\n",
    "\n",
    "# Calculating vif values and saving it into vif_index columns\n",
    "vif_df[\"vif_index\"] = [vif(X_train[numeric_features_vif_ok].values, i) \\\n",
    "                               for i in range(X_train[numeric_features_vif_ok].shape[1])]\n",
    "\n",
    "# Saving variable name into feature column\n",
    "vif_df[\"feature\"] = X_train[numeric_features_vif_ok].columns\n",
    "\n",
    "# Checking results\n",
    "vif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "incorrect-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing variables to be dropped due to high VIF\n",
    "to_drop_from_vif = [feature for feature in numeric_features if feature not in numeric_features_vif_ok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "single-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_drop_from_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-weekly",
   "metadata": {},
   "source": [
    "All `VIF` factor are now $\\le 10$, we can start dealing with the different orders of magnitude in our numeric features scaling them propperly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-advocacy",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "In order to have the numeric data in the same order of magnite, we will:\n",
    "\n",
    "- Use RobustScaler for variables with outliers;\n",
    "- Use StandardScaler for variables with no outliers;\n",
    "- Drop values outstands even after scaling.\n",
    "\n",
    "\n",
    "Let's start by listing features with outliers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-award",
   "metadata": {},
   "source": [
    "**Getting features with ouliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "quantitative-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing features names if feature has outlier\n",
    "to_robust_scale = []\n",
    "for feature in numeric_features:\n",
    "    \n",
    "    Q1 = np.percentile(X_train[feature].sort_values(), 25, interpolation = 'midpoint')  \n",
    "    Q3 = np.percentile(X_train[feature].sort_values(), 75, interpolation = 'midpoint')  \n",
    "\n",
    "    IQR = Q3 - Q1  \n",
    "    \n",
    "    low_lim = Q1 - 1.5 * IQR \n",
    "    up_lim = Q3 + 1.5 * IQR \n",
    "\n",
    "    if (X_train[feature] > up_lim).any() or (X_train[feature] < low_lim).any(): \n",
    "         to_robust_scale.append(feature)\n",
    "\n",
    "# View list of variables to scale with RobustScaler\n",
    "# to_robust_scale "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-college",
   "metadata": {},
   "source": [
    "And then, from the previous list, we can list the variables that will be standardized:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-thunder",
   "metadata": {},
   "source": [
    "**Listing features _without_ outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "organizational-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all other numeric features\n",
    "to_standardize = [feature for feature in numeric_features if feature not in to_robust_scale]\n",
    "\n",
    "# View list of variables to scale with StandScaler\n",
    "# to_standardize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-guyana",
   "metadata": {},
   "source": [
    "**Applying RobustScaler to variables listed in `to_robust_scale` list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "divine-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler()\n",
    "robust_scaler.fit(X_train[to_robust_scale])\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled[to_robust_scale] = robust_scaler.transform(X_train[to_robust_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-secret",
   "metadata": {},
   "source": [
    "**Applying StandardScaler to variables listed in `to_standardize` list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "inappropriate-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_scaler = StandardScaler()\n",
    "\n",
    "stand_scaler.fit(X_train[to_standardize])\n",
    "X_train_scaled[to_standardize] = stand_scaler.transform(X_train[to_standardize])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-geometry",
   "metadata": {},
   "source": [
    "Let's check the `X_train` dataset to see if everything went well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "extensive-belief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Income_PerCap</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Prop_Spending_Income_pc</th>\n",
       "      <th>Total_Puchases</th>\n",
       "      <th>Avg_Ticket</th>\n",
       "      <th>Age</th>\n",
       "      <th>Dt_Customer_InDays</th>\n",
       "      <th>Lives_Alone</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Together</th>\n",
       "      <th>Marital_Status_Widow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.0</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "      <td>424.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>-2.58</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-2.40</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.39</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.61</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.99</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.29</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.37</td>\n",
       "      <td>32.99</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Education  Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  \\\n",
       "count     424.00  424.00   424.00    424.00   424.00    424.00     424.00   \n",
       "mean        0.54    0.00     0.00      0.00     0.00      0.00       0.38   \n",
       "std         0.97    1.00     1.00      1.00     1.00      1.00       0.99   \n",
       "min        -2.00   -2.58    -0.66     -0.74    -1.57     -1.27      -0.39   \n",
       "25%         0.00   -0.85    -0.66     -0.74    -0.84     -0.93      -0.32   \n",
       "50%         0.00    0.12    -0.66     -0.74    -0.10     -0.08       0.00   \n",
       "75%         1.00    0.80     1.40      1.09     0.82      0.78       0.68   \n",
       "max         2.00    2.09     3.45      2.93     1.86      2.39       4.00   \n",
       "\n",
       "       MntMeatProducts  MntFishProducts  MntSweetProducts  MntGoldProds  \\\n",
       "count           424.00           424.00            424.00        424.00   \n",
       "mean              0.34             0.41              0.43          0.38   \n",
       "std               0.69             0.91              0.98          0.98   \n",
       "min              -0.30            -0.29             -0.32         -0.61   \n",
       "25%              -0.22            -0.25             -0.28         -0.28   \n",
       "50%               0.00             0.00              0.00          0.00   \n",
       "75%               0.78             0.75              0.72          0.72   \n",
       "max               3.63             3.41              3.87          3.61   \n",
       "\n",
       "       NumDealsPurchases  NumWebPurchases  NumCatalogPurchases  \\\n",
       "count             424.00           424.00               424.00   \n",
       "mean                0.59             0.00                -0.00   \n",
       "std                 0.95             1.00                 1.00   \n",
       "min                -0.50            -1.92                -1.36   \n",
       "25%                 0.00            -0.75                -1.02   \n",
       "50%                 0.00             0.02                 0.02   \n",
       "75%                 1.00             0.79                 0.71   \n",
       "max                 5.00             2.34                 2.43   \n",
       "\n",
       "       NumStorePurchases  NumWebVisitsMonth  Complain  Family_Size  \\\n",
       "count             424.00             424.00    424.00       424.00   \n",
       "mean                0.00              -0.21      0.00         0.35   \n",
       "std                 1.00               0.66      0.05         0.94   \n",
       "min                -1.95              -1.50      0.00        -1.00   \n",
       "25%                -0.74              -0.75      0.00         0.00   \n",
       "50%                -0.13               0.00      0.00         0.00   \n",
       "75%                 0.78               0.25      0.00         1.00   \n",
       "max                 1.99               3.50      1.00         3.00   \n",
       "\n",
       "       Income_PerCap  Total_Spent  Prop_Spending_Income_pc  Total_Puchases  \\\n",
       "count         424.00       424.00                   424.00          424.00   \n",
       "mean            0.23        -0.00                     0.10            0.00   \n",
       "std             0.86         1.00                     0.69            1.00   \n",
       "min            -0.94        -1.37                    -0.93           -2.40   \n",
       "25%            -0.46        -0.99                    -0.43           -0.67   \n",
       "50%             0.00         0.00                     0.00            0.20   \n",
       "75%             0.54         0.82                     0.57            0.64   \n",
       "max             2.76         2.29                     2.83            2.37   \n",
       "\n",
       "       Avg_Ticket     Age  Dt_Customer_InDays  Lives_Alone  \\\n",
       "count      424.00  424.00              424.00       424.00   \n",
       "mean         0.23   -0.00               -0.00        -0.00   \n",
       "std          1.78    1.00                1.00         1.00   \n",
       "min         -0.78   -2.33               -1.59        -0.78   \n",
       "25%         -0.46   -0.69               -0.88        -0.78   \n",
       "50%         -0.00   -0.08               -0.10        -0.78   \n",
       "75%          0.54    0.84                0.84         1.28   \n",
       "max         32.99    2.26                1.79         1.28   \n",
       "\n",
       "       Marital_Status_Divorced  Marital_Status_Married  Marital_Status_Single  \\\n",
       "count                    424.0                  424.00                 424.00   \n",
       "mean                       0.1                    0.33                   0.23   \n",
       "std                        0.3                    0.47                   0.42   \n",
       "min                        0.0                    0.00                   0.00   \n",
       "25%                        0.0                    0.00                   0.00   \n",
       "50%                        0.0                    0.00                   0.00   \n",
       "75%                        0.0                    1.00                   0.00   \n",
       "max                        1.0                    1.00                   1.00   \n",
       "\n",
       "       Marital_Status_Together  Marital_Status_Widow  \n",
       "count                   424.00                424.00  \n",
       "mean                      0.24                  0.04  \n",
       "std                       0.43                  0.20  \n",
       "min                       0.00                  0.00  \n",
       "25%                       0.00                  0.00  \n",
       "50%                       0.00                  0.00  \n",
       "75%                       0.00                  0.00  \n",
       "max                       1.00                  1.00  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking statistics from scaled DFs\n",
    "round(X_train_scaled.describe(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-hazard",
   "metadata": {},
   "source": [
    "The dataset almost alright alright. Some values are still outstanding and they might disturb distance based models. \n",
    "\n",
    "Let's drop these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ongoing-white",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Income_PerCap</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Prop_Spending_Income_pc</th>\n",
       "      <th>Total_Puchases</th>\n",
       "      <th>Avg_Ticket</th>\n",
       "      <th>Age</th>\n",
       "      <th>Dt_Customer_InDays</th>\n",
       "      <th>Lives_Alone</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Together</th>\n",
       "      <th>Marital_Status_Widow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.0</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "      <td>422.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>-2.58</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.39</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.61</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.99</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.29</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Education  Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  \\\n",
       "count     422.00  422.00   422.00    422.00   422.00    422.00     422.00   \n",
       "mean        0.55   -0.00     0.00      0.00    -0.00      0.00       0.38   \n",
       "std         0.97    1.00     1.00      1.00     1.00      1.00       0.99   \n",
       "min        -2.00   -2.58    -0.66     -0.74    -1.57     -1.27      -0.39   \n",
       "25%         0.00   -0.85    -0.66     -0.74    -0.84     -0.93      -0.32   \n",
       "50%         0.00    0.11    -0.66     -0.74    -0.12     -0.08       0.00   \n",
       "75%         1.00    0.81     1.40      1.09     0.82      0.78       0.67   \n",
       "max         2.00    2.09     3.45      2.93     1.86      2.39       4.00   \n",
       "\n",
       "       MntMeatProducts  MntFishProducts  MntSweetProducts  MntGoldProds  \\\n",
       "count           422.00           422.00            422.00        422.00   \n",
       "mean              0.32             0.41              0.42          0.38   \n",
       "std               0.66             0.90              0.97          0.98   \n",
       "min              -0.30            -0.29             -0.32         -0.61   \n",
       "25%              -0.22            -0.25             -0.28         -0.28   \n",
       "50%              -0.00             0.00              0.00          0.00   \n",
       "75%               0.78             0.75              0.71          0.72   \n",
       "max               2.10             3.41              3.87          3.61   \n",
       "\n",
       "       NumDealsPurchases  NumWebPurchases  NumCatalogPurchases  \\\n",
       "count             422.00           422.00               422.00   \n",
       "mean                0.60             0.01                 0.00   \n",
       "std                 0.95             1.00                 1.00   \n",
       "min                -0.50            -1.53                -1.36   \n",
       "25%                 0.00            -0.75                -1.02   \n",
       "50%                 0.00             0.02                 0.02   \n",
       "75%                 1.00             0.79                 0.71   \n",
       "max                 5.00             2.34                 2.43   \n",
       "\n",
       "       NumStorePurchases  NumWebVisitsMonth  Complain  Family_Size  \\\n",
       "count             422.00             422.00    422.00       422.00   \n",
       "mean                0.00              -0.21      0.00         0.35   \n",
       "std                 1.00               0.66      0.05         0.95   \n",
       "min                -1.95              -1.25      0.00        -1.00   \n",
       "25%                -0.74              -0.75      0.00         0.00   \n",
       "50%                -0.13               0.00      0.00         0.00   \n",
       "75%                 0.78               0.25      0.00         1.00   \n",
       "max                 1.99               3.50      1.00         3.00   \n",
       "\n",
       "       Income_PerCap  Total_Spent  Prop_Spending_Income_pc  Total_Puchases  \\\n",
       "count         422.00       422.00                   422.00          422.00   \n",
       "mean            0.23        -0.01                     0.10            0.01   \n",
       "std             0.86         1.00                     0.69            1.00   \n",
       "min            -0.94        -1.37                    -0.93           -2.26   \n",
       "25%            -0.46        -1.00                    -0.43           -0.67   \n",
       "50%            -0.02        -0.00                    -0.00            0.20   \n",
       "75%             0.54         0.81                     0.56            0.64   \n",
       "max             2.76         2.29                     2.83            2.37   \n",
       "\n",
       "       Avg_Ticket     Age  Dt_Customer_InDays  Lives_Alone  \\\n",
       "count      422.00  422.00              422.00       422.00   \n",
       "mean         0.13    0.00                0.00         0.00   \n",
       "std          0.65    1.00                1.00         1.00   \n",
       "min         -0.78   -2.33               -1.59        -0.78   \n",
       "25%         -0.46   -0.66               -0.87        -0.78   \n",
       "50%         -0.01   -0.08               -0.10        -0.78   \n",
       "75%          0.54    0.84                0.84         1.28   \n",
       "max          1.98    2.26                1.79         1.28   \n",
       "\n",
       "       Marital_Status_Divorced  Marital_Status_Married  Marital_Status_Single  \\\n",
       "count                    422.0                  422.00                 422.00   \n",
       "mean                       0.1                    0.33                   0.23   \n",
       "std                        0.3                    0.47                   0.42   \n",
       "min                        0.0                    0.00                   0.00   \n",
       "25%                        0.0                    0.00                   0.00   \n",
       "50%                        0.0                    0.00                   0.00   \n",
       "75%                        0.0                    1.00                   0.00   \n",
       "max                        1.0                    1.00                   1.00   \n",
       "\n",
       "       Marital_Status_Together  Marital_Status_Widow  \n",
       "count                   422.00                422.00  \n",
       "mean                      0.24                  0.04  \n",
       "std                       0.43                  0.20  \n",
       "min                       0.00                  0.00  \n",
       "25%                       0.00                  0.00  \n",
       "50%                       0.00                  0.00  \n",
       "75%                       0.00                  0.00  \n",
       "max                       1.00                  1.00  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_avg_ticket_to_drop = (X_train_scaled[X_train_scaled['Avg_Ticket'] > \\\n",
    "                                                 np.percentile(X_train_scaled['Avg_Ticket'], 99)].\\\n",
    "                          sort_values('Avg_Ticket', ascending = False).head(2)).index\n",
    "idx_avg_ticket_to_drop\n",
    "\n",
    "for df in [X_train, X_train_scaled, y_train]:\n",
    "    df.drop(idx_avg_ticket_to_drop, inplace = True)\n",
    "\n",
    "round(X_train_scaled.describe(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-treatment",
   "metadata": {},
   "source": [
    "Aiming to avoid **data leakage**, we've performed the `.fit` method using only the `X_train` dataset. We need now to `.transform` the values from `X_val` and `X_test` datasets so we can use them later to make predictions and evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "primary-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming x_val and x_test with scalers from X_train\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_val_scaled[to_robust_scale] = robust_scaler.transform(X_val[to_robust_scale])\n",
    "X_test_scaled[to_robust_scale] = robust_scaler.transform(X_test[to_robust_scale])\n",
    "\n",
    "X_val_scaled[to_standardize] = stand_scaler.transform(X_val[to_standardize])\n",
    "X_test_scaled[to_standardize] = stand_scaler.transform(X_test[to_standardize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "taken-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking transformed datasets\n",
    "# X_val.head() # Uncomment to view dataframes\n",
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hawaiian-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving all new dataframes and target variables to a new csv for posterior recover\n",
    "\n",
    "X_train.to_csv('../data/tests_sets/X_train-customers_exposed.csv', header = True, index = False)\n",
    "X_train_scaled.to_csv('../data/tests_sets/X_train_scaled-customers_exposed.csv', header = True, index = False)\n",
    "y_train.to_csv('../data/tests_sets/y_train-customers_exposed.csv', header = True, index = False)\n",
    "\n",
    "X_val.to_csv('../data/tests_sets/X_val-customers_exposed.csv', header = True, index = False)\n",
    "X_val_scaled.to_csv('../data/tests_sets/X_val_scaled-customers_exposed.csv', header = True, index = False)\n",
    "y_val.to_csv('../data/tests_sets/y_val-customers_exposed.csv', header = True, index = False)\n",
    "\n",
    "X_test.to_csv('../data/tests_sets/X_test-customers_exposed.csv', header = True, index = False)\n",
    "X_test_scaled.to_csv('../data/tests_sets/X_test_scaled-customers_exposed.csv', header = True, index = False)\n",
    "y_test.to_csv('../data/tests_sets/y_test-customers_exposed.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-warrant",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-offset",
   "metadata": {},
   "source": [
    "Befome moving foward to modelling. Let's identify what metrics is more likely to give us the best results.\n",
    "\n",
    "And for choogins a good metric, it is always important to callback our business problem:\n",
    "\n",
    ">**We want to correctly classify potential buyer for the company's new device, but there's a cost associated with advertising for customers who will never buy it in first place.**\n",
    "\n",
    "Having that in mind, let's list some of the most important metrics for classification problems:\n",
    "\n",
    "- **Accuracy**: the ratio of correct predictions. The model is not worried about how wrong it predicted. This might be a problem in a binary classification model that predicts only one class for unballanced data.\n",
    "- **Precision**: measures the ratio of correct predictions of a class. Can generate too many false alarms.\n",
    "- **Recall**: measures the ability to detect occurences of a class of interest. We could choose this metrics if we weren't concerned with the cost associated with predicting one class wrongly.\n",
    "- **F1-score**: the harmonic mean of precision and recall. Measures a model's ability to identify occurences of a class while limiting false alarms. This is a go-to metric!\n",
    "\n",
    "\n",
    "**F1-Score is the metric we are looking for to comply with our task and maximize profits from device sales.**\n",
    "\n",
    "Let's keep this metric in mind when analyzing the models, starting with a baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-ability",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-carroll",
   "metadata": {},
   "source": [
    "Let's start with a baseline model.\n",
    "\n",
    "A baseline model is a good pratice to determine if all sweat put into modelling with different algorithms and hyperparameter tuning is worth the effort.\n",
    "\n",
    "We can use a simple **Linear Regression**, not tunned, model as our baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-retailer",
   "metadata": {},
   "source": [
    "### Simple LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "known-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating the model\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "# Fitting the model\n",
    "log_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "clinical-teacher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71        39\n",
      "           1       0.81      0.79      0.80        58\n",
      "\n",
      "    accuracy                           0.76        97\n",
      "   macro avg       0.75      0.76      0.75        97\n",
      "weighted avg       0.76      0.76      0.76        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking classification report\n",
    "print(classification_report(y_val, log_model.predict(X_val_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-methodology",
   "metadata": {},
   "source": [
    "**We have pretty good metrics for our baseline model!** A lot better than previous results, when analyzing the whole dataset.\n",
    "\n",
    "Better be safe and cross validate our results. \n",
    "\n",
    "For that, we will be using the RandomSearchCV with empty `param_distribution` params. This will allow us to use the model object to `.fit` and `.predict` and therefore we will be able to produce a second `classification_report` that wouldn't be possible with Scikit-Learn `cross_validade`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "welsh-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating RandomizedSearchCV with empty param_distributions\n",
    "log_model_rsearch = RandomizedSearchCV(log_model, \n",
    "                                       param_distributions = {}, \n",
    "                                       cv = 10, \n",
    "                                       n_iter = 1, # Not useful when param_distributions is an empty dict\n",
    "                                       scoring = 'f1', \n",
    "                                       random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "competitive-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting baseline model\n",
    "log_model_rsearch.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Getting baseline model prediction\n",
    "y_val_pred = log_model_rsearch.predict(X_val_scaled)\n",
    "# y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "alert-syracuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71        39\n",
      "           1       0.81      0.79      0.80        58\n",
      "\n",
      "    accuracy                           0.76        97\n",
      "   macro avg       0.75      0.76      0.75        97\n",
      "weighted avg       0.76      0.76      0.76        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating metrics with Skelearn Classification Report\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-plumbing",
   "metadata": {},
   "source": [
    "Results remain robusts even after cross validation.\n",
    "\n",
    "Too good to be true? Let's analyze it even further with a `AUC` curve and a `confusion_matrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "modified-utilization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting AUC and Confusion Matrix side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 4))\n",
    "\n",
    "# AUC Plot\n",
    "plot_roc_curve(log_model, X_val_scaled, y_val, ax = ax[0])\n",
    "\n",
    "# Confusion Matrix\n",
    "plot_confusion_matrix(log_model, X_val_scaled, y_val, cmap=plt.cm.Reds, ax = ax[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-glass",
   "metadata": {},
   "source": [
    "### Keeping metrics logs in MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-flexibility",
   "metadata": {},
   "source": [
    "Data science is an interative process. In order to keep track of performance metrics, let's instantiate a MLFlow Client.\n",
    "\n",
    "MLFlow will free us to modify and test unlimitedly while not fearing to lose our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "seeing-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Naming Experiment\n",
    "EXPERIMENT_NAME = '[v4.8] [customers_exposed] [Consumer Behavior Analytics] [Renan Moises]'\n",
    "\n",
    "# Instantiating MLFlow Client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Saving experiment with experiment_id variable\n",
    "experiment_id = client.create_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "timely-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining metrics to keep track of. We will discuss them later.\n",
    "metrics_names = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "metrics = [accuracy_score, precision_score, recall_score, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "suspected-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a run for MlFlow Client\n",
    "run = client.create_run(experiment_id)\n",
    "\n",
    "# Logging params: Model Name\n",
    "client.log_param(run.info.run_id, 'model', 'LogistRegression-Baseline')\n",
    "\n",
    "# Iteration over metrics and logging them\n",
    "for metric in zip(metrics_names, metrics):\n",
    "    client.log_metric(run.info.run_id, metric[0], metric[1](y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "occasional-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving baseline model into a pickle file\n",
    "with open(f\"../models/v2_pkl_cexposed_Logistic_Regression-Baseline.pkl\", \"wb\") as file:\n",
    "    pickle.dump(log_model_rsearch, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-desktop",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "Some of the most known classification algorithms are:\n",
    "\n",
    "- **LogisticRegression**;\n",
    "- **KNNClassifier**;\n",
    "- **SVC (Support Vector Classifier)**;\n",
    "- **RFClassifier**;\n",
    "- **AdaBoostClassifier**;\n",
    "- **GradientBoostClassifier**;\n",
    "- **XGBoostClassifier**.\n",
    "\n",
    "\n",
    "Apart from these ones (and many others) there's still the possibility of _stacking_ two or more modules as well as combining them into a _voting_ classifier, but we will be leavig these ones for the next steps of this analysis, after approval of the CMO.\n",
    "\n",
    "For now, we will go with the \"basic\" ones listed above and for that, we will go semi-automatic: first creating a dictionary with model names and models, so that we can iterate over it, and then, well... effectively iterate over it with a `for` loop.\n",
    "\n",
    "<small>_NOTE_: Ideally, this would have been built within a `pipeline` and called with `python classes`. That implementation, altough very important in terms of machine learning engineering, will be left for the future though.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "unauthorized-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of model_keys and model_values (the algorithms, instantiated)\n",
    "models = {\n",
    "    'LogisticRegression-Tunned': LogisticRegression(),\n",
    "    'KNNClassifier': KNeighborsClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'XGboostClassifier': XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "related-mouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression-Tunned ####################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62        39\n",
      "           1       0.75      0.76      0.75        58\n",
      "\n",
      "    accuracy                           0.70        97\n",
      "   macro avg       0.69      0.69      0.69        97\n",
      "weighted avg       0.70      0.70      0.70        97\n",
      " \n",
      "\n",
      "KNNClassifier ################################################\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.54      0.57        39\n",
      "           1       0.71      0.76      0.73        58\n",
      "\n",
      "    accuracy                           0.67        97\n",
      "   macro avg       0.65      0.65      0.65        97\n",
      "weighted avg       0.67      0.67      0.67        97\n",
      " \n",
      "\n",
      "SVC ##########################################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63        39\n",
      "           1       0.75      0.78      0.76        58\n",
      "\n",
      "    accuracy                           0.71        97\n",
      "   macro avg       0.70      0.70      0.70        97\n",
      "weighted avg       0.71      0.71      0.71        97\n",
      " \n",
      "\n",
      "RandomForestClassifier #######################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.68        39\n",
      "           1       0.78      0.79      0.79        58\n",
      "\n",
      "    accuracy                           0.74        97\n",
      "   macro avg       0.73      0.73      0.73        97\n",
      "weighted avg       0.74      0.74      0.74        97\n",
      " \n",
      "\n",
      "AdaBoostClassifier ###########################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.54      0.59        39\n",
      "           1       0.72      0.81      0.76        58\n",
      "\n",
      "    accuracy                           0.70        97\n",
      "   macro avg       0.69      0.67      0.68        97\n",
      "weighted avg       0.70      0.70      0.69        97\n",
      " \n",
      "\n",
      "GradientBoostingClassifier ###################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72        39\n",
      "           1       0.86      0.66      0.75        58\n",
      "\n",
      "    accuracy                           0.73        97\n",
      "   macro avg       0.74      0.75      0.73        97\n",
      "weighted avg       0.77      0.73      0.73        97\n",
      " \n",
      "\n",
      "XGboostClassifier ############################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "[22:53:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.79      0.72        39\n",
      "           1       0.84      0.72      0.78        58\n",
      "\n",
      "    accuracy                           0.75        97\n",
      "   macro avg       0.75      0.76      0.75        97\n",
      "weighted avg       0.77      0.75      0.75        97\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Big long mannually interative for loop (Not ideal, but code works just fine!)\n",
    "for model_key, model_value in models.items():\n",
    "#     X_train_modelling = X_train.copy().drop(to_drop_from_vif, axis = 1)\n",
    "#     X_val_modelling = X_val.copy().drop(to_drop_from_vif, axis = 1)\n",
    "    \n",
    "    X_train_modelling = X_train.copy()\n",
    "    X_val_modelling = X_val.copy()\n",
    "\n",
    "    \n",
    "    if model_key == 'LogisticRegression-Tunned':\n",
    "        # Dropping Multicolinear Features for Logistic Regression\n",
    "        X_train_modelling = X_train_scaled.drop(to_drop_from_vif, axis = 1)\n",
    "        X_val_modelling = X_val_scaled.drop(to_drop_from_vif, axis = 1)\n",
    "        \n",
    "        param_grid = {\n",
    "            'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "            'tol': stats.loguniform(0.1, 1),\n",
    "            'C': stats.loguniform(3, 10)\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'KNNClassifier':\n",
    "        # Dropping Multicolinear Features for KNNClassifier\n",
    "        X_train_modelling = X_train_scaled.drop(to_drop_from_vif, axis = 1)\n",
    "        X_val_modelling = X_val_scaled.drop(to_drop_from_vif, axis = 1)\n",
    "        \n",
    "        param_grid = {'n_neighbors':[3, 4, 5, 6, 7]}\n",
    "    \n",
    "    elif model_key == 'SVC':\n",
    "        # Dropping Multicolinear Features for SVC\n",
    "        X_train_modelling = X_train_scaled.drop(to_drop_from_vif, axis = 1)\n",
    "        X_val_modelling = X_val_scaled.drop(to_drop_from_vif, axis = 1)\n",
    "        \n",
    "        param_grid = {\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'C': stats.loguniform(3, 20)\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'RandomForestClassifier':\n",
    "        param_grid = {\n",
    "            'n_estimators': np.array([50, 60, 70, 80, 90, 100, 120, 150, 200, 400], dtype = int),\n",
    "            'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "            'max_features': ['auto', 'sqrt'],\n",
    "            'min_samples_split': np.arange(0, 10),\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'bootstrap': [True, False],\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'AdaBoostClassifier':\n",
    "        param_grid = {\n",
    "            'n_estimators': np.array([50, 60, 70, 80, 90, 100, 120, 150, 200, 400], dtype = int),\n",
    "            'learning_rate': stats.lognorm(.001, 1)\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'GradientBoostingClassifier':\n",
    "        param_grid = {\n",
    "            'n_estimators': np.array([50, 60, 70, 80, 90, 100, 120, 150, 200, 400], dtype = int),\n",
    "            'learning_rate': stats.lognorm(.001, 1),\n",
    "            'min_samples_split': np.arange(0, 10),\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_depth': np.arange(0, 10)\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        param_grid = {\n",
    "            'n_estimators': np.array([50, 60, 70, 80, 90, 100, 120, 150, 200, 400], dtype = int),\n",
    "            'learning_rate': stats.loguniform(.001, 1),            \n",
    "            'max_depth': np.arange(0, 10),\n",
    "            'gamma': stats.loguniform(.001, 1),\n",
    "        }   \n",
    "    \n",
    "    \n",
    "    # Running RandomizedSearchCV\n",
    "    print(model_key, '#'.replace('#', '#'*(61 - len(model_key))))\n",
    "    model_rsearch = RandomizedSearchCV(model_value, \n",
    "                                       param_distributions = param_grid, \n",
    "                                       n_iter = 50, \n",
    "                                       scoring = 'f1', # Used to update weights\n",
    "                                       cv = 10, \n",
    "                                       n_jobs = -1, \n",
    "                                       verbose = 1,\n",
    "                                       random_state = 7)\n",
    "    \n",
    "    # Fitting the model to the train data\n",
    "    model_rsearch.fit(X_train_modelling, y_train)\n",
    "    \n",
    "    # Saving model as a joblib file\n",
    "#     joblib.dump(model_rsearch, f'../models/cexposed_{model_key}.pkl')\n",
    "    with open(f\"../models/v2_pkl_cexposed_{model_key}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model_rsearch, file)\n",
    "\n",
    "    \n",
    "    # Predictions using X_val\n",
    "    y_val_pred = model_rsearch.predict(X_val_modelling)\n",
    "    \n",
    "    # Setting up metrics\n",
    "    metrics_names = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    metrics = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "    \n",
    "    # MLFlow Logs\n",
    "    run = client.create_run(experiment_id)\n",
    "    for metric_name, metric in zip(metrics_names, metrics):\n",
    "        client.log_metric(run.info.run_id, metric_name, metric(y_val, y_val_pred))\n",
    "    client.log_param(run.info.run_id, \"model\", model_key)\n",
    "    client.log_param(run.info.run_id, \"params\", model_value.get_params())\n",
    "    client.log_param(run.info.run_id, \"features\", X_train_modelling.columns.tolist())\n",
    "\n",
    "    \n",
    "    print(classification_report(y_val, y_val_pred), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-magic",
   "metadata": {},
   "source": [
    "### Best overall model\n",
    "\n",
    "Analyzing the previous `classification_report`'s, the best overall model still is our **baseline Logistic Regression model**.\n",
    "\n",
    "The second best was XGBoost. For the sake of simplicity we will move forward analyzing only the very best, the Logistic Regression.\n",
    "\n",
    "Gone are the days that we would analyze the whole dataset. We've just confirmed that more important than tunning the models, working upon a dataset with only customers' who been guaranteedly exposed to the marketing campaign is very effective.\n",
    "\n",
    "Since all models (and datasets) have been dully saved into its respective files, we can continue the **best model and interpretability** analysis in a new notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-batman",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "academic-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# DRAFTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "proved-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model_fromfor = joblib.load('../models/v2_pkl_cexposed_RandomForestClassifier.pkl')\n",
    "# params = rf_model_fromfor.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled.rename(columns={'Education_2n Cycle': 'Education_2n_Cycle'}, inplace = True)\n",
    "# X_val_scaled.rename(columns={'Education_2n Cycle': 'Education_2n_Cycle'}, inplace = True)\n",
    "# X_test_scaled.rename(columns={'Education_2n Cycle': 'Education_2n_Cycle'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting_model = VotingClassifier(estimators = [('log_model', LogisticRegression()),\n",
    "#                                               ('rfc_model', RandomForestClassifier(**params))],\n",
    "#                                 voting = 'hard', weights = [1.2, .8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting_model.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, voting_model.predict(X_test_scaled)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
