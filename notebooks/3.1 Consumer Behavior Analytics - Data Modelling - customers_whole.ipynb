{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dying-james",
   "metadata": {},
   "source": [
    "# Consumer Behavior Analytics - Data Modelling  of `customers_whole`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-webcam",
   "metadata": {},
   "source": [
    "**Libraries and imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "visible-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic DS libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# DataViz libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistics Libraries\n",
    "from scipy import stats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "# Data Utils\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, \\\n",
    "                                                                     recall_score, \\\n",
    "                                                                     precision_score, \\\n",
    "                                                                     accuracy_score, \\\n",
    "                                                                     roc_auc_score, \\\n",
    "                                                                     auc, \\\n",
    "                                                                     plot_confusion_matrix, \\\n",
    "                                                                     plot_roc_curve\n",
    "                                                                         \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Notebook setup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occupied-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading customers exposed\n",
    "customers_exposed = pd.read_csv('../data/customers_exposed.csv', parse_dates = ['Dt_Customer'])\n",
    "\n",
    "# Loading customers whole\n",
    "customers_whole = pd.read_csv('../data/customers_whole.csv', parse_dates = ['Dt_Customer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "residential-colleague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Response</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Income_PerCap</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Prop_Spending_Income_pc</th>\n",
       "      <th>Total_Puchases</th>\n",
       "      <th>Avg_Ticket</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5524</td>\n",
       "      <td>1957</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>88</td>\n",
       "      <td>546</td>\n",
       "      <td>172</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>1617</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>25</td>\n",
       "      <td>64.68</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174</td>\n",
       "      <td>1954</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15448.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>6</td>\n",
       "      <td>4.50</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4141</td>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-21</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>49</td>\n",
       "      <td>127</td>\n",
       "      <td>111</td>\n",
       "      <td>21</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35806.5</td>\n",
       "      <td>776</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>21</td>\n",
       "      <td>36.95</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6182</td>\n",
       "      <td>1984</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-10</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8882.0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.005967</td>\n",
       "      <td>8</td>\n",
       "      <td>6.62</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5324</td>\n",
       "      <td>1981</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-19</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>46</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19431.0</td>\n",
       "      <td>422</td>\n",
       "      <td>0.021718</td>\n",
       "      <td>19</td>\n",
       "      <td>22.21</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
       "0  5524        1957  Graduation         Single  58138.0        0         0   \n",
       "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
       "2  4141        1965  Graduation       Together  71613.0        0         0   \n",
       "3  6182        1984  Graduation       Together  26646.0        1         0   \n",
       "4  5324        1981         PhD        Married  58293.0        1         0   \n",
       "\n",
       "  Dt_Customer  Recency  MntWines  MntFruits  MntMeatProducts  MntFishProducts  \\\n",
       "0  2012-09-04       58       635         88              546              172   \n",
       "1  2014-03-08       38        11          1                6                2   \n",
       "2  2013-08-21       26       426         49              127              111   \n",
       "3  2014-02-10       26        11          4               20               10   \n",
       "4  2014-01-19       94       173         43              118               46   \n",
       "\n",
       "   MntSweetProducts  MntGoldProds  NumDealsPurchases  NumWebPurchases  \\\n",
       "0                88            88                  3                8   \n",
       "1                 1             6                  2                1   \n",
       "2                21            42                  1                8   \n",
       "3                 3             5                  2                2   \n",
       "4                27            15                  5                5   \n",
       "\n",
       "   NumCatalogPurchases  NumStorePurchases  NumWebVisitsMonth  AcceptedCmp3  \\\n",
       "0                   10                  4                  7             0   \n",
       "1                    1                  2                  5             0   \n",
       "2                    2                 10                  4             0   \n",
       "3                    0                  4                  6             0   \n",
       "4                    3                  6                  5             0   \n",
       "\n",
       "   AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  Response  \\\n",
       "0             0             0             0             0         0         1   \n",
       "1             0             0             0             0         0         0   \n",
       "2             0             0             0             0         0         0   \n",
       "3             0             0             0             0         0         0   \n",
       "4             0             0             0             0         0         0   \n",
       "\n",
       "   Family_Size  Income_PerCap  Total_Spent  Prop_Spending_Income_pc  \\\n",
       "0            1        58138.0         1617                 0.027813   \n",
       "1            3        15448.0           27                 0.001748   \n",
       "2            2        35806.5          776                 0.021672   \n",
       "3            3         8882.0           53                 0.005967   \n",
       "4            3        19431.0          422                 0.021718   \n",
       "\n",
       "   Total_Puchases  Avg_Ticket  Age  \n",
       "0              25       64.68   57  \n",
       "1               6        4.50   60  \n",
       "2              21       36.95   49  \n",
       "3               8        6.62   30  \n",
       "4              19       22.21   33  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "distinguished-murder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.850873\n",
       "1    0.149127\n",
       "Name: Response, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking class balance (or imballance)\n",
    "customers_whole['Response'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-escape",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-cardiff",
   "metadata": {},
   "source": [
    "We are going to start preparing the data for modelling regarding both datasets: `customers_whole` and `customers_exposed`, but only until One Hot Encoding.\n",
    "\n",
    "After that, we will save both one hot encoded dataframes into new csv files and split both analysis in different notebooks. The analysis in this notebook will be for `customers_whole` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "light-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Sample first_date\n",
    "first_date = customers_whole['Dt_Customer'].min()\n",
    "\n",
    "# Transforming datetime feature to numeric feature\n",
    "for df in [customers_exposed, customers_whole]:\n",
    "    df['Dt_Customer_InDays'] = df['Dt_Customer'] - first_date\n",
    "    \n",
    "    df['Dt_Customer_InDays'] = (df['Dt_Customer_InDays'] / np.timedelta64(1, 'D')).astype(int) + 1\n",
    "    \n",
    "    # Dropping unuseful columns for modelling\n",
    "    df.drop(['ID', 'Dt_Customer'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "second-postcard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graduation    1126\n",
       "PhD            483\n",
       "Master         369\n",
       "2n Cycle       201\n",
       "Basic           54\n",
       "Name: Education, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_whole['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "distinct-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Education Variable\n",
    "# customers_whole['Education'] = customers_whole['Education'].map({'Basic': 1,\n",
    "#                                                                  '2n Cycle': 2,\n",
    "#                                                                  'Graduation': 3,\n",
    "#                                                                  'Master': 4, \n",
    "#                                                                  'PhD': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affiliated-atmosphere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Response</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Income_PerCap</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Prop_Spending_Income_pc</th>\n",
       "      <th>Total_Puchases</th>\n",
       "      <th>Avg_Ticket</th>\n",
       "      <th>Age</th>\n",
       "      <th>Dt_Customer_InDays</th>\n",
       "      <th>Education_2n Cycle</th>\n",
       "      <th>Education_Basic</th>\n",
       "      <th>Education_Graduation</th>\n",
       "      <th>Education_Master</th>\n",
       "      <th>Education_PhD</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Together</th>\n",
       "      <th>Marital_Status_Widow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1957</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>88</td>\n",
       "      <td>546</td>\n",
       "      <td>172</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58138.00</td>\n",
       "      <td>1617</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>25</td>\n",
       "      <td>64.68</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1954</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15448.00</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>6</td>\n",
       "      <td>4.50</td>\n",
       "      <td>60</td>\n",
       "      <td>587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1965</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>49</td>\n",
       "      <td>127</td>\n",
       "      <td>111</td>\n",
       "      <td>21</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35806.50</td>\n",
       "      <td>776</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>21</td>\n",
       "      <td>36.95</td>\n",
       "      <td>49</td>\n",
       "      <td>388</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8882.00</td>\n",
       "      <td>53</td>\n",
       "      <td>0.005967</td>\n",
       "      <td>8</td>\n",
       "      <td>6.62</td>\n",
       "      <td>30</td>\n",
       "      <td>561</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>46</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19431.00</td>\n",
       "      <td>422</td>\n",
       "      <td>0.021718</td>\n",
       "      <td>19</td>\n",
       "      <td>22.21</td>\n",
       "      <td>33</td>\n",
       "      <td>539</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>1967</td>\n",
       "      <td>61223.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>709</td>\n",
       "      <td>43</td>\n",
       "      <td>182</td>\n",
       "      <td>42</td>\n",
       "      <td>118</td>\n",
       "      <td>247</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20407.67</td>\n",
       "      <td>1341</td>\n",
       "      <td>0.065711</td>\n",
       "      <td>18</td>\n",
       "      <td>74.50</td>\n",
       "      <td>47</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>1946</td>\n",
       "      <td>64014.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>406</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12802.80</td>\n",
       "      <td>444</td>\n",
       "      <td>0.034680</td>\n",
       "      <td>22</td>\n",
       "      <td>20.18</td>\n",
       "      <td>68</td>\n",
       "      <td>681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>1981</td>\n",
       "      <td>56981.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>908</td>\n",
       "      <td>48</td>\n",
       "      <td>217</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56981.00</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.021779</td>\n",
       "      <td>19</td>\n",
       "      <td>65.32</td>\n",
       "      <td>33</td>\n",
       "      <td>545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>1956</td>\n",
       "      <td>69245.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>428</td>\n",
       "      <td>30</td>\n",
       "      <td>214</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23081.67</td>\n",
       "      <td>843</td>\n",
       "      <td>0.036522</td>\n",
       "      <td>23</td>\n",
       "      <td>36.65</td>\n",
       "      <td>58</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>1954</td>\n",
       "      <td>52869.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13217.25</td>\n",
       "      <td>172</td>\n",
       "      <td>0.013013</td>\n",
       "      <td>11</td>\n",
       "      <td>15.64</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2233 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year_Birth   Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  \\\n",
       "0           1957  58138.0        0         0       58       635         88   \n",
       "1           1954  46344.0        1         1       38        11          1   \n",
       "2           1965  71613.0        0         0       26       426         49   \n",
       "3           1984  26646.0        1         0       26        11          4   \n",
       "4           1981  58293.0        1         0       94       173         43   \n",
       "...          ...      ...      ...       ...      ...       ...        ...   \n",
       "2228        1967  61223.0        0         1       46       709         43   \n",
       "2229        1946  64014.0        2         1       56       406          0   \n",
       "2230        1981  56981.0        0         0       91       908         48   \n",
       "2231        1956  69245.0        0         1        8       428         30   \n",
       "2232        1954  52869.0        1         1       40        84          3   \n",
       "\n",
       "      MntMeatProducts  MntFishProducts  MntSweetProducts  MntGoldProds  \\\n",
       "0                 546              172                88            88   \n",
       "1                   6                2                 1             6   \n",
       "2                 127              111                21            42   \n",
       "3                  20               10                 3             5   \n",
       "4                 118               46                27            15   \n",
       "...               ...              ...               ...           ...   \n",
       "2228              182               42               118           247   \n",
       "2229               30                0                 0             8   \n",
       "2230              217               32                12            24   \n",
       "2231              214               80                30            61   \n",
       "2232               61                2                 1            21   \n",
       "\n",
       "      NumDealsPurchases  NumWebPurchases  NumCatalogPurchases  \\\n",
       "0                     3                8                   10   \n",
       "1                     2                1                    1   \n",
       "2                     1                8                    2   \n",
       "3                     2                2                    0   \n",
       "4                     5                5                    3   \n",
       "...                 ...              ...                  ...   \n",
       "2228                  2                9                    3   \n",
       "2229                  7                8                    2   \n",
       "2230                  1                2                    3   \n",
       "2231                  2                6                    5   \n",
       "2232                  3                3                    1   \n",
       "\n",
       "      NumStorePurchases  NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  \\\n",
       "0                     4                  7             0             0   \n",
       "1                     2                  5             0             0   \n",
       "2                    10                  4             0             0   \n",
       "3                     4                  6             0             0   \n",
       "4                     6                  5             0             0   \n",
       "...                 ...                ...           ...           ...   \n",
       "2228                  4                  5             0             0   \n",
       "2229                  5                  7             0             0   \n",
       "2230                 13                  6             0             1   \n",
       "2231                 10                  3             0             0   \n",
       "2232                  4                  7             0             0   \n",
       "\n",
       "      AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  Response  \\\n",
       "0                0             0             0         0         1   \n",
       "1                0             0             0         0         0   \n",
       "2                0             0             0         0         0   \n",
       "3                0             0             0         0         0   \n",
       "4                0             0             0         0         0   \n",
       "...            ...           ...           ...       ...       ...   \n",
       "2228             0             0             0         0         0   \n",
       "2229             0             1             0         0         0   \n",
       "2230             0             0             0         0         0   \n",
       "2231             0             0             0         0         0   \n",
       "2232             0             0             0         0         1   \n",
       "\n",
       "      Family_Size  Income_PerCap  Total_Spent  Prop_Spending_Income_pc  \\\n",
       "0               1       58138.00         1617                 0.027813   \n",
       "1               3       15448.00           27                 0.001748   \n",
       "2               2       35806.50          776                 0.021672   \n",
       "3               3        8882.00           53                 0.005967   \n",
       "4               3       19431.00          422                 0.021718   \n",
       "...           ...            ...          ...                      ...   \n",
       "2228            3       20407.67         1341                 0.065711   \n",
       "2229            5       12802.80          444                 0.034680   \n",
       "2230            1       56981.00         1241                 0.021779   \n",
       "2231            3       23081.67          843                 0.036522   \n",
       "2232            4       13217.25          172                 0.013013   \n",
       "\n",
       "      Total_Puchases  Avg_Ticket  Age  Dt_Customer_InDays  Education_2n Cycle  \\\n",
       "0                 25       64.68   57                  37                   0   \n",
       "1                  6        4.50   60                 587                   0   \n",
       "2                 21       36.95   49                 388                   0   \n",
       "3                  8        6.62   30                 561                   0   \n",
       "4                 19       22.21   33                 539                   0   \n",
       "...              ...         ...  ...                 ...                 ...   \n",
       "2228              18       74.50   47                 319                   0   \n",
       "2229              22       20.18   68                 681                   0   \n",
       "2230              19       65.32   33                 545                   0   \n",
       "2231              23       36.65   58                 544                   0   \n",
       "2232              11       15.64   60                  78                   0   \n",
       "\n",
       "      Education_Basic  Education_Graduation  Education_Master  Education_PhD  \\\n",
       "0                   0                     1                 0              0   \n",
       "1                   0                     1                 0              0   \n",
       "2                   0                     1                 0              0   \n",
       "3                   0                     1                 0              0   \n",
       "4                   0                     0                 0              1   \n",
       "...               ...                   ...               ...            ...   \n",
       "2228                0                     1                 0              0   \n",
       "2229                0                     0                 0              1   \n",
       "2230                0                     1                 0              0   \n",
       "2231                0                     0                 1              0   \n",
       "2232                0                     0                 0              1   \n",
       "\n",
       "      Marital_Status_Divorced  Marital_Status_Married  Marital_Status_Single  \\\n",
       "0                           0                       0                      1   \n",
       "1                           0                       0                      1   \n",
       "2                           0                       0                      0   \n",
       "3                           0                       0                      0   \n",
       "4                           0                       1                      0   \n",
       "...                       ...                     ...                    ...   \n",
       "2228                        0                       1                      0   \n",
       "2229                        0                       0                      0   \n",
       "2230                        1                       0                      0   \n",
       "2231                        0                       0                      0   \n",
       "2232                        0                       1                      0   \n",
       "\n",
       "      Marital_Status_Together  Marital_Status_Widow  \n",
       "0                           0                     0  \n",
       "1                           0                     0  \n",
       "2                           1                     0  \n",
       "3                           1                     0  \n",
       "4                           0                     0  \n",
       "...                       ...                   ...  \n",
       "2228                        0                     0  \n",
       "2229                        1                     0  \n",
       "2230                        0                     0  \n",
       "2231                        1                     0  \n",
       "2232                        0                     0  \n",
       "\n",
       "[2233 rows x 41 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot Encoding categorical feature 'Marital_Status' with pd.get_dummies\n",
    "customers_exposed_ohe = pd.get_dummies(customers_exposed)\n",
    "customers_whole_ohe = pd.get_dummies(customers_whole)\n",
    "\n",
    "customers_whole_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "august-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving One Hot Enconded files into a new csv file\n",
    "customers_whole_ohe.to_csv('../data/customers_whole_ohe.csv', header = True, index = False)\n",
    "# pd.read_csv('../data/customers_whole_ohe.csv')\n",
    "\n",
    "customers_exposed_ohe.to_csv('../data/customers_exposed_ohe.csv', header = True, index = False)\n",
    "# pd.read_csv('../data/customers_exposed_ohe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-tribune",
   "metadata": {},
   "source": [
    "Both files have been saved! We will not need to load the `customers_whole_ohe.csv` into this notebook, but it is aways good to keep a standartd log of actions.\n",
    "\n",
    "**We will move forward with modelling for the `customers_whole` dataset hereafter.**\n",
    "\n",
    "Let's start:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-billion",
   "metadata": {},
   "source": [
    "### Splitting Data into _Train_, _Validation_ and _Test_ sets\n",
    "\n",
    "We will split the data according to the following schedule:\n",
    "\n",
    "- Create a `df_train` and a `df_test`.\n",
    "- From the previous `df_train` we will once again split it into two: `df_train` and `df_val`.\n",
    "\n",
    "We also know that _specially_ in this dataset (`_whole`) we have unballanced data. So we will perform a oversampling technique called SMOTE. According to the paper published in _The Journal of Artificial Intelligence Research_ in 2002:\n",
    "\n",
    "> [With SMOTE] The minority class is over-sampled by taking each minority class sample and introducing synthetic examples along the line segments joining any/all of the $k$ minority class nearest neighbors. Depending upon the amount of over-sampling required, neighbors from the k nearest neighbors are randomly chosen.[$^{SMOTE: \\: Synthetic\\:Minority\\:Over-sampling\\:Technique}$](https://arxiv.org/pdf/1106.1813.pdf)\n",
    "\n",
    "- Finally, we will separate all dfs into `X`'s and `y`, naming respectively accordint to the df they belong to.\n",
    "\n",
    "Let's start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "certified-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting df_train and df_test for training and testing\n",
    "df_train, df_test = train_test_split(customers_whole_ohe, test_size = .2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accepted-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting df_train into df_train and df_val\n",
    "df_train, df_val = train_test_split(df_train, test_size = .2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "miniature-replacement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1217\n",
       "1     211\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking target variable balance (or imballance)\n",
    "df_train['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "surface-native",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1217\n",
       "1    1217\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balancing target variable with SMOTE technique\n",
    "\n",
    "# Instantiating SMOTER over_sampler\n",
    "smote = SMOTE(random_state = 7)\n",
    "\n",
    "# Fitting and resampling data with SMOTE\n",
    "X_train, y_train = smote.fit_resample(df_train.drop('Response', axis = 1), df_train['Response'])\n",
    "\n",
    "# Checking target class balance\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pressed-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_val.drop('Response', axis = 1)\n",
    "y_val = df_val['Response']\n",
    "\n",
    "X_test = df_test.drop('Response', axis = 1)\n",
    "y_test = df_test['Response']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-strength",
   "metadata": {},
   "source": [
    "Let's check if the generated `X`'s and `y`'s are correctly built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dimensional-senate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, y_train   shapes:  (2434, 40) (2434,)\n",
      "X_val  , y_val     shapes:  (358, 40) (358,)\n",
      "X_test , y_test    shapes:  (447, 40) (447,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train, y_train   shapes: ', X_train.shape, y_train.shape)\n",
    "print('X_val  , y_val     shapes: ', X_val.shape, y_val.shape)\n",
    "print('X_test , y_test    shapes: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-chicken",
   "metadata": {},
   "source": [
    "**All shapes match**. We are good to go on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-canberra",
   "metadata": {},
   "source": [
    "### Analyzing multicolinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-trick",
   "metadata": {},
   "source": [
    "In the previous notebooks, we have created new variables from pre-existing variables. Therefore we made room for possible multicolinearity.\n",
    "\n",
    "Some techniques for analyzing multicolinearity are:\n",
    "\n",
    "- Checking correlation values between variables;\n",
    "- Checking the Variance Inflation Factor (VIF) and dropping variables with factor $> 10$;\n",
    "- Performing Principal Component Analysis, to the cost of lesser interpretability;\n",
    "- Perform regularization such as (Lasso or Ridge) for linear models, such as Logistic Regression;\n",
    "\n",
    "For the sake of simplicity, let's go foward with `VIF` and drop variables with factor $ >10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "according-howard",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines',\n",
       "       'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
       "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
       "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
       "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
       "       'AcceptedCmp2', 'Complain', 'Family_Size', 'Income_PerCap',\n",
       "       'Total_Spent', 'Prop_Spending_Income_pc', 'Total_Puchases',\n",
       "       'Avg_Ticket', 'Age', 'Dt_Customer_InDays', 'Education_2n Cycle',\n",
       "       'Education_Basic', 'Education_Graduation', 'Education_Master',\n",
       "       'Education_PhD', 'Marital_Status_Divorced', 'Marital_Status_Married',\n",
       "       'Marital_Status_Single', 'Marital_Status_Together',\n",
       "       'Marital_Status_Widow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "electronic-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating numeric features in a list, except booleans\n",
    "numeric_features = [\n",
    "    'Year_Birth', \n",
    "#     'Education',\n",
    "    'Income', \n",
    "    'Kidhome',                \n",
    "    'Teenhome', \n",
    "    'Recency', \n",
    "    'MntWines', \n",
    "    'MntFruits',\n",
    "    'MntMeatProducts', \n",
    "    'MntFishProducts', \n",
    "    'MntSweetProducts',\n",
    "    'MntGoldProds', \n",
    "    'NumDealsPurchases', \n",
    "    'NumWebPurchases',\n",
    "    'NumCatalogPurchases', \n",
    "    'NumStorePurchases', \n",
    "    'NumWebVisitsMonth',\n",
    "    'Total_Spent',\n",
    "    'Total_Puchases',\n",
    "    'Family_Size',\n",
    "    'Income_PerCap',\n",
    "    'Prop_Spending_Income_pc', \n",
    "    'Avg_Ticket', \n",
    "    'Age', \n",
    "    'Dt_Customer_InDays'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "absent-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of varibles for VIF analysis\n",
    "\n",
    "################################################################################################\n",
    "#   This cell has been iterated \"mannually\" after checking vif values in the dataframe below   #\n",
    "################################################################################################\n",
    "\n",
    "numeric_features_vif_ok = [\n",
    "#     'Year_Birth', \n",
    "#     'Education',\n",
    "#     'Income', \n",
    "    'Kidhome',                \n",
    "    'Teenhome', \n",
    "    'Recency', \n",
    "    'MntWines', \n",
    "    'MntFruits',\n",
    "    'MntMeatProducts', \n",
    "    'MntFishProducts', \n",
    "    'MntSweetProducts',\n",
    "    'MntGoldProds', \n",
    "    'NumDealsPurchases', \n",
    "    'NumWebPurchases',\n",
    "    'NumCatalogPurchases', \n",
    "    'NumStorePurchases', \n",
    "#     'NumWebVisitsMonth',\n",
    "#     'Total_Spent',\n",
    "#     'Total_Puchases',\n",
    "#     'Family_Size',\n",
    "    'Income_PerCap',\n",
    "    'Prop_Spending_Income_pc', \n",
    "    'Avg_Ticket', \n",
    "#     'Age', \n",
    "    'Dt_Customer_InDays'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "supreme-trunk",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vif_index</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.762486</td>\n",
       "      <td>Kidhome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.428671</td>\n",
       "      <td>Teenhome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.431837</td>\n",
       "      <td>Recency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.835720</td>\n",
       "      <td>MntWines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.243574</td>\n",
       "      <td>MntFruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.225452</td>\n",
       "      <td>MntMeatProducts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.383925</td>\n",
       "      <td>MntFishProducts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.324011</td>\n",
       "      <td>MntSweetProducts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.033618</td>\n",
       "      <td>MntGoldProds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.194466</td>\n",
       "      <td>NumDealsPurchases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.745325</td>\n",
       "      <td>NumWebPurchases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.458291</td>\n",
       "      <td>NumCatalogPurchases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.781989</td>\n",
       "      <td>NumStorePurchases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.733158</td>\n",
       "      <td>NumWebVisitsMonth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.205587</td>\n",
       "      <td>Income_PerCap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.772839</td>\n",
       "      <td>Prop_Spending_Income_pc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.599945</td>\n",
       "      <td>Avg_Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.230653</td>\n",
       "      <td>Dt_Customer_InDays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vif_index                  feature\n",
       "0    2.762486                  Kidhome\n",
       "1    2.428671                 Teenhome\n",
       "2    3.431837                  Recency\n",
       "3    5.835720                 MntWines\n",
       "4    3.243574                MntFruits\n",
       "5    6.225452          MntMeatProducts\n",
       "6    3.383925          MntFishProducts\n",
       "7    3.324011         MntSweetProducts\n",
       "8    3.033618             MntGoldProds\n",
       "9    4.194466        NumDealsPurchases\n",
       "10   7.745325          NumWebPurchases\n",
       "11   6.458291      NumCatalogPurchases\n",
       "12   9.781989        NumStorePurchases\n",
       "13   6.733158        NumWebVisitsMonth\n",
       "14   8.205587            Income_PerCap\n",
       "15   1.772839  Prop_Spending_Income_pc\n",
       "16   3.599945               Avg_Ticket\n",
       "17   3.230653       Dt_Customer_InDays"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe for storing vif and its respective variable\n",
    "vif_df = pd.DataFrame()\n",
    "\n",
    "# Calculating vif values and saving it into vif_index columns\n",
    "vif_df[\"vif_index\"] = [vif(X_train[numeric_features_vif_ok].values, i) \\\n",
    "                               for i in range(X_train[numeric_features_vif_ok].shape[1])]\n",
    "\n",
    "# Saving variable name into feature column\n",
    "vif_df[\"feature\"] = X_train[numeric_features_vif_ok].columns\n",
    "\n",
    "# Checking results\n",
    "vif_df\n",
    "# del(vif_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-western",
   "metadata": {},
   "source": [
    "All `VIF` factor are now $\\le 10$, we can start dealing with the different orders of magnitude in our numeric features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "double-wages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year_Birth', 'Income', 'Total_Spent', 'Total_Puchases', 'Family_Size', 'Age']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop_from_vif = [feature for feature in numeric_features if feature not in numeric_features_vif_ok]\n",
    "to_drop_from_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-baker",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "In order to have the numeric data in the same order of magnite, we will:\n",
    "\n",
    "- Use RobustScaler for variables with outliers;\n",
    "- Use StandardScaler for variables with no outliers;\n",
    "\n",
    "\n",
    "Let's start by listing features with outliers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-lingerie",
   "metadata": {},
   "source": [
    "**Getting features with ouliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "given-singles",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Income',\n",
       " 'MntFruits',\n",
       " 'MntMeatProducts',\n",
       " 'MntFishProducts',\n",
       " 'MntSweetProducts',\n",
       " 'MntGoldProds',\n",
       " 'NumDealsPurchases',\n",
       " 'NumWebPurchases',\n",
       " 'NumCatalogPurchases',\n",
       " 'NumWebVisitsMonth',\n",
       " 'Total_Puchases',\n",
       " 'Family_Size',\n",
       " 'Income_PerCap',\n",
       " 'Prop_Spending_Income_pc',\n",
       " 'Avg_Ticket']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing features names if feature has outlier\n",
    "to_robust_scale = []\n",
    "for feature in numeric_features:\n",
    "    \n",
    "    Q1 = np.percentile(X_train[feature].sort_values(), 25, interpolation = 'midpoint')  \n",
    "    Q3 = np.percentile(X_train[feature].sort_values(), 75, interpolation = 'midpoint')  \n",
    "\n",
    "    IQR = Q3 - Q1  \n",
    "    \n",
    "    low_lim = Q1 - 1.5 * IQR \n",
    "    up_lim = Q3 + 1.5 * IQR \n",
    "\n",
    "    if (X_train[feature] > up_lim).any() or (X_train[feature] < low_lim).any(): \n",
    "         to_robust_scale.append(feature)\n",
    "\n",
    "to_robust_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-mouse",
   "metadata": {},
   "source": [
    "And then, from the previous list, we can list the variables that will be standardized:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-waterproof",
   "metadata": {},
   "source": [
    "**Listing features _without_ outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "small-format",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year_Birth',\n",
       " 'Kidhome',\n",
       " 'Teenhome',\n",
       " 'Recency',\n",
       " 'MntWines',\n",
       " 'NumStorePurchases',\n",
       " 'Total_Spent',\n",
       " 'Age',\n",
       " 'Dt_Customer_InDays']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_standardize = [feature for feature in numeric_features if feature not in to_robust_scale]\n",
    "to_standardize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-office",
   "metadata": {},
   "source": [
    "**Applying RobustScaler to variables listed in `to_robust_scale` list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "supposed-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler()\n",
    "robust_scaler.fit(X_train[to_robust_scale])\n",
    "X_train[to_robust_scale] = robust_scaler.transform(X_train[to_robust_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-science",
   "metadata": {},
   "source": [
    "**Applying StandardScaler to variables listed in `to_standardize` list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "utility-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_scaler = StandardScaler()\n",
    "\n",
    "stand_scaler.fit(X_train[to_standardize])\n",
    "X_train[to_standardize] = stand_scaler.transform(X_train[to_standardize])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-technical",
   "metadata": {},
   "source": [
    "Let's check the `X_train` dataset to see if everything went well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "assisted-ottawa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Income_PerCap</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Prop_Spending_Income_pc</th>\n",
       "      <th>Total_Puchases</th>\n",
       "      <th>Avg_Ticket</th>\n",
       "      <th>Age</th>\n",
       "      <th>Dt_Customer_InDays</th>\n",
       "      <th>Education_2n Cycle</th>\n",
       "      <th>Education_Basic</th>\n",
       "      <th>Education_Graduation</th>\n",
       "      <th>Education_Master</th>\n",
       "      <th>Education_PhD</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Together</th>\n",
       "      <th>Marital_Status_Widow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.48</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.78</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.33</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.22</td>\n",
       "      <td>3.15</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.96</td>\n",
       "      <td>4.54</td>\n",
       "      <td>5.20</td>\n",
       "      <td>3.92</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.47</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.75</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.69</td>\n",
       "      <td>77.92</td>\n",
       "      <td>2.25</td>\n",
       "      <td>32.06</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year_Birth   Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  \\\n",
       "count     2434.00  2434.00  2434.00   2434.00  2434.00   2434.00    2434.00   \n",
       "mean         0.00     0.01    -0.00     -0.00     0.00      0.00       0.44   \n",
       "std          1.00     0.61     1.00      1.00     1.00      1.00       0.99   \n",
       "min         -2.48    -1.47    -0.72     -0.75    -1.59     -1.04      -0.32   \n",
       "25%         -0.78    -0.50    -0.72     -0.75    -0.82     -0.93      -0.24   \n",
       "50%          0.11     0.00    -0.72     -0.75    -0.13     -0.28       0.00   \n",
       "75%          0.73     0.50     1.25      1.20     0.75      0.72       0.76   \n",
       "max          2.33     2.98     3.22      3.15     2.03      2.96       4.54   \n",
       "\n",
       "       MntMeatProducts  MntFishProducts  MntSweetProducts  MntGoldProds  \\\n",
       "count          2434.00          2434.00           2434.00       2434.00   \n",
       "mean              0.34             0.41              0.43          0.30   \n",
       "std               0.79             0.92              0.96          0.85   \n",
       "min              -0.34            -0.31             -0.32         -0.57   \n",
       "25%              -0.27            -0.25             -0.25         -0.32   \n",
       "50%               0.00             0.00              0.00          0.00   \n",
       "75%               0.73             0.75              0.75          0.68   \n",
       "max               5.20             3.92              5.66          5.47   \n",
       "\n",
       "       NumDealsPurchases  NumWebPurchases  NumCatalogPurchases  \\\n",
       "count            2434.00          2434.00              2434.00   \n",
       "mean                0.11             0.06                 0.29   \n",
       "std                 0.97             0.62                 0.75   \n",
       "min                -1.00            -1.00                -0.50   \n",
       "25%                -0.50            -0.50                -0.25   \n",
       "50%                 0.00             0.00                 0.00   \n",
       "75%                 0.50             0.50                 0.75   \n",
       "max                 6.50             5.75                 6.50   \n",
       "\n",
       "       NumStorePurchases  NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  \\\n",
       "count            2434.00            2434.00       2434.00       2434.00   \n",
       "mean               -0.00              -0.21          0.07          0.06   \n",
       "std                 1.00               0.61          0.26          0.25   \n",
       "min                -1.91              -1.50          0.00          0.00   \n",
       "25%                -0.93              -0.75          0.00          0.00   \n",
       "50%                -0.27               0.00          0.00          0.00   \n",
       "75%                 0.71               0.25          0.00          0.00   \n",
       "max                 2.35               3.50          1.00          1.00   \n",
       "\n",
       "       AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  Family_Size  \\\n",
       "count       2434.00       2434.00       2434.00   2434.00      2434.00   \n",
       "mean           0.11          0.09          0.01      0.00         0.38   \n",
       "std            0.31          0.29          0.10      0.05         0.93   \n",
       "min            0.00          0.00          0.00      0.00        -1.00   \n",
       "25%            0.00          0.00          0.00      0.00         0.00   \n",
       "50%            0.00          0.00          0.00      0.00         0.00   \n",
       "75%            0.00          0.00          0.00      0.00         1.00   \n",
       "max            1.00          1.00          1.00      1.00         3.00   \n",
       "\n",
       "       Income_PerCap  Total_Spent  Prop_Spending_Income_pc  Total_Puchases  \\\n",
       "count        2434.00      2434.00                  2434.00         2434.00   \n",
       "mean            0.33         0.00                     0.18           -0.09   \n",
       "std             0.87         1.00                     1.70            0.60   \n",
       "min            -0.76        -1.15                    -0.72           -1.42   \n",
       "25%            -0.32        -0.98                    -0.40           -0.67   \n",
       "50%             0.00        -0.22                    -0.00            0.00   \n",
       "75%             0.68         0.83                     0.60            0.33   \n",
       "max             2.97         2.69                    77.92            2.25   \n",
       "\n",
       "       Avg_Ticket      Age  Dt_Customer_InDays  Education_2n Cycle  \\\n",
       "count     2434.00  2434.00             2434.00             2434.00   \n",
       "mean         0.21     0.00                0.00                0.05   \n",
       "std          0.89     1.00                1.00                0.22   \n",
       "min         -0.60    -2.30               -1.58                0.00   \n",
       "25%         -0.32    -0.70               -0.86                0.00   \n",
       "50%          0.00    -0.16               -0.14                0.00   \n",
       "75%          0.68     0.82                0.81                0.00   \n",
       "max         32.06     2.51                2.00                1.00   \n",
       "\n",
       "       Education_Basic  Education_Graduation  Education_Master  Education_PhD  \\\n",
       "count          2434.00               2434.00           2434.00        2434.00   \n",
       "mean              0.01                  0.39              0.11           0.18   \n",
       "std               0.11                  0.49              0.31           0.38   \n",
       "min               0.00                  0.00              0.00           0.00   \n",
       "25%               0.00                  0.00              0.00           0.00   \n",
       "50%               0.00                  0.00              0.00           0.00   \n",
       "75%               0.00                  1.00              0.00           0.00   \n",
       "max               1.00                  1.00              1.00           1.00   \n",
       "\n",
       "       Marital_Status_Divorced  Marital_Status_Married  Marital_Status_Single  \\\n",
       "count                  2434.00                 2434.00                2434.00   \n",
       "mean                      0.07                    0.30                   0.19   \n",
       "std                       0.25                    0.46                   0.39   \n",
       "min                       0.00                    0.00                   0.00   \n",
       "25%                       0.00                    0.00                   0.00   \n",
       "50%                       0.00                    0.00                   0.00   \n",
       "75%                       0.00                    1.00                   0.00   \n",
       "max                       1.00                    1.00                   1.00   \n",
       "\n",
       "       Marital_Status_Together  Marital_Status_Widow  \n",
       "count                  2434.00               2434.00  \n",
       "mean                      0.17                  0.02  \n",
       "std                       0.37                  0.15  \n",
       "min                       0.00                  0.00  \n",
       "25%                       0.00                  0.00  \n",
       "50%                       0.00                  0.00  \n",
       "75%                       0.00                  0.00  \n",
       "max                       1.00                  1.00  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking statistics from scaled DFs\n",
    "round(X_train.describe(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-notification",
   "metadata": {},
   "source": [
    "The dataset seems alright.\n",
    "\n",
    "Aiming to avoid **data leakage**, we've performed the `.fit` method using only the `X_train` dataset. We need now to `.transform` the values from `X_val` and `X_test` datasets so we can use them later to make predictions and evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "provincial-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming x_val and x_test with scalers from X_train\n",
    "X_val[to_robust_scale] = robust_scaler.transform(X_val[to_robust_scale])\n",
    "X_test[to_robust_scale] = robust_scaler.transform(X_test[to_robust_scale])\n",
    "\n",
    "X_val[to_standardize] = stand_scaler.transform(X_val[to_standardize])\n",
    "X_test[to_standardize] = stand_scaler.transform(X_test[to_standardize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "deadly-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking transformed datasets\n",
    "# X_val.head() # Uncomment to view dataframes\n",
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-cabin",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-commission",
   "metadata": {},
   "source": [
    "Let's start with a baseline model.\n",
    "\n",
    "A baseline model is a good pratice to determine if all sweat put into modelling with different algorithms and hyperparameter tuning is worth the effort.\n",
    "\n",
    "We can use a simple **Linear Regression**, not tunned, model as our baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-tutorial",
   "metadata": {},
   "source": [
    "### Simple LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cheap-cooler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating the model\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "# Fitting the model\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "joint-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting using X_val\n",
    "y_val_pred = log_model.predict(X_val)\n",
    "# y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "clean-episode",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       299\n",
      "           1       0.70      0.63      0.66        59\n",
      "\n",
      "    accuracy                           0.89       358\n",
      "   macro avg       0.81      0.79      0.80       358\n",
      "weighted avg       0.89      0.89      0.89       358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating metrics with Skelearn Classification Report\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "solved-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (10, 4))\n",
    "plot_roc_curve(log_model, X_val, y_val, ax = ax[0])\n",
    "plot_confusion_matrix(log_model, X_val, y_val, cmap=plt.cm.Reds, ax = ax[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-hacker",
   "metadata": {},
   "source": [
    "### Keeping metrics logs in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "minute-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "EXPERIMENT_NAME = '[v2.2] [customers_whole] [Consumer Behavior Analytics] [Renan Moises]'\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment_id = client.create_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "registered-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "metrics = [accuracy_score, precision_score, recall_score, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "phantom-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.create_run(experiment_id)\n",
    "\n",
    "client.log_param(run.info.run_id, 'model', 'LogistRegression-Baseline')\n",
    "\n",
    "for metric in zip(metrics_names, metrics):\n",
    "    client.log_metric(run.info.run_id, metric[0], metric[1](y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-color",
   "metadata": {},
   "source": [
    "## Modelling for Real\n",
    "\n",
    "- LogisticRegression (tunned)\n",
    "- KNNClassifier\n",
    "- SVC\n",
    "- RFClassifier\n",
    "- AdaBoost\n",
    "- GradientBoostClassifier\n",
    "- XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "connected-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'LogisticRegression-Tunned': LogisticRegression(),\n",
    "          'KNNClassifier': KNeighborsClassifier(),\n",
    "          'SVC': SVC(),\n",
    "          'RandomForestClassifier': RandomForestClassifier(),\n",
    "          'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "          'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "          'XGboostClassifier': XGBClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "parental-external",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression-Tunned ####################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       299\n",
      "           1       0.70      0.63      0.66        59\n",
      "\n",
      "    accuracy                           0.89       358\n",
      "   macro avg       0.81      0.79      0.80       358\n",
      "weighted avg       0.89      0.89      0.89       358\n",
      " \n",
      "\n",
      "KNNClassifier ################################################\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88       299\n",
      "           1       0.44      0.63      0.51        59\n",
      "\n",
      "    accuracy                           0.80       358\n",
      "   macro avg       0.68      0.73      0.70       358\n",
      "weighted avg       0.84      0.80      0.82       358\n",
      " \n",
      "\n",
      "SVC ##########################################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93       299\n",
      "           1       0.66      0.49      0.56        59\n",
      "\n",
      "    accuracy                           0.87       358\n",
      "   macro avg       0.78      0.72      0.74       358\n",
      "weighted avg       0.86      0.87      0.87       358\n",
      " \n",
      "\n",
      "RandomForestClassifier #######################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.90       299\n",
      "           1       0.49      0.69      0.58        59\n",
      "\n",
      "    accuracy                           0.83       358\n",
      "   macro avg       0.71      0.78      0.74       358\n",
      "weighted avg       0.86      0.83      0.84       358\n",
      " \n",
      "\n",
      "AdaBoostClassifier ###########################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.46      0.61       299\n",
      "           1       0.23      0.80      0.35        59\n",
      "\n",
      "    accuracy                           0.52       358\n",
      "   macro avg       0.57      0.63      0.48       358\n",
      "weighted avg       0.81      0.52      0.57       358\n",
      " \n",
      "\n",
      "GradientBoostingClassifier ###################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.83       299\n",
      "           1       0.26      0.37      0.31        59\n",
      "\n",
      "    accuracy                           0.72       358\n",
      "   macro avg       0.56      0.58      0.57       358\n",
      "weighted avg       0.77      0.72      0.74       358\n",
      " \n",
      "\n",
      "XGboostClassifier ############################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "[21:44:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93       299\n",
      "           1       0.61      0.73      0.67        59\n",
      "\n",
      "    accuracy                           0.88       358\n",
      "   macro avg       0.78      0.82      0.80       358\n",
      "weighted avg       0.89      0.88      0.88       358\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_key, model_value in models.items():\n",
    "    X_train_modelling = X_train.copy().drop(to_drop_from_vif, axis = 1)\n",
    "    X_val_modelling = X_val.copy().drop(to_drop_from_vif, axis = 1)\n",
    "    \n",
    "    if model_key == 'LogisticRegression-Tunned':\n",
    "        # Dropping Multicolinear Features for Logistic Regression\n",
    "#         X_train_modelling = X_train.drop(to_drop_from_vif, axis = 1)\n",
    "#         X_val_modelling = X_val.drop(to_drop_from_vif, axis = 1)\n",
    "        param_grid = {\n",
    "            'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "            'tol': stats.loguniform(0.1, 1),\n",
    "            'C': stats.loguniform(3, 10)\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'KNNClassifier':\n",
    "        # Dropping Multicolinear Features for KNNClassifier\n",
    "#         X_train_modelling = X_train.drop(to_drop_from_vif, axis = 1)\n",
    "#         X_val_modelling = X_val.drop(to_drop_from_vif, axis = 1)\n",
    "        param_grid = {'n_neighbors':[3, 4, 5, 6, 7]}\n",
    "    \n",
    "    elif model_key == 'SVC':\n",
    "        # Dropping Multicolinear Features for SVC\n",
    "#         X_train_modelling = X_train.drop(to_drop_from_vif, axis = 1)\n",
    "#         X_val_modelling = X_val.drop(to_drop_from_vif, axis = 1)\n",
    "        param_grid = {\n",
    "            'C': stats.loguniform(3, 10)\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'RandomForestClassifier':\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 60, 70, 80, 90, 100],\n",
    "            'max_depth': np.arange(0, 10),\n",
    "            'min_samples_split': np.arange(0, 10),\n",
    "            'min_samples_leaf': stats.loguniform(.01, 1),\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'AdaBoostClassifier':\n",
    "        param_grid = {\n",
    "            'learning_rate': stats.lognorm(.001, 1)\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'GradientBoostingClassifier':\n",
    "        param_grid = {\n",
    "            'learning_rate': stats.lognorm(.001, 1),\n",
    "            'n_estimators': [50, 60, 70, 80, 90, 100],\n",
    "            'min_samples_split': np.arange(0, 10),\n",
    "            'min_samples_leaf': stats.loguniform(.01, 1),\n",
    "            'max_depth': np.arange(0, 10)\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 60, 70, 80, 90, 100],\n",
    "            'max_depth': np.arange(0, 10),\n",
    "            'learning_rate': stats.lognorm(.001, 1),\n",
    "            'gamma': stats.lognorm(.001, 1),\n",
    "        }   \n",
    "    \n",
    "    \n",
    "    # Running RandomizedSearchCV\n",
    "    print(model_key, '#'.replace('#', '#'*(61 - len(model_key))))\n",
    "    model_rsearch = RandomizedSearchCV(model_value, \n",
    "                                       param_distributions = param_grid, \n",
    "                                       n_iter = 50, \n",
    "                                       scoring = 'f1', # Used to update weights\n",
    "                                       cv = 10, \n",
    "                                       n_jobs = -1, \n",
    "                                       verbose = 1)\n",
    "    \n",
    "    # Fitting the model to the train data\n",
    "    model_rsearch.fit(X_train_modelling, y_train)\n",
    "    \n",
    "    # Saving model as a joblib file\n",
    "    joblib.dump(model_rsearch, f'../models/{model_key}.joblib')\n",
    "    \n",
    "    # Predictions using X_val\n",
    "    y_val_pred = model_rsearch.predict(X_val_modelling)\n",
    "    \n",
    "    # Setting up metrics\n",
    "    metrics_names = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    metrics = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "    \n",
    "    # MLFlow Logs\n",
    "    run = client.create_run(experiment_id)\n",
    "    for metric_name, metric in zip(metrics_names, metrics):\n",
    "        client.log_metric(run.info.run_id, metric_name, metric(y_val, y_val_pred))\n",
    "    client.log_param(run.info.run_id, \"model\", model_key)\n",
    "    client.log_param(run.info.run_id, \"params\", model_value.get_params())\n",
    "    client.log_param(run.info.run_id, \"features\", model_rsearch.columns.tolist())\n",
    "    \n",
    "    print(classification_report(y_val, y_val_pred), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-mayor",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-receipt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
