{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "integrated-energy",
   "metadata": {},
   "source": [
    "# Consumer Behavior Analytics - Data Modelling  of `customers_whole`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-hypothetical",
   "metadata": {},
   "source": [
    "**Libraries and imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "controversial-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic DS libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# DataViz libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistics Libraries\n",
    "from scipy import stats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "# Data Utils\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, \\\n",
    "                                                                     recall_score, \\\n",
    "                                                                     precision_score, \\\n",
    "                                                                     accuracy_score, \\\n",
    "                                                                     roc_auc_score, \\\n",
    "                                                                     auc, \\\n",
    "                                                                     plot_confusion_matrix, \\\n",
    "                                                                     plot_roc_curve\n",
    "                                                                         \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Notebook setup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "boxed-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading customers exposed\n",
    "customers_exposed = pd.read_csv('../data/customers_exposed.csv', parse_dates = ['Dt_Customer'])\n",
    "\n",
    "# Loading customers whole\n",
    "customers_whole = pd.read_csv('../data/customers_whole.csv', parse_dates = ['Dt_Customer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "productive-hammer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Response</th>\n",
       "      <th>Income_PerCap</th>\n",
       "      <th>Prop_Spending_Income_pc</th>\n",
       "      <th>Avg_Ticket</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5524</td>\n",
       "      <td>1957</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>88</td>\n",
       "      <td>546</td>\n",
       "      <td>172</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>64.68</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174</td>\n",
       "      <td>1954</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15448.0</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>4.50</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4141</td>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-21</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>49</td>\n",
       "      <td>127</td>\n",
       "      <td>111</td>\n",
       "      <td>21</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35806.5</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>36.95</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6182</td>\n",
       "      <td>1984</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-10</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8882.0</td>\n",
       "      <td>0.005967</td>\n",
       "      <td>6.62</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5324</td>\n",
       "      <td>1981</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-19</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>46</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19431.0</td>\n",
       "      <td>0.021718</td>\n",
       "      <td>22.21</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
       "0  5524        1957  Graduation         Single  58138.0        0         0   \n",
       "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
       "2  4141        1965  Graduation       Together  71613.0        0         0   \n",
       "3  6182        1984  Graduation       Together  26646.0        1         0   \n",
       "4  5324        1981         PhD        Married  58293.0        1         0   \n",
       "\n",
       "  Dt_Customer  Recency  MntWines  MntFruits  MntMeatProducts  MntFishProducts  \\\n",
       "0  2012-09-04       58       635         88              546              172   \n",
       "1  2014-03-08       38        11          1                6                2   \n",
       "2  2013-08-21       26       426         49              127              111   \n",
       "3  2014-02-10       26        11          4               20               10   \n",
       "4  2014-01-19       94       173         43              118               46   \n",
       "\n",
       "   MntSweetProducts  MntGoldProds  NumDealsPurchases  NumWebPurchases  \\\n",
       "0                88            88                  3                8   \n",
       "1                 1             6                  2                1   \n",
       "2                21            42                  1                8   \n",
       "3                 3             5                  2                2   \n",
       "4                27            15                  5                5   \n",
       "\n",
       "   NumCatalogPurchases  NumStorePurchases  NumWebVisitsMonth  AcceptedCmp3  \\\n",
       "0                   10                  4                  7             0   \n",
       "1                    1                  2                  5             0   \n",
       "2                    2                 10                  4             0   \n",
       "3                    0                  4                  6             0   \n",
       "4                    3                  6                  5             0   \n",
       "\n",
       "   AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  Response  \\\n",
       "0             0             0             0             0         0         1   \n",
       "1             0             0             0             0         0         0   \n",
       "2             0             0             0             0         0         0   \n",
       "3             0             0             0             0         0         0   \n",
       "4             0             0             0             0         0         0   \n",
       "\n",
       "   Income_PerCap  Prop_Spending_Income_pc  Avg_Ticket  Age  \n",
       "0        58138.0                 0.027813       64.68   57  \n",
       "1        15448.0                 0.001748        4.50   60  \n",
       "2        35806.5                 0.021672       36.95   49  \n",
       "3         8882.0                 0.005967        6.62   30  \n",
       "4        19431.0                 0.021718       22.21   33  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bacterial-lesbian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.850873\n",
       "1    0.149127\n",
       "Name: Response, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking class balance (or imballance)\n",
    "customers_whole['Response'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-force",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-drink",
   "metadata": {},
   "source": [
    "We are going to start preparing the data for modelling regarding both datasets: `customers_whole` and `customers_exposed`, but only until One Hot Encoding.\n",
    "\n",
    "After that, we will save both one hot encoded dataframes into new csv files and split both analysis in different notebooks. The analysis in this notebook will be for `customers_whole` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "three-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Sample first_date\n",
    "first_date = customers_whole['Dt_Customer'].min()\n",
    "\n",
    "# Transforming datetime feature to numeric feature\n",
    "for df in [customers_exposed, customers_whole]:\n",
    "    df['Dt_Customer_InDays'] = df['Dt_Customer'] - first_date\n",
    "    \n",
    "    df['Dt_Customer_InDays'] = (df['Dt_Customer_InDays'] / np.timedelta64(1, 'D')).astype(int) + 1\n",
    "    \n",
    "    # Dropping unuseful columns for modelling\n",
    "    df.drop(['ID', 'Dt_Customer'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "armed-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding categorical features with pd.get_dummies\n",
    "customers_exposed_ohe = pd.get_dummies(customers_exposed)\n",
    "customers_whole_ohe = pd.get_dummies(customers_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "desperate-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving One Hot Enconded files into a new csv file\n",
    "customers_whole_ohe.to_csv('../data/customers_whole_ohe.csv', header = True, index = False)\n",
    "# pd.read_csv('../data/customers_whole_ohe.csv')\n",
    "\n",
    "customers_exposed_ohe.to_csv('../data/customers_exposed_ohe.csv', header = True, index = False)\n",
    "# pd.read_csv('../data/customers_exposed_ohe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-lover",
   "metadata": {},
   "source": [
    "Both files have been saved! We will not need to load the `customers_whole_ohe.csv` into this notebook, but it is aways good to keep a standartd log of actions.\n",
    "\n",
    "**We will move forward with modelling for the `customers_whole` dataset hereafter.**\n",
    "\n",
    "Let's start:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-hundred",
   "metadata": {},
   "source": [
    "### Splitting Data into _Train_, _Validation_ and _Test_ sets\n",
    "\n",
    "We will split the data according to the following schedule:\n",
    "\n",
    "- Create a `df_train` and a `df_test`.\n",
    "- From the previous `df_train` we will once again split it into two: `df_train` and `df_val`.\n",
    "\n",
    "We also know that _specially_ in this dataset (`_whole`) we have unballanced data. So we will perform a oversampling technique called SMOTE. According to the paper published in _The Journal of Artificial Intelligence Research_ in 2002:\n",
    "\n",
    "> [With SMOTE] The minority class is over-sampled by taking each minority class sample and introducing synthetic examples along the line segments joining any/all of the $k$ minority class nearest neighbors. Depending upon the amount of over-sampling required, neighbors from the k nearest neighbors are randomly chosen.[$^{SMOTE: \\: Synthetic\\:Minority\\:Over-sampling\\:Technique}$](https://arxiv.org/pdf/1106.1813.pdf)\n",
    "\n",
    "- Finally, we will separate all dfs into `X`'s and `y`, naming respectively accordint to the df they belong to.\n",
    "\n",
    "Let's start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "legitimate-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting df_train and df_test for training and testing\n",
    "df_train, df_test = train_test_split(customers_whole_ohe, test_size = .2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ordered-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting df_train into df_train and df_val\n",
    "df_train, df_val = train_test_split(df_train, test_size = .2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "domestic-attitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1217\n",
       "1     211\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking target variable balance (or imballance)\n",
    "df_train['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "departmental-bread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1217\n",
       "1    1217\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balancing target variable with SMOTE technique\n",
    "\n",
    "# Instantiating SMOTER over_sampler\n",
    "smote = SMOTE(random_state = 7)\n",
    "\n",
    "# Fitting and resampling data with SMOTE\n",
    "X_train, y_train = smote.fit_resample(df_train.drop('Response', axis = 1), df_train['Response'])\n",
    "\n",
    "# Checking target class balance\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "auburn-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_val.drop('Response', axis = 1)\n",
    "y_val = df_val['Response']\n",
    "\n",
    "X_test = df_test.drop('Response', axis = 1)\n",
    "y_test = df_test['Response']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-night",
   "metadata": {},
   "source": [
    "Let's check if the generated `X`'s and `y`'s are correctly built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "planned-electron",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, y_train   shapes:  (2434, 37) (2434,)\n",
      "X_val  , y_val     shapes:  (358, 37) (358,)\n",
      "X_test , y_test    shapes:  (447, 37) (447,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train, y_train   shapes: ', X_train.shape, y_train.shape)\n",
    "print('X_val  , y_val     shapes: ', X_val.shape, y_val.shape)\n",
    "print('X_test , y_test    shapes: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-correlation",
   "metadata": {},
   "source": [
    "**All shapes match**. We are good to go on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-lighting",
   "metadata": {},
   "source": [
    "### Analyzing multicolinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-vanilla",
   "metadata": {},
   "source": [
    "In the previous notebooks, we have created new variables from pre-existing variables. Therefore we made room for possible multicolinearity.\n",
    "\n",
    "Some techniques for analyzing multicolinearity are:\n",
    "\n",
    "- Checking correlation values between variables;\n",
    "- Checking the Variance Inflation Factor (VIF) and dropping variables with factor $> 10$;\n",
    "- Performing Principal Component Analysis, to the cost of lesser interpretability;\n",
    "- Perform regularization such as (Lasso or Ridge) for linear models, such as Logistic Regression;\n",
    "\n",
    "For the sake of simplicity, let's go foward with `VIF` and drop variables with factor $ >10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "roman-budapest",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines',\n",
       "       'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
       "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
       "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
       "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
       "       'AcceptedCmp2', 'Complain', 'Income_PerCap', 'Prop_Spending_Income_pc',\n",
       "       'Avg_Ticket', 'Age', 'Dt_Customer_InDays', 'Education_2n Cycle',\n",
       "       'Education_Basic', 'Education_Graduation', 'Education_Master',\n",
       "       'Education_PhD', 'Marital_Status_Divorced', 'Marital_Status_Married',\n",
       "       'Marital_Status_Single', 'Marital_Status_Together',\n",
       "       'Marital_Status_Widow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tender-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating numeric features in a list, except booleans\n",
    "numeric_features = [\n",
    "    'Year_Birth', \n",
    "    'Income', \n",
    "    'Kidhome',                \n",
    "    'Teenhome', \n",
    "    'Recency', \n",
    "    'MntWines', \n",
    "    'MntFruits',\n",
    "    'MntMeatProducts', \n",
    "    'MntFishProducts', \n",
    "    'MntSweetProducts',\n",
    "    'MntGoldProds', \n",
    "    'NumDealsPurchases', \n",
    "    'NumWebPurchases',\n",
    "    'NumCatalogPurchases', \n",
    "    'NumStorePurchases', \n",
    "    'NumWebVisitsMonth', \n",
    "    'Income_PerCap',\n",
    "    'Prop_Spending_Income_pc', \n",
    "    'Avg_Ticket', \n",
    "    'Age', \n",
    "    'Dt_Customer_InDays'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "electric-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of varibles for VIF analysis\n",
    "\n",
    "################################################################################################\n",
    "#   This cell has been iterated \"mannually\" after checking vif values in the dataframe below   #\n",
    "################################################################################################\n",
    "\n",
    "numeric_features_vif_ok = [\n",
    "#     'Year_Birth', \n",
    "#     'Income', \n",
    "    'Kidhome',                \n",
    "    'Teenhome', \n",
    "    'Recency', \n",
    "    'MntWines', \n",
    "    'MntFruits',\n",
    "    'MntMeatProducts', \n",
    "    'MntFishProducts', \n",
    "    'MntSweetProducts',\n",
    "    'MntGoldProds', \n",
    "    'NumDealsPurchases', \n",
    "    'NumWebPurchases',\n",
    "    'NumCatalogPurchases', \n",
    "    'NumStorePurchases', \n",
    "    'NumWebVisitsMonth', \n",
    "    'Income_PerCap',\n",
    "    'Prop_Spending_Income_pc', \n",
    "    'Avg_Ticket', \n",
    "#     'Age', \n",
    "    'Dt_Customer_InDays'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "purple-bulletin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vif_index</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.770909</td>\n",
       "      <td>Kidhome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.428519</td>\n",
       "      <td>Teenhome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.390774</td>\n",
       "      <td>Recency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.811089</td>\n",
       "      <td>MntWines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.245729</td>\n",
       "      <td>MntFruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.251313</td>\n",
       "      <td>MntMeatProducts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.419433</td>\n",
       "      <td>MntFishProducts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.303406</td>\n",
       "      <td>MntSweetProducts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.029202</td>\n",
       "      <td>MntGoldProds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.215827</td>\n",
       "      <td>NumDealsPurchases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.736607</td>\n",
       "      <td>NumWebPurchases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.480013</td>\n",
       "      <td>NumCatalogPurchases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.798706</td>\n",
       "      <td>NumStorePurchases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.695898</td>\n",
       "      <td>NumWebVisitsMonth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.215038</td>\n",
       "      <td>Income_PerCap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.773105</td>\n",
       "      <td>Prop_Spending_Income_pc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.600511</td>\n",
       "      <td>Avg_Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.217400</td>\n",
       "      <td>Dt_Customer_InDays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vif_index                  feature\n",
       "0    2.770909                  Kidhome\n",
       "1    2.428519                 Teenhome\n",
       "2    3.390774                  Recency\n",
       "3    5.811089                 MntWines\n",
       "4    3.245729                MntFruits\n",
       "5    6.251313          MntMeatProducts\n",
       "6    3.419433          MntFishProducts\n",
       "7    3.303406         MntSweetProducts\n",
       "8    3.029202             MntGoldProds\n",
       "9    4.215827        NumDealsPurchases\n",
       "10   7.736607          NumWebPurchases\n",
       "11   6.480013      NumCatalogPurchases\n",
       "12   9.798706        NumStorePurchases\n",
       "13   6.695898        NumWebVisitsMonth\n",
       "14   8.215038            Income_PerCap\n",
       "15   1.773105  Prop_Spending_Income_pc\n",
       "16   3.600511               Avg_Ticket\n",
       "17   3.217400       Dt_Customer_InDays"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe for storing vif and its respective variable\n",
    "vif_df = pd.DataFrame()\n",
    "\n",
    "# Calculating vif values and saving it into vif_index columns\n",
    "vif_df[\"vif_index\"] = [vif(X_train[numeric_features_vif_ok].values, i) \\\n",
    "                               for i in range(X_train[numeric_features_vif_ok].shape[1])]\n",
    "\n",
    "# Saving variable name into feature column\n",
    "vif_df[\"feature\"] = X_train[numeric_features_vif_ok].columns\n",
    "\n",
    "# Checking results\n",
    "vif_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-sport",
   "metadata": {},
   "source": [
    "All `VIF` factor are now $\\le 10$, we can start dealing with the different orders of magnitude in our numeric features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "boxed-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_from_vif = ['Year_Birth', 'Income', 'Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-petersburg",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "In order to have the numeric data in the same order of magnite, we will:\n",
    "\n",
    "- Use RobustScaler for variables with outliers;\n",
    "- Use StandardScaler for variables with no outliers;\n",
    "\n",
    "\n",
    "Let's start by listing features with outliers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-setup",
   "metadata": {},
   "source": [
    "**Getting features with ouliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "painted-accident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Income',\n",
       " 'MntFruits',\n",
       " 'MntMeatProducts',\n",
       " 'MntFishProducts',\n",
       " 'MntSweetProducts',\n",
       " 'MntGoldProds',\n",
       " 'NumDealsPurchases',\n",
       " 'NumWebPurchases',\n",
       " 'NumCatalogPurchases',\n",
       " 'NumWebVisitsMonth',\n",
       " 'Income_PerCap',\n",
       " 'Prop_Spending_Income_pc',\n",
       " 'Avg_Ticket']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing features names if feature has outlier\n",
    "to_robust_scale = []\n",
    "for feature in numeric_features:\n",
    "    \n",
    "    Q1 = np.percentile(X_train[feature].sort_values(), 25, interpolation = 'midpoint')  \n",
    "    Q3 = np.percentile(X_train[feature].sort_values(), 75, interpolation = 'midpoint')  \n",
    "\n",
    "    IQR = Q3 - Q1  \n",
    "    \n",
    "    low_lim = Q1 - 1.5 * IQR \n",
    "    up_lim = Q3 + 1.5 * IQR \n",
    "\n",
    "    if (X_train[feature] > up_lim).any() or (X_train[feature] < low_lim).any(): \n",
    "         to_robust_scale.append(feature)\n",
    "\n",
    "to_robust_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-favorite",
   "metadata": {},
   "source": [
    "And then, from the previous list, we can list the variables that will be standardized:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-million",
   "metadata": {},
   "source": [
    "**Listing features _without_ outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sensitive-cornell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year_Birth',\n",
       " 'Kidhome',\n",
       " 'Teenhome',\n",
       " 'Recency',\n",
       " 'MntWines',\n",
       " 'NumStorePurchases',\n",
       " 'Age',\n",
       " 'Dt_Customer_InDays']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_standardize = [feature for feature in numeric_features if feature not in to_robust_scale]\n",
    "to_standardize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-discrimination",
   "metadata": {},
   "source": [
    "**Applying RobustScaler to variables listed in `to_robust_scale` list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "subsequent-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler()\n",
    "robust_scaler.fit(X_train[to_robust_scale])\n",
    "X_train[to_robust_scale] = robust_scaler.transform(X_train[to_robust_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-norwegian",
   "metadata": {},
   "source": [
    "**Applying StandardScaler to variables listed in `to_standardize` list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "environmental-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_scaler = StandardScaler()\n",
    "\n",
    "stand_scaler.fit(X_train[to_standardize])\n",
    "X_train[to_standardize] = stand_scaler.transform(X_train[to_standardize])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-ukraine",
   "metadata": {},
   "source": [
    "Let's check the `X_train` dataset to see if everything went well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "separate-payroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Income_PerCap</th>\n",
       "      <th>Prop_Spending_Income_pc</th>\n",
       "      <th>Avg_Ticket</th>\n",
       "      <th>Age</th>\n",
       "      <th>Dt_Customer_InDays</th>\n",
       "      <th>Education_2n Cycle</th>\n",
       "      <th>Education_Basic</th>\n",
       "      <th>Education_Graduation</th>\n",
       "      <th>Education_Master</th>\n",
       "      <th>Education_PhD</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Together</th>\n",
       "      <th>Marital_Status_Widow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "      <td>2434.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.48</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.34</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.15</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.98</td>\n",
       "      <td>4.54</td>\n",
       "      <td>5.17</td>\n",
       "      <td>3.85</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.38</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.75</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.36</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.97</td>\n",
       "      <td>78.67</td>\n",
       "      <td>32.06</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year_Birth   Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  \\\n",
       "count     2434.00  2434.00  2434.00   2434.00  2434.00   2434.00    2434.00   \n",
       "mean        -0.00     0.01     0.00     -0.00    -0.00     -0.00       0.45   \n",
       "std          1.00     0.61     1.00      1.00     1.00      1.00       0.99   \n",
       "min         -2.48    -1.47    -0.72     -0.75    -1.58     -1.04      -0.32   \n",
       "25%         -0.79    -0.50    -0.72     -0.75    -0.81     -0.93      -0.24   \n",
       "50%          0.11     0.00    -0.72     -0.75    -0.12     -0.27       0.00   \n",
       "75%          0.73     0.50     1.25      1.20     0.76      0.71       0.76   \n",
       "max          2.34     2.98     3.21      3.15     2.03      2.98       4.54   \n",
       "\n",
       "       MntMeatProducts  MntFishProducts  MntSweetProducts  MntGoldProds  \\\n",
       "count          2434.00          2434.00           2434.00       2434.00   \n",
       "mean              0.34             0.41              0.43          0.30   \n",
       "std               0.79             0.90              0.97          0.85   \n",
       "min              -0.34            -0.31             -0.32         -0.56   \n",
       "25%              -0.26            -0.24             -0.25         -0.31   \n",
       "50%               0.00             0.00              0.00          0.00   \n",
       "75%               0.74             0.76              0.75          0.69   \n",
       "max               5.17             3.85              5.66          5.38   \n",
       "\n",
       "       NumDealsPurchases  NumWebPurchases  NumCatalogPurchases  \\\n",
       "count            2434.00          2434.00              2434.00   \n",
       "mean                0.11             0.06                 0.29   \n",
       "std                 0.97             0.62                 0.74   \n",
       "min                -1.00            -1.00                -0.50   \n",
       "25%                -0.50            -0.50                -0.25   \n",
       "50%                 0.00             0.00                 0.00   \n",
       "75%                 0.50             0.50                 0.75   \n",
       "max                 6.50             5.75                 6.50   \n",
       "\n",
       "       NumStorePurchases  NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  \\\n",
       "count            2434.00            2434.00       2434.00       2434.00   \n",
       "mean               -0.00              -0.22          0.07          0.06   \n",
       "std                 1.00               0.61          0.26          0.25   \n",
       "min                -1.92              -1.50          0.00          0.00   \n",
       "25%                -0.93              -0.75          0.00          0.00   \n",
       "50%                -0.27               0.00          0.00          0.00   \n",
       "75%                 0.71               0.25          0.00          0.00   \n",
       "max                 2.36               3.50          1.00          1.00   \n",
       "\n",
       "       AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  Income_PerCap  \\\n",
       "count       2434.00       2434.00       2434.00   2434.00        2434.00   \n",
       "mean           0.11          0.09          0.01      0.00           0.33   \n",
       "std            0.31          0.29          0.10      0.05           0.87   \n",
       "min            0.00          0.00          0.00      0.00          -0.76   \n",
       "25%            0.00          0.00          0.00      0.00          -0.32   \n",
       "50%            0.00          0.00          0.00      0.00           0.00   \n",
       "75%            0.00          0.00          0.00      0.00           0.68   \n",
       "max            1.00          1.00          1.00      1.00           2.97   \n",
       "\n",
       "       Prop_Spending_Income_pc  Avg_Ticket      Age  Dt_Customer_InDays  \\\n",
       "count                  2434.00     2434.00  2434.00             2434.00   \n",
       "mean                      0.18        0.21     0.00                0.00   \n",
       "std                       1.72        0.89     1.00                1.00   \n",
       "min                      -0.72       -0.60    -2.30               -1.59   \n",
       "25%                      -0.40       -0.32    -0.70               -0.85   \n",
       "50%                       0.00        0.00    -0.16               -0.14   \n",
       "75%                       0.60        0.68     0.82                0.82   \n",
       "max                      78.67       32.06     2.52                2.00   \n",
       "\n",
       "       Education_2n Cycle  Education_Basic  Education_Graduation  \\\n",
       "count             2434.00          2434.00               2434.00   \n",
       "mean                 0.05             0.01                  0.39   \n",
       "std                  0.22             0.11                  0.49   \n",
       "min                  0.00             0.00                  0.00   \n",
       "25%                  0.00             0.00                  0.00   \n",
       "50%                  0.00             0.00                  0.00   \n",
       "75%                  0.00             0.00                  1.00   \n",
       "max                  1.00             1.00                  1.00   \n",
       "\n",
       "       Education_Master  Education_PhD  Marital_Status_Divorced  \\\n",
       "count           2434.00        2434.00                  2434.00   \n",
       "mean               0.11           0.18                     0.07   \n",
       "std                0.31           0.38                     0.25   \n",
       "min                0.00           0.00                     0.00   \n",
       "25%                0.00           0.00                     0.00   \n",
       "50%                0.00           0.00                     0.00   \n",
       "75%                0.00           0.00                     0.00   \n",
       "max                1.00           1.00                     1.00   \n",
       "\n",
       "       Marital_Status_Married  Marital_Status_Single  Marital_Status_Together  \\\n",
       "count                 2434.00                2434.00                  2434.00   \n",
       "mean                     0.30                   0.19                     0.16   \n",
       "std                      0.46                   0.39                     0.37   \n",
       "min                      0.00                   0.00                     0.00   \n",
       "25%                      0.00                   0.00                     0.00   \n",
       "50%                      0.00                   0.00                     0.00   \n",
       "75%                      1.00                   0.00                     0.00   \n",
       "max                      1.00                   1.00                     1.00   \n",
       "\n",
       "       Marital_Status_Widow  \n",
       "count               2434.00  \n",
       "mean                   0.02  \n",
       "std                    0.15  \n",
       "min                    0.00  \n",
       "25%                    0.00  \n",
       "50%                    0.00  \n",
       "75%                    0.00  \n",
       "max                    1.00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking statistics from scaled DFs\n",
    "round(X_train.describe(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-jackson",
   "metadata": {},
   "source": [
    "The dataset seems alright.\n",
    "\n",
    "Aiming to avoid **data leakage**, we've performed the `.fit` method using only the `X_train` dataset. We need now to `.transform` the values from `X_val` and `X_test` datasets so we can use them later to make predictions and evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sweet-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming x_val and x_test with scalers from X_train\n",
    "X_val[to_robust_scale] = robust_scaler.transform(X_val[to_robust_scale])\n",
    "X_test[to_robust_scale] = robust_scaler.transform(X_test[to_robust_scale])\n",
    "\n",
    "X_val[to_standardize] = stand_scaler.transform(X_val[to_standardize])\n",
    "X_test[to_standardize] = stand_scaler.transform(X_test[to_standardize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "british-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking transformed datasets\n",
    "# X_val.head() # Uncomment to view dataframes\n",
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-tsunami",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-edward",
   "metadata": {},
   "source": [
    "Let's start with a baseline model.\n",
    "\n",
    "A baseline model is a good pratice to determine if all sweat put into modelling with different algorithms and hyperparameter tuning is worth the effort.\n",
    "\n",
    "We can use a simple **Linear Regression**, not tunned, model as our baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-agent",
   "metadata": {},
   "source": [
    "### Simple LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "addressed-chester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating the model\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "# Fitting the model\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "velvet-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting using X_val\n",
    "y_val_pred = log_model.predict(X_val)\n",
    "# y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "wound-playback",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       299\n",
      "           1       0.69      0.63      0.65        59\n",
      "\n",
      "    accuracy                           0.89       358\n",
      "   macro avg       0.81      0.79      0.80       358\n",
      "weighted avg       0.89      0.89      0.89       358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating metrics with Skelearn Classification Report\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "owned-toyota",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr8AAAEYCAYAAABV6J4lAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABCp0lEQVR4nO3deZyd8/n/8dd7khBkQWyxRFKibQTBkKa22JeqUCqSWhtFS2ur0tbX2hYtilYRy89SoVrSRMRWje37JZIQkcUSRCRCCCIRQeT6/XHfM04ms9wzc86cOWfez8fjfsy59+s+J3Pnms+57s9HEYGZmZmZWVtQUewAzMzMzMxaipNfMzMzM2sznPyamZmZWZvh5NfMzMzM2gwnv2ZmZmbWZrQvdgCNtc4660TPnj2LHYaZWd5NmjTpg4hYt9hx5EtHKTq7jaXsbLrt1sUOwfJs1uzZfPDBAjV1/03UPpaSvfewD1j+cETs19TzNVfJJb89e/Zk4sSJxQ7DzCzvJL1V7BjyqTMVHMrqxQ7D8uz6px8vdgiWZ5U7D2zW/ksJDmWNzNvfwKJ1mnXCZiq55NfMzMzMWg9RWnW0Tn7NzMzMrFkq1IiqiSKPr+bk18zMzMyazC2/ZmZmZtamtG/M43Ju+TUzMzOzUiXUuLKHInPya2ZmZmbNUkplDwWLVdItkuZLmlrHekm6RtJMSVMkbVeoWMzMzMysMARUKPtUbIVM1G8F6uvAeH+gdzqdAFxXwFjMzMzMrEAqGjEVW8HKHiLiSUk969lkEHB7RATwrKQ1JXWPiHmFisnMWpcR42czavLcYoeRd3027ML539+y2GGYmbUMgUqo5reYCfhGwNs583PSZSuRdIKkiZImvv/++y0SnJkV3qjJc5k+75Nih2FmZs1Q1dVZm2/5zaeIGA4MB6isrCxyBxlmlk99unfhHycOKHYYZmbWDK2hljerYia/c4FNcuY3TpeZmZmZWQlpDS26WRUz+R0NnCLpbqA/sND1vlYuyrWWNd+mz/uEPt27FDsMMzNrhqS3h9Jp+i1Y8ivpLmAgsI6kOcD5QAeAiLgeGAscAMwElgDHFSoWs5ZWVcvqxK5+fbp3YVC/Wkv9zcyshLjlF4iIIQ2sD+DkQp3frNhcy2pmZm1BVT+/paIkHniz8laOJQJu9TUzs7akPaWT/ZZSK7WVqXLs7spf55uZWVtRaiO8ueXXWgWXCJiZmZWuUmpNdfJrZmZmZk2mVtKim5WTX2uSfNbpuj7WzMystFW45tfKXT7rdF0fa2ZmVtpc82ttgut0zczMTJRWa6qTXzMzMzNrltbQopuVk18zMzMzazIh1/yamZmZWduRr5pfSZtIGidpuqRpkk5Nl18gaa6kyel0QM4+v5Y0U9IrkvZtKFa3/JqZmZlZs+Sx3XcZcGZEPC+pMzBJ0qPpuj9HxOUrnFfqAxwBbAlsCPxH0hYR8VVdJ3Dy20Y1t6syd09mZmZmkCS+7ZWf9Dci5gHz0teLJM0A6usSahBwd0R8DrwpaSawI/BMXTu47KGNam5XZe6ezMzMzODrQS4aUfawjqSJOdMJtR9XPYFtgfHpolMkTZF0i6S10mUbAW/n7DaH+pNlt/y2Ze6qzMzMzPKhka2pH0REZX0bSOoE3AucFhGfSLoOuBiI9OcVwI+bEmum5FdSBbANSS3FZ8DUiJjflBOamZmZWXnJZ18PkjqQJL53RsR9ABHxXs76G4Ex6excYJOc3TdOl9Wp3uRX0mbA2cBewGvA+0BHYAtJS4AbgNsiYnkjrsmKoGaNr2t2zczMLB8EVOSp5leSgJuBGRFxZc7y7mk9MMAhwNT09WhghKQrSRppewPP1XeOhlp+fwdcB5wYEVEjuPWAocBRwG2ZrsiKpqrGtyrhdc2umZmZ5UseW353IsktX5I0OV32G2CIpH4kZQ+zgBMBImKapHuA6SQ9RZxcX08P0EDyGxFD6lk3H7gqw0VYK+EaXzMzMyuEfCW/EfF0HYcbW88+vwd+n/UcTX7gTdLeEfFow1taseSWOrjMwczMzAqldMZ3a15XZzfnLQoriNzuzFzmYGZmZoUiKfNUbA098Da6rlVAt/yHY/nmUgczMzMrJFFaLb8NlT3sAhwJLK6xXCSjZ5iZmZlZG1dKo6Y1lPw+CyyJiCdqrpD0SmFCsuaqqvV1na+ZmZm1hFZQzZBZQ7097F/Pul3zH47lQ27i6zpfMzMzKyQBFSVU+ODhjcuUa33NzMyspZRO6uvk18zMzMyaqaKEsl8nvyWm5jDFtXGtr5mZmbUcoRJq+y2lh/OMFfvurYtrfc3MzKylqJFTsWVu+ZV0QURcUNe8tRzX85qZmVmrodLq7aExLb+TGpi3Ahsxfjbj3/yw2GGYmZmZraAsW34j4v765q3wqmp9XdJgZmZmrUnZdHUm6S9A1LU+In6R94isXv17rc3Q/j2KHYaZmZkZ0HpadLNqqOV3YotEYWZmZmYlq5Rqfhsa4e223HlJq0fEksKGZGZmZmalpIRy32wPvEkaIGk68HI6v42kv2XYbz9Jr0iaKemcWtb3kDRO0guSpkg6oNFXYGZmZmZFI6CdlHkqtqy9PVwF7AssAIiIF4Fd69tBUjvgWmB/oA8wRFKfGpudC9wTEdsCRwANJtRmZmZm1rqUUm8Pmbs6i4i3ayz6qoFddgRmRsQbEfEFcDcwqOZhgaqhyLoC72SNx8zMzMxah1JKfrN2dfa2pO8CIakDcCowo4F9NgJyE+Y5QP8a21wAPCLp58AawF61HUjSCcAJAD16uKcDMzMzs9aklIY3zpr8ngRcTZLQvgM8DJych/MPAW6NiCskDQDukNQ3IpbnbhQRw4HhAJWVlXV2vWZmZpZva23UnWNvvJou661DRPD0/xvBf/92Mxtv3YehV19Kh46rsnzZMu467bfMmjSZHQcfwj5n/AxJLF20mBGn/Zq5LzXUXmTFdPtJZ/LSg4/Red1unDfxMQBuPPqnvPfqGwAsWfgJq3ftwrnPPlzMMFu1VlDKm1mm5DciPgB+1MhjzwU2yZnfOF2WaxiwX3qOZyR1BNYB5jfyXGZmVmCS9iNpCGkH3BQRlxY5pBbx1Vdf8a/fXMTbk6eyaqc1+M3TDzLjv0/yg9/9lgcu+TPTHhlH33334Ae/+y1X7v9DPpg1myv3PYwlHy9ky31258i//JHLBn6/2Jdh9Rhw5A8ZeOKx3PqT06qX/eT266pf/+uci1ita5da9jRIShkaM2RwsWXt7eEbku6X9L6k+ZJGSfpGA7tNAHpL6iVpFZIH2kbX2GY2sGd6jm8DHYH3G3cJ5W/E+NkMvuEZps/7pNihmFkblfEh5rL0ybvzeXvyVAA+X/wp777yGmtuuAERQcfOnQDo2KUzH7/7HgBvjJ/Eko8XAvDmc8+z1kbdixO4ZdZ75++w+tpr1rouIph03xgqf1jzsSXLVY41vyNIbnqHpPNHAHexcg1vtYhYJukUkhKJdsAtETFN0kXAxIgYDZwJ3CjpdJKH346NCJc11DBq8lymz/uEPt27eGhjMyuW6oeYASRVPcQ8vahRtbBuPTZmk2368uaEF/jnry7gF6Pu5NA//A8VFRX8cY+Vk6OdjjmCqY+MK0Kkli8z/3c8nddbh/U371XsUFo1lVDdQ9bkd/WIuCNn/u+Szmpop4gYC4ytsey8nNfTgZ0yxtCm9enehX+cOKDYYZhZ25XlIeYVHlDu1CraePJn1TVW54QRw7nnVxewdNFidj3+aP559oW8MGos2//gQI667nKuPnBI9fZb7Ppdvnv0EVy+9yH1HNVauwn/HMUObvVtUCn9ttdb9iBpbUlrAw9KOkdST0mbSvoVNZJaMzOziBgeEZURUdmxpP47rF9F+/acMGI4z/1jJJNHPwjAgB8dxgujkv8KJ903hp7b96vefqO+3+aoa//IdYN/zKcfflyEiC0fvlq2jBdGPUTlYQcVO5RWrTElD63hrtBQy+8kknKEqlhPzFkXwK8LEZR9bcT42Yx/80P691q72KGYWduW5SHmsnX0dZfz7iszeewvN1Yv+3jee2yxywBefeoZvjlwJ+a//iYAa228ISeOuJH/d/ypzJ/5ZrFCtjx4+b9PscE3N3PddkOk8il7iAgXuBTZqMnJ/y2u9TWzIqt+iJkk6T0CGFrckFrGZgN24DtDD2PO1Bn89pmkq6tRF1zG30/5FYf/6ULatW/Pl0s/585Tzgbge78+nTXWXpMhV/0BgOXLlnHJLt8rWvzWsJuOOZlXn3qWxQs+5JzeO/D9c89kp2OOYMK/RrvkIaOK0sl9UdbnyyT1JXnCt2PVsoi4vUBx1amysjImTpzY0qctmsE3PAPgel+zNkDSpIioLHYcdZF0AMlw91UPMf++vu3XVbs4lNVbIjRrQdd/OqfYIVieVe48kInPv9Dk9HXLVVaNERtkbx3v9/ZbRb3XZXrgTdL5wECS5HcsSVc3TwMtnvyamVlx1PYQs5kZKq1BLrL2SXwYSX+870bEccA2QNeCRWXA1/W+ZmZmZq2Z0rrfLFOxZe3q7LOIWC5pmaQuJCOwbdLQTtY8rvc1MzOzUtAKctrMsia/EyWtCdxI0gPEYuCZQgVlX+vfa22G9u9R7DDMzMzM6tQaWnSzypT8RsTP0pfXS3oI6BIRUwoXlrmLMzMzMysFooxafiVtV9+6iHg+/yEZuOTBzMzMSoSgooSy34Zafq+oZ10Ae+QxFqvBJQ9mZmZWCvKV+0rahKQ3sfVJcs3hEXF1OuLwP4CewCzg8Ij4SEm9xdXAAcAS4NiGGmcbGuRi9+ZehJmZmZmVs7z24rAMODMinpfUGZgk6VHgWOCxiLhU0jnAOcDZJN3v9k6n/sB16c86Ze3qzMzMzMxsJQJUkX2qT0TMq2q5jYhFwAxgI2AQcFu62W3AwenrQcDtkXgWWFNSvSNuZO3twczMzMxsZWp0bw/rSModrnd4RAxf6bBST2BbYDywfkTMS1e9S1IWAUli/HbObnPSZfOog5NfMzMzM2uWiopGJb8fNDS8saROwL3AaRHxSW5yHREhKZoUKBnLHpQ4UtJ56XwPSTs29aRWtxHjZzP4hmeYPu+TYodiZmZmlomUfWr4WOpAkvjeGRH3pYvfqypnSH/OT5fPZcWB1zZOl9Upa83v34ABwJB0fhFwbcZ9rRFGTZ7L9Hmf0Kd7F3dzZmZmZq2eSLo6yzrVe6ykifdmYEZEXJmzajRwTPr6GGBUzvKj04ba7wALc8ojapW17KF/RGwn6QWAtGuJVTLua43Up3sX/nHigGKHYWZmZtawjC26Ge0EHAW8JGlyuuw3wKXAPZKGAW8Bh6frxpJ0czaTpKuz4xo6Qdbk90tJ7Uj6W0PSusDyjPuamZmZWRnLV1dnEfE0SWNybfasZfsATm7MObKWPVwDjATWk/R74GngD405kZmZmZmVp3zW/BZappbfiLhT0iSSjFvAwRExo6CRmZmZmVmrJ1pHUptVpuRX0jXA3RHhh9zMzMzM7GsSalxXZ0WVtexhEnCupNclXS6p3r7ZzMzMzKztKMeyh9uA2yStDRwKXCapR0T0Lmh0ZWDE+NmMmlxvd3MrqOrmzMzMzKxUNNSFWWuSteW3yubAt4BNgZfzH075qeq3Nyv372tmZmalpKrmt6xafiX9ETgEeB34B3BxRHxcwLjKivvtNTMzs7KlRg9vXFRZ+/l9HRgQER8UMpjWrLHlC1VcxmBmZmblLl/9/LaEepNfSd+KiJeBCUAPST1y10fE84UMrjXJHXa4MVzGYGZmZuWuhHLfBlt+zwBOAK6oZV0Ae+Q9olbM5QtmZmZmK0pqfksn+603+Y2IE9KX+0fE0tx1kjoWLCozMzMzKw0CNbYLhSLKGur/ZVxWdkaMn83gG55pVI8NZmZmZm2HkLJPxdZQze8GwEbAapK2JWnZBugCrF7g2FqF3Fpf1+6amZmZ1aKMenvYFzgW2Bi4Mmf5IuA3BYqp1XGtr5mZmVk9WkGLblYN1fxWjex2aETc29iDS9oPuBpoB9wUEZfWss3hwAUkD9C9GBFDG3seMzMzMysSldEDb5KOjIi/Az0lnVFzfURcWctuVfu2A64F9gbmABMkjY6I6Tnb9AZ+DewUER9JWq+J15F3Vf36up9eMzMzswaUUdnDGunPTk049o7AzIh4A0DS3cAgYHrONj8Bro2IjwAiYn4TzlMQrvU1MzMzy6KVjFucUUNlDzekPy9swrE3At7OmZ8D9K+xzRYAkv6XpDTigoh4qAnnKgjX+ppZuZD0F5LyslpFxC9aMBwzKyMSqIxafgGQ9Efgd8BnwEPA1sDpaUlEc8/fGxhI8lDdk5K2ioiPa5z/BJLBNujRoweFNmL8bMa/+SH9e61d8HOZmbWQicUOwMzKl9qVTke/mZJfYJ+I+JWkQ4BZwA+AJ4H6kt+5wCY58xuny3LNAcZHxJfAm5JeJUmGJ+RuFBHDgeEAlZWVdbZc5MuoyUmYLncws3KRPsBcTdLqEbGkWPGYWZkpobKHrGl6VZL8PeCfEbEwwz4TgN6SeklaBTgCGF1jm3+TtPoiaR2SMog3MsZUUP17rc3Q/oVvZTYza0mSBkiaDryczm8j6W9FDsvMSpmUPPCWdSqyrMnvGEkvA9sDj0laF1ha3w4RsQw4BXgYmAHcExHTJF0k6aB0s4eBBemNeBxwVkQsaMqFmJlZJleR9OG+ACAiXgR2LWZAZlb6ymaEtyoRcU5a97swIr6S9ClJzw0N7TcWGFtj2Xk5rwM4I53MzKwFRMTbNf4D+qpYsZhZmWgFLbpZZX3grQNwJLBresN8Ari+gHGZmVlhvC3pu0Ck9/ZTSb6dMzNrGlFSNb9ZH3i7DugAVNWFHZUuO74QQZmZWcGcRDLy5kbAOyTlZycXNSIzK3kqnc4eMie/O0TENjnz/5X0YiECKiaP6mZm5S4iPgB+VOw4zKzMlFDLb9Y8/StJm1XNSPoGZVgj5lHdzKzcSfqGpPslvS9pvqRR6T3dzKxpJFSRfSq2rC2/ZwHjJL1BUtmxKXBcwaIqIo/qZmZlbgRwLXBIOn8EcBcrj8BpZpZdCbX8Npj8pt2aLQR2BNZLF78SEZ8XMjAzMyuI1SPijpz5v0s6q2jRmFl5aAUtulnVm/xKOh74A/A60As4ISJqDlRhZmatnKSq8doflHQOcDcQwGBqdElpZtYYUnkNb3wasGVEvJ/WhN3JyqO0mZlZ6zeJJNmtap45MWddAL9u8YjMrEyorMoevoiI9wEi4g1Jq7ZATGZmlmcR0avYMZhZ+WoNI7dl1VDyu7Gka+qaj4hfFCYsMzMrFEl9gT5Ax6plEXF78SIys5Imyqfml6SXh1yTChWImZkVnqTzgYEkye9YYH/gacDJr5k1Wdm0/EbEbS0ViJmZtYjDgG2AFyLiOEnrA38vckxmVupKqOW33kfzJN2Yfj1W27o1JP1YkkcKMjMrHZ9FxHJgmaQuwHxgkyLHZGalTGrc1ODhdEs6CM/UnGUXSJoraXI6HZCz7teSZkp6RdK+DR2/obKHa4HzJG0FTAXeJ6kR6w10AW4h6QGiZFUNaQx4WGMzawsmSloTuJGklG0x8ExRIzKzkpfnkdtuBf7KyuVYf46Iy1c4r9SHZLCeLYENgf9I2iIi6hyJuKGyh8nA4ZI6AZVAd+AzYEZEvNK462idcoc09rDGZlbuIuJn6cvrJT0EdImIKcWMyczKQB5rfiPiSUk9M24+CLg7HXztTUkzSQZmq/OP+kzDG0fEYuDxjEGUHA9pbGblTtJ29a2LiOdbMh4zKyMt19vDKZKOBiYCZ0bER8BGwLM528xJl9UpU/JrZmYl74p61gWwR75PuOm2W3HdE4/l+7BWZLHow2KHYPn21bJmH6KRvT2sI2lizvzwiBjewD7XAReT3K8uJrmn/bhRQaac/JqZtQERsXuxYzCzcqXGtvx+EBGVjdkhIt6rPpt0IzAmnZ3Lig/tbpwuq1OjBmKWtHpjtjczMzOzMiegoiL71JRTSN1zZg8h6YgBYDRwhKRVJfUi6ZThufqOlanlV9J3gZuATkAPSdsAJ+Y8OGFmZmZmbVUeH3iTdBfJYDzrSJoDnA8MlNSPpOxhFnAiQERMk3QPMB1YBpxcX08PkL3s4c/AviTZNRHxoqRdG3sxZmZmZlZu1OQW3dpExJBaFt9cz/a/B36f9fiZI42It2ssqjerNjOz1keJIyWdl873kLRjseMysxKXx0EuCi1r8vt2WvoQkjpI+iUwo4BxmZlZYfwNGABUtawsIhnQyMysaURJJb9Zyx5OAq4m6TdtLvAI4HpfM7PS0z8itpP0AkBEfCRplWIHZWYlrhUktVllTX6/GRE/yl0gaSfgf/MfkpmZFdCXktqRPDSCpHWB5cUNycxKW35rfgsta6R/ybjMzMxat2uAkcB6kn4PPA38obghmVnJK5eyB0kDgO8C60o6I2dVF6BdIQMzM7P8i4g7JU0C9iSp1Ds4IvwMh5k1XVXNb4loqOxhFZK+fdsDnXOWfwIcVqigzMysMCT1AJYA9+cui4jZxYvKzEpeuSS/EfEE8ISkWyPirRaKyczMCucBknpfAR2BXsArwJbFDMrMSllp1fxmfeBtiaQ/kdwcO1YtjIg9ChKVmZkVRERslTsvaTvce4+ZNUfV8MYlImukdwIvk7QQXEgyrNyEAsVkZmYtJCKeB/oXOw4zK3Hl8sBbjm4RcbOkU3NKIZz8mpmVmBoPL1cA2wHvFCkcMysDQqiEWn6zJr9fpj/nSfoeyY1y7cKEZGZmBZT78PIykhrge4sUi5mVi1bQoptV1uT3d5K6AmeS9O/bBTitUEGZmVn+pYNbdI6IXxY7FjMrIyXW1VmmNuqIGBMRCyNiakTsHhHbAx82tJ+k/SS9ImmmpHPq2e5QSSGpshGxm5lZRpLaR8RXwE7FjsXMylC51PymrQSHAxsBD0XEVEkHAr8BVgO2bWDfa4G9gTnABEmjI2J6je06A6cC45tzIU0xYvxsxr/5If17uYLDzMrecyT1vZMljQb+CXxatTIi7itWYGZW6sqrq7ObgU1IbprXSHoHqATOiYh/N7DvjsDMiHgDQNLdwCBgeo3tLgYuA85qXOjNN2ryXAAG9duopU9tZlYsHYEFwB583d9vAE5+zazpWkGLblYNJb+VwNYRsVxSR+BdYLOIWJDh2BsBb+fMz6FGdzpp/5KbRMQDklo8+QXo32tthvbvUYxTm5m1pPXSnh6m8nXSWyWKE5KZlYUSq/ltKPn9IiKWA0TEUklvZEx8GySpArgSODbDticAJwD06OFE1cysCdqRDFdf2/9QTn7NrHnKKPn9lqQp6WsBm6XzAiIitq5n37kkJRNVNk6XVekM9AUeV/KGbQCMlnRQREzMPVBEDAeGA1RWVublJu16XzNrY+ZFxEXFDsLMylF51fx+uxnHngD0ltSLJOk9AhhatTIiFgLrVM1Lehz4Zc3Et1Bc72tmbUzpNMuYWekpl5bfiHirqQeOiGWSTgEeJvm67ZaImCbpImBiRIxu6rHzxfW+ZtaG7FnsAMysTEnQrl2xo8gs6yAXTRIRY4GxNZadV8e2AwsZi5lZWxYRDfbNbmbWZOXS8mtmZmZm1qASSn4zVydLWk3SNwsZjJmZmZmVmKquzkpkhLdMya+k7wOTgYfS+X7pCEFmZmZm1qalvT1knYosawQXkIzY9jFAREwGehUkIjMzMzMrLSXU8pu15vfLiFioFQN2p+hmZmZm1iqS2qyyJr/TJA0F2knqDfwC+L/ChWVmZmZmJUGAil/OkFXWSH8ObAl8DowAFgKnFSgmMzMzMysZgopGTEWWteX3WxHxW+C3hQzGzMzMzEpQGbb8XiFphqSLJfUtaERmZmZmVlpK6IG3TMlvROwO7A68D9wg6SVJ5xY0MjMzMzNr/aqGN846FVnmNuqIeDcirgFOIunzt9Zhis3MzMysjVFF9qnIMtX8Svo2MBg4FFgA/AM4s4BxmZmZmVmpaAXlDFllfeDtFpKEd9+IeKeA8ZiZmZlZKZFaxchtWWVKfiNiQKEDMTMzM7MSVUItv/Wm6ZLuSX++JGlKzvSSpCktE6KZmZmZtWp5rPmVdIuk+ZKm5ixbW9Kjkl5Lf66VLpekayTNTHPU7Ro6fkMtv6emPw9sMFIzMzMza3uU98ErbgX+Ctyes+wc4LGIuFTSOen82cD+QO906g9cl/6sU73pd0TMS1/+LCLeyp2AnzXhYszMzMys3OSx5TcingQ+rLF4EHBb+vo24OCc5bdH4llgTUnd6zt+1urkvWtZtn/Gfc3MzMysnDVukIt1JE3MmU7IcIb1cxpl3wXWT19vBLyds92cdFmd6i17kPRTkhbeb9So8e0M/G+GQM3MzMysrKmx/fd+EBGVTT1bRISkaOr+DdX8jgAeBC4hqa2osigiajZHm5mZmVlbI/Jd81ub9yR1j4h5aVnD/HT5XGCTnO02TpfVqaE0PSJiFnAysChnQtLaTQjczMzMzMpNRbvsU9OMBo5JXx8DjMpZfnTa68N3gIU55RG1ytLyeyAwCQiS3L5KAN9oZOBmZmZmVk7y3NuDpLuAgSS1wXOA84FLgXskDQPeAg5PNx8LHADMBJYAxzV0/HqT34g4MP3Zq4nxm5mZmVm5a1zNb70iYkgdq/asZdsgqVDILFOkknaStEb6+khJV0rq0ZgTmZmZmVmZalxvD0WVNU2/DlgiaRvgTOB14I6CRWVmZmZmJUJ57ee30LJGsCxtVh4E/DUiriXp7szMzMzM2rKq3h6yTkXW0ANvVRZJ+jVwFLCLpAqgQ+HCMjMzM7OS0QpadLPKGulg4HPgxxHxLkkfan8qWFRmZmZmVjpKqOY3U8tvRLwr6U5gB0kHAs9FxO2FDS3/RoyfzajJSb/H0+d9Qp/uXYockZmZlZIP57zDbSeeySfzP0ASOx87hD1+dhz3nvsHXnrwMdqv0oF1em3K0X/7E6uv6f9jSsWXSz/nioOPY9kXX7J82TK2PXBvvv+rn3H5oGP5fPESABZ98CE9t+3LSbdeVdxgWyVBRem0/GZKfiUdTtLS+zhJZcdfJJ0VEf8qYGx5N2ry3Oqkt0/3LgzqV+/Qz2ZmlkPSLSR9v8+PiL7FjqcY2rVvz6G//y09+vVl6aLFXLLr9/n2Hjvz7d135uALfkW79u0Zed6lPHzl3zjkonMaPqC1Cu1XXYXT7r2JjmuszldffsnlBx3LlnvuzC9H3Vq9zQ3DzmCbfXcvXpCtmWgVLbpZZa35/S2wQ0TMB5C0LvAfoKSSX4A+3bvwjxMHFDsMM7NSdCvwV6DkvvnLl64brEfXDdYDoGPnTmzwzc35+J136bPnrtXb9NphW57/94PFCtGaQBId11gdgK++XMZXy5atkMt9tmgxrzz9HEdfdVGRIiwBJVTzmzX5rahKfFMLyF4vbGZmZSAinpTUs9hxtBYL3prD21Om07Oy3wrL/++Oe9j+BwcWJyhrsuVffcUl+wzh/Tdns9txg+m13dbV6158cBzf2rk/q3XuVMQIW7PWUcubVdYE9iFJD0s6VtKxwAMkw8mVjBHjZzP+zQ+LHYaZWVmTdIKkiZImvv/BgmKHUzBLF3/KDUf9lB9e+j+s1uXrnj8f/NNfqWjfnh0HH1y84KxJKtq147eP3cMfXniEWS9MZe6M16rXTRj5IJWH7F/E6Fo5Ae3aZZ+KLFPyGxFnATcAW6fT8Ig4u5CB5VvVg26u8zUzK5yIGB4RlRFRue463YodTkF89eWXDD/yp+x4+CC2PWi/6uXP3PkvXnrov/z4pqtQCbWC2YpW79qFLXbagenj/g+AxQs+4q3JU9lqr12KHFlrVkaDXEjqLWmUpKnAD4ErIuKMiBiZ5eCS9pP0iqSZklaq/Jd0hqTpkqZIekzSpk27jGz691qbof09KrOZmTVNRHDHyWezwTc3Z69Tjq9ePu3RJ3jkqhv46T9uZJXVVytihNYUiz74kCULPwHgi8+WMuPJZ9lg854APD/mUfrutSsdOq5axAhLQBl1dXYLyYMNTwLfB/4C/CDLgSW1A64F9gbmABMkjY6I6TmbvQBURsQSST8F/kjSp7CZmVmr8/qzExl/90g22vKb/H6nAwAYdN5Z3POrC1n2xRdcM+goIHnobehVvy9mqNYIC+d/wG2/OJf4ajnLly9n+4P2Yat9dgNg4r8fZt+f/7jIEZaAVtCim1VDyW/niLgxff2KpOcbcewdgZkR8QaApLtJhkeuTn4jYlzO9s8CRzbi+GZm1oIk3QUMBNaRNAc4PyJuLm5ULWvzATtw3SdvrrS8r7vAKmkb99mC3/7nnlrXnTGyTf0Tbxq1jmGLs2oo+e0oaVuSUmaA1XLnI6K+ZHgj4O2c+TlA/3q2HwbU2jeMpBOAEwB69HDZgplZMUTEkGLHYGatVBm1/M4DrsyZfzdnPoA98hGEpCOBSmC32tZHxHBgOEBlZWXk45xmZmZmlietoJY3q3qT34hozvc4c4FNcuY3TpetQNJeJINo7BYRnzfjfGZmZmbW4lRWLb/NMQHoLakXSdJ7BDA0d4O0hOIGYL8ag2iYmZmZWYkope79Cpb8RsQySacADwPtgFsiYpqki4CJETEa+BPQCfhn+qbNjoiDChWTmZmZmeWZcMtvlYgYS42R4CLivJzXexXy/GZmZmZWaGVY9qCkWfZHwDci4iJJPYANIuK5gkZnZmZmZq1fKxi2OKusafrfgAFAVTc3i0gGsDAzMzOztkyU1QhvVfpHxHaSXgCIiI8krVLAuMzMzMysJJRh2QPwZTpccQBIWhdYXrCozMzMzKx0tIIW3ayyJr/XACOB9ST9HjgMOLdgUZmZmZlZ6Si3lt+IuFPSJGBPksqOgyNiRkEjMzMzM7PWT4KKMmv5TXt3WALcn7ssImYXKjAzMzMzKxHl1vILPEBS7yugI9ALeAXYskBxmZmZmVmpKLea34jYKnde0nbAzwoSkZmZmZmVkPLs7WEFEfG8pP75DsbMzMzMSlC5tfxKOiNntgLYDninIBGZmZmZWekQZdny2znn9TKSGuB78x+OmZmZmZUWQUUZJb/p4BadI+KXLRCPmZmZmZUYVbQrdgiZ1Zv8SmofEcsk7dRSAZmZmZlZCRFlVfP7HEl972RJo4F/Ap9WrYyI+woYm5mZmZm1euXZ20NHYAGwB1/39xuAk18zMzOzti6PLb+SZgGLgK+AZRFRKWlt4B9AT2AWcHhEfNSU4zeU/K6X9vQwla+T3irRlBOamZmZWZnJ/wNvu0fEBznz5wCPRcSlks5J589uyoEbSn7bAZ1YMemt4uTXzMzMrK2TWqLmdxAwMH19G/A4BUp+50XERU05sJmZmZm1EY2r+V1H0sSc+eERMTxnPoBHJAVwQ7pu/YiYl65/F1i/qaE2lPyWzqN7ZmZmZlYcjWv5/SAiKutZv3NEzJW0HvCopJdzV0ZEpIlxkzSUpu/Z1AObmZmZWVuhRkz1i4i56c/5wEhgR+A9Sd0B0p/zmxppvclvRHzY1AObmZmZWVugr+t+s0z1HUlaQ1LnqtfAPiQdL4wGjkk3OwYY1dRos3Z1VtJGjJ/N+Dc/pH+vtYsdipmZmVn5yd8Db+sDI5Ucrz0wIiIekjQBuEfSMOAt4PCmnqBNJL+jJs8FYFC/jYociZmZmVmZEXkb5CIi3gC2qWX5AvJUjtsmkl+A/r3WZmj/HsUOw8zMzKz8lFAXCW0m+bXi+fLLL5kzZw5Lly4tdihmrULHjh3ZeOON6dChQ7FDMTPLk9LJfp38WsHNmTOHzp0707NnT1T4TrDNWrWIYMGCBcyZM4devXoVOxwzszxokUEu8ibvY9GZ1bR06VK6devmxNcMkES3bt38TYiZlZc89fbQEtzyay3Cia/Z1/z7YGblp3Tua05+zczMzKx5SuiPepc9WJvQqVOnZh9j4sSJ/OIXv6hz/axZsxgxYkTm7QF69uzJVlttxdZbb81uu+3GW2+91ew48+X666/n9ttvz8ux5s2bx4EHHrjCstNOO42NNtqI5cuXVy+74IILuPzyy1fYrmfPnnzwwQcAvPvuuxxxxBFsttlmbL/99hxwwAG8+uqrzYrt888/Z/DgwWy++eb079+fWbNm1brd1VdfTd++fdlyyy256qqrqpd/+OGH7L333vTu3Zu9996bjz76CIAxY8Zw3nnnNSs2M7PSkb8R3grNya9ZRpWVlVxzzTV1rq+Z/Da0fZVx48YxZcoUBg4cyO9+97tmxxkRKySUTXXSSSdx9NFHN/s4AFdeeSU/+clPqueXL1/OyJEj2WSTTXjiiScyHSMiOOSQQxg4cCCvv/46kyZN4pJLLuG9995rVmw333wza621FjNnzuT000/n7LPPXmmbqVOncuONN/Lcc8/x4osvMmbMGGbOnAnApZdeyp577slrr73GnnvuyaWXXgrA9773Pe6//36WLFnSrPjMzFq9xtT7toIWYpc9WIu68P5pTH/nk7wes8+GXTj/+1s2er/Jkydz0kknsWTJEjbbbDNuueUW1lprLSZMmMCwYcOoqKhg77335sEHH2Tq1Kk8/vjjXH755YwZM4YnnniCU089FUjqN5988knOOeccZsyYQb9+/TjmmGPYdtttq7dfvHgxP//5z5k4cSKSOP/88zn00ENXiGfAgAHVyfL777/PSSedxOzZswG46qqr2GmnnXj//fcZOnQo77zzDgMGDODRRx9l0qRJLF68mH333Zf+/fszadIkxo4dyz333MM999zD559/ziGHHMKFF17Ip59+yuGHH86cOXP46quv+J//+R8GDx7MOeecw+jRo2nfvj377LMPl19+ORdccAGdOnXil7/8ZZ3v1cCBA+nfvz/jxo3j448/5uabb2aXXXZZ6b2+9957V0jsH3/8cbbccksGDx7MXXfdxe67797g5zVu3Dg6dOjASSedVL1sm21W6ge90UaNGsUFF1wAwGGHHcYpp5xCRKxQlztjxgz69+/P6quvDsBuu+3Gfffdx69+9StGjRrF448/DsAxxxzDwIEDueyyy5DEwIEDGTNmDIcf3uSBiMzMSkMrSGqzcsuvtVlHH300l112GVOmTGGrrbbiwgsvBOC4447jhhtuYPLkybRr167WfS+//HKuvfZaJk+ezFNPPcVqq63GpZdeyi677MLkyZM5/fTTV9j+4osvpmvXrrz00ktMmTKFPfbYY6VjPvTQQxx88MEAnHrqqZx++ulMmDCBe++9l+OPPx6ACy+8kD322INp06Zx2GGHVSfHAK+99ho/+9nPmDZtGq+88gqvvfYazz33HJMnT2bSpEk8+eSTPPTQQ2y44Ya8+OKLTJ06lf32248FCxYwcuRIpk2bxpQpUzj33HMzv1cAy5Yt47nnnuOqq65aYXmVN998k7XWWotVV121etldd93FkCFDOOSQQ3jggQf48ssv6/qYqk2dOpXtt9++we0AdtllF/r167fS9J///GelbefOncsmm2wCQPv27enatSsLFixYYZu+ffvy1FNPsWDBApYsWcLYsWN5++23AXjvvffo3r07ABtssMEKLdGVlZU89dRTmWI2MyttpVP2UNCWX0n7AVcD7YCbIuLSGutXBW4HtgcWAIMjYlYhY7LiakoLbSEsXLiQjz/+mN122w1IWux++MMf8vHHH7No0SIGDBgAwNChQxkzZsxK+++0006cccYZ/OhHP+IHP/gBG2+8cb3n+89//sPdd99dPb/WWmtVv95999358MMP6dSpExdffHH19tOnT6/e5pNPPmHx4sU8/fTTjBw5EoD99ttvheNsuummfOc73wHgkUce4ZFHHmHbbbcFYPHixbz22mvssssunHnmmZx99tkceOCB7LLLLixbtoyOHTsybNgwDjzwwJVqc+t6r6r84Ac/AGD77bevtV523rx5rLvuutXzX3zxBWPHjuXKK6+kc+fO9O/fn4cffpgDDzywzl4QGts7Qr4Tzm9/+9ucffbZ7LPPPqyxxhr069ev1j+MJK0Q63rrrcc777yT11jMzFqjUurFpmAtv5LaAdcC+wN9gCGS+tTYbBjwUURsDvwZuKxQ8Zjl0znnnMNNN93EZ599xk477cTLL7/c5GONGzeOt956i379+nH++ecDSU3ss88+y+TJk5k8eTJz585t8KG9NdZYo/p1RPDrX/+6ev+ZM2cybNgwtthiC55//nm22morzj33XC666CLat2/Pc889x2GHHcaYMWPYb7/9GhV/VYtuu3btWLZs2UrrV1tttRX6tH344Yf5+OOP2WqrrejZsydPP/00d911FwDdunWrfmCsyqJFi1hzzTXZcsstmTRpUqaYGtPyu9FGG1W34i5btoyFCxfSrVu3lbYbNmxYdQv6WmutxRZbbAHA+uuvz7x584Ak0V9vvfWq91m6dCmrrbZappjNzEqXQBXZpyIrZAQ7AjMj4o2I+AK4GxhUY5tBwG3p638Be6qU/nSwktW1a1fWWmut6hbCO+64g912240111yTzp07M378eIAVWmtzvf7662y11VacffbZ7LDDDrz88st07tyZRYsW1br93nvvzbXXXls9XzPBa9++PVdddRW33347H374Ifvssw9/+ctfqtdPnjwZSFqc77nnHiBp3a15nCr77rsvt9xyC4sXLwaSr/bnz5/PO++8w+qrr86RRx7JWWedxfPPP8/ixYtZuHAhBxxwAH/+85958cUXM71XWW2xxRYrtAjfdddd3HTTTcyaNYtZs2bx5ptv8uijj7JkyRJ23XVXRo8eXf0+3nfffWyzzTa0a9eOPfbYg88//5zhw4dXH2vKlCm1tvI+9dRT1Yl/7rTXXnuttO1BBx3Ebbclt6F//etf7LHHHrW2YMyfPx+A2bNnc9999zF06NCV9r/tttsYNOjr29yrr75K3759M79XZmYlyw+8AbAR8HbO/Bygf13bRMQySQuBbsAHuRtJOgE4AaBHjx6NDqTPhl0avY+VlyVLlqxQmnDGGWdw2223VT/E9Y1vfIP/9//+H5A8/f+Tn/yEiooKdtttN7p27brS8a666irGjRtHRUUFW265Jfvvvz8VFRW0a9eObbbZhmOPPba65ADg3HPP5eSTT6Zv3760a9eO888/v7pcoEr37t0ZMmQI1157Lddccw0nn3wyW2+9NcuWLWPXXXfl+uuv5/zzz2fIkCHccccdDBgwgA022IDOnTtXJ7lV9tlnH2bMmFFdvtGpUyf+/ve/M3PmTM466ywqKiro0KED1113HYsWLWLQoEEsXbqUiODKK69c6Xrreq+yWGONNdhss82YOXMmG264IQ899BDXX3/9Cut33nln7r//fgYPHswpp5zCzjvvjCTWW289brrpJiD5Sm3kyJGcdtppXHbZZXTs2JGePXuu0O1YUwwbNoyjjjqKzTffnLXXXrv6D5533nmH448/nrFjxwJw6KGHsmDBAjp06MC1117LmmuuCSTfAhx++OHcfPPNbLrpptV/nEDSqn/JJZc0Kz4zs1ZPtIqkNitFRGEOLB0G7BcRx6fzRwH9I+KUnG2mptvMSedfT7f5oLZjAlRWVsbEiRMLErMVxowZM/j2t79d7DAyW7x4cXWJwaWXXsq8efO4+uqrixxV4vPPP6ddu3a0b9+eZ555hp/+9KfVrcKt2ciRI5k0aVJeunIrFe+99x5Dhw7lscceq3V9bb8XkiZFRGVLxNcSKrfrFxOeqP36rYQtyW+PPVZ8O+xzEBNffKnJ2WvlttvExP8+nHl7rd29qPe6Qrb8zgU2yZnfOF1W2zZzJLUHupI8+GZWNA888ACXXHIJy5YtY9NNN+XWW28tdkjVZs+ezeGHH87y5ctZZZVVuPHGG4sdUiaHHHLISj0olLvZs2dzxRVXFDsMM7OWUUItv4VMficAvSX1IklyjwCG1thmNHAM8AxwGPDfKFRTtFlGgwcPZvDgwcUOo1a9e/fmhRdeKHYYTVLVXVtbscMOOxQ7BDOzllM6uW/hkt+0hvcU4GGSrs5uiYhpki4CJkbEaOBm4A5JM4EPSRJkK0M1Bw0wa8v8N76ZlZfW0X9vVgXt5zcixgJjayw7L+f1UuCHNfez8tKxY0cWLFhAt27dnABbmxcRLFiwgI4dOxY7FDOz/Cmh/989vLEV3MYbb8ycOXN4//33ix2KWavQsWPHBgdGMTMrGSXW24OTXyu4Dh060KtXr2KHYWZmZgXj5NfMzMzM2gq3/JqZmZlZ26BWMWxxVk5+zczMzKx5Sqjlt2AjvBWKpPeBt5qw6zrUGDa5DPkaS1+5Xx/4GuuzaUSsm+9giqUZ9+tS1Bb+Xbc1bekzbda9R9JDJO9XVh9ExH5NPV9zlVzy21SSJpbTsKG18TWWvnK/PvA1WnnyZ15+/JmWr9Ip0DAzMzMzayYnv2ZmZmbWZrSl5Hd4sQNoAb7G0lfu1we+RitP/szLjz/TMtVman7NzMzMzNpSy6+ZmZmZtXFOfs3MzMyszSi75FfSfpJekTRT0jm1rF9V0j/S9eMl9SxCmM2S4RrPkDRd0hRJj0natBhxNlVD15ez3aGSQlLJdUWT5RolHZ5+jtMkjWjpGJsrw7/THpLGSXoh/bd6QDHibCpJt0iaL2lqHesl6Zr0+qdI2q6lY7TCy3q/stLR0O+2lb6ySn4ltQOuBfYH+gBDJPWpsdkw4KOI2Bz4M3BZy0bZPBmv8QWgMiK2Bv4F/LFlo2y6jNeHpM7AqcD4lo2w+bJco6TewK+BnSJiS+C0lo6zOTJ+jucC90TEtsARwN9aNspmuxWor5P2/YHe6XQCcF0LxGQtKOv9ykrOrdT/u20lrqySX2BHYGZEvBERXwB3A4NqbDMIuC19/S9gT6mExuTLcI0RMS4ilqSzzwIbt3CMzZHlMwS4mOQPl6UtGVyeZLnGnwDXRsRHABExv4VjbK4s1xhAl/R1V+CdFoyv2SLiSeDDejYZBNweiWeBNSV1b5norIVkvV9ZCcnwu20lrtyS342At3Pm56TLat0mIpYBC4FuLRJdfmS5xlzDgAcLGlF+NXh96dfHm0TEAy0ZWB5l+Qy3ALaQ9L+SnpVUaq0QWa7xAuBISXOAscDPWya0FtPY31UrPf6MzUpQ+2IHYIUj6UigEtit2LHki6QK4Erg2CKHUmjtSb4uH0jScv+kpK0i4uNiBpVnQ4BbI+IKSQOAOyT1jYjlxQ7MzMzKV7m1/M4FNsmZ3zhdVus2ktqTfN26oEWiy48s14ikvYDfAgdFxOctFFs+NHR9nYG+wOOSZgHfAUaX2ENvWT7DOcDoiPgyIt4EXiVJhktFlmscBtwDEBHPAB2BdVokupaR6XfVSpo/Y7MSVG7J7wSgt6ReklYheYhmdI1tRgPHpK8PA/4bpTXSR4PXKGlb4AaSxLfUakXrvb6IWBgR60REz4joSVLTfFBETCxOuE2S5d/pv0lafZG0DkkZxBstGGNzZbnG2cCeAJK+TZL8vt+iURbWaODotNeH7wALI2JesYOyvMry79zMWpmyKnuIiGWSTgEeBtoBt0TENEkXARMjYjRwM8nXqzNJCtqPKF7EjZfxGv8EdAL+mT7LNzsiDipa0I2Q8fpKWsZrfBjYR9J04CvgrIgomW8oMl7jmcCNkk4nefjt2FL6Q1TSXSR/oKyT1i2fD3QAiIjrSeqYDwBmAkuA44oTqRVKXf/OixyWNVNtv9sRcXNxo7J88vDGZmZmZtZmlFvZg5mZmZlZnZz8mpmZmVmb4eTXzMzMzNoMJ79mZmZm1mY4+TUzMzOzNsPJb4mS9JWkyTlTz3q2XZyH890q6c30XM+nI3I19hg3SeqTvv5NjXX/19wY0+NUvS9TJd0vac0Gtu8n6YAmnKe7pDHp64GSFqbnnSHp/CYc7yBJ56SvD656n9L5i9JBS5ol/QwPa2CbxxszYEh67WMybHeLpPmSptZYfrmkPbKez6ytqXFP+6ek1ZtxrOp7QO79uI5tB0r6bhPOMSvtmzzT8hrbNOr/KkkXSPplY2M0c/Jbuj6LiH4506wWOOdZEdEPOIdkEI1GiYjjI2J6OvubGusafZOtQ9X70pekH+eTG9i+H0lfrI11BnBjzvxT6XtTCRwpabvGHCwiRkfEpenswUCfnHXnRcR/mhBja3IrsF8ty/9C8u/JzGqXe0/7Ajgpd2U6Ummj1bgf12YgkK/7slmr4uS3TEjqJOmxtFX2JUmDatmmu6Qnc1oRdkmX7yPpmXTff0rq1MDpngQ2T/c9Iz3WVEmnpcvWkPSApBfT5YPT5Y9LqpR0KbBaGsed6brF6c+7JX0vJ+ZbJR0mqZ2kP0maIGmKpBMzvC3PABulx9kxvcYXJP2fpG8qGZHpImBwGsvgNPZbJD2XbrvS+5g6FHio5sKI+BSYBGyetio/m8Y7UtJaaSy/kDQ9XX53uuxYSX9NW1oOAv6UxrRZznuwn6R/5rw31a2ujf0MJZ2XvpdTJQ2XktFQUkfl/BvZMd0+6/tSq4h4kuSPkZrL3wK6SdqgMccza6OeIrm3DJT0lKTRwPS67o9K/FXSK5L+A6xXdSDlfMuT3lueT+/Zjyn5JvEk4PT0XrCLpHUl3ZueY4KkndJ9u0l6RNI0STcBogGS/i1pUrrPCTXW/Tld/pikddNlm0l6KN3nKUnfysu7aW1XRHgqwYlk1K/J6TSSZLS+Lum6dUhGlaoaxGRx+vNM4Lfp63ZA53TbJ4E10uVnA+fVcr5bgcPS1z8ExgPbAy8Ba5CMKDcN2JYkMbwxZ9+u6c/HgcrcmHK2qYrxEOC29PUqwNvAasAJwLnp8lWBiUCvWuJcnHN9/wT2S+e7AO3T13sB96avjwX+mrP/H4Aj09drAq9WvTc52/QCJuXMDwTGpK+7AbOALYEpwG7p8ouAq9LX7wCrVp2jZhy573XufPoZz875rK4DjmziZ7h2zvI7gO/nfEY3pq93BabW977UuPZK4KZ6/s32rDpejeU3AocW+3fKk6fWOOXc09oDo4Cfpr93n1bdA+u6PwI/AB5N74cbAh/n3AMeT39n1yW5z1Yda+305wXAL3PiGAHsnL7uAcxIX19Tdb8BvkcyWuM6tVzHrKrlOedYDZgKdEvnA/hR+vq8nHviY0Dv9HV/4L+1xejJU9aprIY3bmM+i+RrdgAkdQD+IGlXYDlJi+f6wLs5+0wAbkm3/XdETJa0G8lX7P+bNv6tQtJiWps/SToXeB8YBuwJjIyktRNJ9wG7kLSIXiHpMpLE6KlGXNeDwNWSViX5mvzJiPhM0j7A1vq6ZrUr0Bt4s8b+q0manF7/DJIbf9X2t0nqTXKD7VDH+fcBDtLXdWQdSW/0Odt0T9+DXLtIeoHkvb8UmEOS2D6Rrr+NJBmHJCm+U9K/gX/XEcdKIhlK9SHg+5L+RfIfza+AxnyGVXaX9CtgdWBtkj9c7k/X3ZWe70lJXZTUTdf1vuTGNxE4Puv15JhP8h+zma2s6p4GScvvzSTlCM9FRNX9r677467AXRHxFfCOpP/WcvzvkNxn3wSIiJW+oUntBfTJ+ZKoS/oN064kSTYR8YCkjzJc0y8kHZK+3iSNdQHJ/fMf6fK/A/el5/gu8M+cc6+a4RxmdXLyWz5+RPIX/PYR8aWkWSQJSrU0mdmVJGm6VdKVwEfAoxExJMM5zoqIf1XNSNqzto0i4lUlNa8HAL+T9FhEXJTlIiJiqaTHgX2BwcDdVacDfh4RDzdwiM8iop+Sh0IeJqn5vQa4GBgXEYekX+k9Xsf+ImmFfKW+c1DjvSWp+T2w+iBS13r2/x7JfxjfB34raat6tq3pbuAUkhKCiRGxKC1ZyPoZIqkj8DeSVvi3JV3AitdTc8zzoI73RdL6jYi9Lh1J3lMzW9kKDR0AaRL4ae4iark/qgkP89ajAvhORCytJZbMJA0kSaQHRMSS9H5f835aJdLzflzzPTBrDtf8lo+uwPw08d0d2LTmBpI2Bd6LiBuBm4DtgGeBnSRV1fCuIWmLjOd8CjhY0uqS1iApWXhK0obAkoj4O/Cn9Dw1fZm2QNfmH8BxfN2KDEki+9OqfSRtkZ6zVhGxBPgFcKaSB0K6AnPT1cfmbLqIpPyjysPAz9OEEknb1nL4V0m+wq9TRCwEPlJaVw0cBTwhqQLYJCLGkZQndCUpGclVM6ZcT5C8nz/h6z8MGvsZVv1H80HaqlKzB4iqGu2dgYXptWR5X5pqC5KvPs2saeq6Pz5J8kxDO0ndgd1r2fdZYFdJvdJ9106X17wPPQL8vGpGUr/05ZPA0HTZ/sBaDcTaFfgoTXy/RdLyXKWCr+9HQ4GnI+IT4E1JP0zPIUnbNHAOs3o5+S0fdwKVkl4CjgZermWbgcCL6dfzg4GrI+J9kmTwLklTSL4uz/QwQUQ8T1JH+hxJDfBNEfECsBXwXPpV3fnA72rZfTgwRekDbzU8QvJV/n8i4ot02U3AdOB5Jd1l3UAD31yksUwBhgB/BC5Jrz13v3EkX+VNVvJg3sUkJRFTJE1L52se91Pg9apksx7HkJSKTCHpVeIiktq7v6ef0wvANRHxcY397gbOUvJg2WY1zv0VMAbYP/1JYz/D9Hw3kiScD5OUw+Ramr5P15OUt0CG90XJw4w31XZOSXelcX1T0hxJw9LlHUgenpxYV7xm1qC67o8jgdfSdbdTSzlUev84gaTE4EW+Lju4HzgkvTfuQtKYUKnkgbrpfN3rxIUkyfM0kvKH2Q3E+hDQXtIMkhKxZ3PWfQrsmF7DHiT3TEi+2RyWxjcNaNQDt2Y1VT0QZWaNkNarbR8R5xY7llKWvo/bRcT/FDsWMzNrG1zza9YEETFSUrdix1EG2gNXFDsIMzNrO9zya2ZmZmZthmt+zczMzKzNcPJrZmZmZm2Gk18zMzMzazOc/JqZmZlZm+Hk18zMzMzajP8PD8cCv/JIhIIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (10, 4))\n",
    "plot_roc_curve(log_model, X_val, y_val, ax = ax[0])\n",
    "plot_confusion_matrix(log_model, X_val, y_val, cmap=plt.cm.Reds, ax = ax[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-lobby",
   "metadata": {},
   "source": [
    "### Keeping metrics logs in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "opened-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "EXPERIMENT_NAME = '[v1.5] [customers_whole] [Consumer Behavior Analytics] [Renan Moises]'\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment_id = client.create_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "accomplished-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "metrics = [accuracy_score, precision_score, recall_score, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "impossible-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.create_run(experiment_id)\n",
    "\n",
    "client.log_param(run.info.run_id, 'model', 'LogistRegression-Baseline')\n",
    "\n",
    "for metric in zip(metrics_names, metrics):\n",
    "    client.log_metric(run.info.run_id, metric[0], metric[1](y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-expansion",
   "metadata": {},
   "source": [
    "## Modelling for Real\n",
    "\n",
    "- LogisticRegression (tunned)\n",
    "- KNNClassifier\n",
    "- SVC\n",
    "- RFClassifier\n",
    "- AdaBoost\n",
    "- GradientBoostClassifier\n",
    "- XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "suburban-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'LogisticRegression-Tunned': LogisticRegression(),\n",
    "          'KNNClassifier': KNeighborsClassifier(),\n",
    "          'SVC': SVC(),\n",
    "          'RandomForestClassifier': RandomForestClassifier(),\n",
    "          'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "          'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "          'XGboostClassifier': XGBClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-carpet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression-Tunned ####################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       299\n",
      "           1       0.70      0.63      0.66        59\n",
      "\n",
      "    accuracy                           0.89       358\n",
      "   macro avg       0.81      0.79      0.80       358\n",
      "weighted avg       0.89      0.89      0.89       358\n",
      " \n",
      "\n",
      "KNNClassifier ################################################\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88       299\n",
      "           1       0.45      0.66      0.53        59\n",
      "\n",
      "    accuracy                           0.81       358\n",
      "   macro avg       0.69      0.75      0.71       358\n",
      "weighted avg       0.85      0.81      0.82       358\n",
      " \n",
      "\n",
      "SVC ##########################################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93       299\n",
      "           1       0.67      0.49      0.57        59\n",
      "\n",
      "    accuracy                           0.88       358\n",
      "   macro avg       0.79      0.72      0.75       358\n",
      "weighted avg       0.87      0.88      0.87       358\n",
      " \n",
      "\n",
      "RandomForestClassifier #######################################\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "for model_key, model_value in models.items():\n",
    "    X_train_modelling = X_train.copy()\n",
    "    X_val_modelling = X_val.copy()\n",
    "    \n",
    "    if model_key == 'LogisticRegression-Tunned':\n",
    "        # Dropping Multicolinear Features for Logistic Regression\n",
    "        X_train_modelling = X_train.drop(to_drop_from_vif, axis = 1)\n",
    "        X_val_modelling = X_val.drop(to_drop_from_vif, axis = 1)\n",
    "        param_grid = {\n",
    "            'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "            'tol': stats.loguniform(0.1, 1),\n",
    "            'C': stats.loguniform(3, 10)\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'KNNClassifier':\n",
    "        # Dropping Multicolinear Features for KNNClassifier\n",
    "        X_train_modelling = X_train.drop(to_drop_from_vif, axis = 1)\n",
    "        X_val_modelling = X_val.drop(to_drop_from_vif, axis = 1)\n",
    "        param_grid = {'n_neighbors':[3, 4, 5, 6, 7]}\n",
    "    \n",
    "    elif model_key == 'SVC':\n",
    "        # Dropping Multicolinear Features for SVC\n",
    "        X_train_modelling = X_train.drop(to_drop_from_vif, axis = 1)\n",
    "        X_val_modelling = X_val.drop(to_drop_from_vif, axis = 1)\n",
    "        param_grid = {\n",
    "            'C': stats.loguniform(3, 10)\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'RandomForestClassifier':\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 60, 70, 80, 90, 100],\n",
    "            'max_depth': np.arange(0, 10),\n",
    "            'min_samples_split': np.arange(0, 10),\n",
    "            'min_samples_leaf': stats.loguniform(.01, 1),\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'AdaBoostClassifier':\n",
    "        param_grid = {\n",
    "            'learning_rate': stats.lognorm(.001, 1)\n",
    "        }\n",
    "    \n",
    "    elif model_key == 'GradientBoostingClassifier':\n",
    "        param_grid = {\n",
    "            'learning_rate': stats.lognorm(.001, 1),\n",
    "            'n_estimators': [50, 60, 70, 80, 90, 100],\n",
    "            'min_samples_split': np.arange(0, 10),\n",
    "            'min_samples_leaf': stats.loguniform(.01, 1),\n",
    "            'max_depth': np.arange(0, 10)\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 60, 70, 80, 90, 100],\n",
    "            'max_depth': np.arange(0, 10),\n",
    "            'learning_rate': stats.lognorm(.001, 1),\n",
    "            'gamma': stats.lognorm(.001, 1),\n",
    "        }   \n",
    "    \n",
    "    \n",
    "    # Running RandomizedSearchCV\n",
    "    print(model_key, '#'.replace('#', '#'*(61 - len(model_key))))\n",
    "    model_rsearch = RandomizedSearchCV(model_value, \n",
    "                                       param_distributions = param_grid, \n",
    "                                       n_iter = 50, \n",
    "                                       scoring = 'f1', # Used to update weights\n",
    "                                       cv = 10, \n",
    "                                       n_jobs = -1, \n",
    "                                       verbose = 1)\n",
    "    \n",
    "    # Fitting the model to the train data\n",
    "    model_rsearch.fit(X_train_modelling, y_train)\n",
    "    \n",
    "    # Saving model as a joblib file\n",
    "    joblib.dump(model_rsearch, f'../models/{model_key}.joblib')\n",
    "    \n",
    "    # Predictions using X_val\n",
    "    y_val_pred = model_rsearch.predict(X_val_modelling)\n",
    "    \n",
    "    # Setting up metrics\n",
    "    metrics_names = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    metrics = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "    \n",
    "    # MLFlow Logs\n",
    "    run = client.create_run(experiment_id)\n",
    "    for metric_name, metric in zip(metrics_names, metrics):\n",
    "        client.log_metric(run.info.run_id, metric_name, metric(y_val, y_val_pred))\n",
    "    client.log_param(run.info.run_id, \"model\", model_key)\n",
    "    client.log_param(run.info.run_id, \"params\", model_value.get_params())\n",
    "    \n",
    "    print(classification_report(y_val, y_val_pred), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-cause",
   "metadata": {},
   "source": [
    "___________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
